{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6b29e2",
   "metadata": {},
   "source": [
    "# Utility function 1 to review images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75423dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive RAS+ mask reviewer for BraTS-like datasets\n",
    "# Requirements: nibabel, numpy, matplotlib, ipywidgets\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import (\n",
    "    Dropdown, SelectMultiple, IntSlider, FloatSlider, Checkbox, RadioButtons,\n",
    "    HBox, VBox, Output, HTML, Layout, Button\n",
    ")\n",
    "from matplotlib.colors import ListedColormap, to_rgba\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers: discovery and loading (RAS reorientation)\n",
    "# ---------------------------\n",
    "\n",
    "def _is_case_folder(path: Path) -> bool:\n",
    "    nii_files = list(path.glob(\"*.nii\")) + list(path.glob(\"*.nii.gz\"))\n",
    "    return len(nii_files) > 0\n",
    "\n",
    "\n",
    "def _find_case_modalities(case_dir: Path) -> dict:\n",
    "    # Find segmentation and modalities by naming hints\n",
    "    files = list(case_dir.glob(\"*.nii\")) + list(case_dir.glob(\"*.nii.gz\"))\n",
    "    by_key = {\n",
    "        \"seg\": None,\n",
    "        \"t1c\": None,\n",
    "        \"flair\": None,\n",
    "        \"t2\": None,\n",
    "        \"t1\": None,\n",
    "    }\n",
    "    for f in files:\n",
    "        name = f.name.lower()\n",
    "        if \"seg\" in name and by_key[\"seg\"] is None:\n",
    "            by_key[\"seg\"] = f\n",
    "        if \"t1c\" in name and by_key[\"t1c\"] is None:\n",
    "            by_key[\"t1c\"] = f\n",
    "        if \"flair\" in name and by_key[\"flair\"] is None:\n",
    "            by_key[\"flair\"] = f\n",
    "        if re.search(r\"(^|[^a-z])t2([^a-z]|$)\", name) and by_key[\"t2\"] is None:\n",
    "            by_key[\"t2\"] = f\n",
    "        if \"t1\" in name and \"t1c\" not in name and by_key[\"t1\"] is None:\n",
    "            by_key[\"t1\"] = f\n",
    "    return by_key\n",
    "\n",
    "\n",
    "def _discover_cases(root_path: str) -> dict:\n",
    "    root = Path(root_path)\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"Path not found: {root_path}\")\n",
    "\n",
    "    cases = {}\n",
    "    if _is_case_folder(root):\n",
    "        modalities = _find_case_modalities(root)\n",
    "        if modalities[\"seg\"] is not None:\n",
    "            cases[root.name] = modalities\n",
    "    else:\n",
    "        for sub in sorted(p for p in root.iterdir() if p.is_dir()):\n",
    "            modalities = _find_case_modalities(sub)\n",
    "            if modalities[\"seg\"] is not None:\n",
    "                cases[sub.name] = modalities\n",
    "\n",
    "    if not cases:\n",
    "        raise RuntimeError(\"No valid cases with a 'seg' file were found under the provided path.\")\n",
    "    return cases\n",
    "\n",
    "# Simple cache to avoid reloading from disk\n",
    "_VOLUME_CACHE = {}\n",
    "\n",
    "\n",
    "def _load_nifti_array(path: Path, is_segmentation: bool = False) -> np.ndarray:\n",
    "    \"\"\"Load NIfTI, reorient to RAS+ using nib.as_closest_canonical, return array.\n",
    "    If is_segmentation is True, cast to integer type for exact label comparisons.\n",
    "    \"\"\"\n",
    "    key = (str(path.resolve()), bool(is_segmentation))\n",
    "    if key in _VOLUME_CACHE:\n",
    "        return _VOLUME_CACHE[key]\n",
    "\n",
    "    img = nib.load(path)\n",
    "    img_ras = nib.as_closest_canonical(img)  # RAS+\n",
    "    arr = img_ras.get_fdata(dtype=np.float32)\n",
    "    if is_segmentation:\n",
    "        # Cast to int for exact equality and counting; assume non-negative labels\n",
    "        arr = np.rint(arr).astype(np.int16)\n",
    "    _VOLUME_CACHE[key] = arr\n",
    "    return arr\n",
    "\n",
    "# ---------------------------\n",
    "# Label utilities and colors\n",
    "# ---------------------------\n",
    "\n",
    "def summarize_segmentation_labels(seg_path: str) -> dict:\n",
    "    \"\"\"Return a dict: label_value -> voxel_count (after RAS reorientation).\"\"\"\n",
    "    seg = _load_nifti_array(Path(seg_path), is_segmentation=True)\n",
    "    unique, counts = np.unique(seg, return_counts=True)\n",
    "    summary = {int(u): int(c) for u, c in zip(unique, counts)}\n",
    "    return summary\n",
    "\n",
    "\n",
    "def _default_label_colors(unique_labels):\n",
    "    # Default mapping for common BraTS labels; fall back to tab20 for others\n",
    "    preferred = {\n",
    "        1: \"#1f77b4\",  # blue\n",
    "        2: \"#2ca02c\",  # green\n",
    "        3: \"#ff7f0e\",  # orange\n",
    "        4: \"#d62728\",  # red\n",
    "    }\n",
    "    colors = {}\n",
    "    tab20 = plt.get_cmap(\"tab20\")\n",
    "    extra_labels = [l for l in unique_labels if l not in preferred and l != 0]\n",
    "    for idx, l in enumerate(extra_labels):\n",
    "        colors[l] = tab20(idx % tab20.N)\n",
    "    for k, v in preferred.items():\n",
    "        if k in unique_labels:\n",
    "            colors[k] = v\n",
    "    return colors\n",
    "\n",
    "# ---------------------------\n",
    "# Visualization\n",
    "# ---------------------------\n",
    "\n",
    "def _extract_slice(volume: np.ndarray, axis: int, index: int) -> np.ndarray:\n",
    "    if axis == 0:\n",
    "        return volume[index, :, :]\n",
    "    elif axis == 1:\n",
    "        return volume[:, index, :]\n",
    "    else:\n",
    "        return volume[:, :, index]\n",
    "\n",
    "\n",
    "def _normalize_image(image2d: np.ndarray, do_normalize: bool) -> np.ndarray:\n",
    "    if not do_normalize:\n",
    "        return image2d\n",
    "    valid = np.isfinite(image2d)\n",
    "    if not np.any(valid):\n",
    "        return image2d\n",
    "    lo, hi = np.percentile(image2d[valid], [1, 99])\n",
    "    if hi <= lo:\n",
    "        return image2d\n",
    "    img = np.clip(image2d, lo, hi)\n",
    "    img = (img - lo) / (hi - lo + 1e-6)\n",
    "    return img\n",
    "\n",
    "\n",
    "def launch_mask_viewer(root_path: str):\n",
    "    \"\"\"\n",
    "    Launch an interactive viewer for cases under root_path. All volumes are reoriented to RAS+.\n",
    "    \"\"\"\n",
    "    cases = _discover_cases(root_path)\n",
    "    case_names = sorted(cases.keys())\n",
    "\n",
    "    def _default_modality(mods: dict) -> str:\n",
    "        for m in [\"t1c\", \"flair\", \"t2\", \"t1\"]:\n",
    "            if mods.get(m) is not None:\n",
    "                return m\n",
    "        return \"seg\"\n",
    "\n",
    "    # Widgets\n",
    "    case_dd = Dropdown(options=case_names, description=\"Case:\", layout=Layout(width=\"280px\"))\n",
    "    modality_dd = Dropdown(options=[], description=\"Modality:\", layout=Layout(width=\"180px\"))\n",
    "    plane_rb = RadioButtons(options=[(\"Axial\", 2), (\"Coronal\", 1), (\"Sagittal\", 0)],\n",
    "                            description=\"Plane:\", layout=Layout(width=\"200px\"))\n",
    "    slice_slider = IntSlider(description=\"Slice:\", min=0, max=1, value=0, continuous_update=False, layout=Layout(width=\"400px\"))\n",
    "    labels_ms = SelectMultiple(options=[], description=\"Labels:\", layout=Layout(width=\"180px\", height=\"160px\"))\n",
    "    alpha_slider = FloatSlider(description=\"Alpha:\", min=0.1, max=1.0, step=0.05, value=0.5, readout_format=\".2f\", layout=Layout(width=\"200px\"))\n",
    "    contour_cb = Checkbox(value=False, description=\"Contour only\")\n",
    "    norm_cb = Checkbox(value=True, description=\"Normalize image\")\n",
    "\n",
    "    label_summary_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    info_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    out = Output(layout=Layout(border=\"1px solid #ddd\"))\n",
    "\n",
    "    # State\n",
    "    current_seg_unique = []\n",
    "    current_case_modalities = {}\n",
    "\n",
    "    def _update_modality_options(change=None):\n",
    "        nonlocal current_case_modalities, current_seg_unique\n",
    "        case = case_dd.value\n",
    "        current_case_modalities = cases[case]\n",
    "\n",
    "        available_modalities = [m for m in [\"t1c\", \"flair\", \"t2\", \"t1\"] if current_case_modalities.get(m) is not None]\n",
    "        if not available_modalities:\n",
    "            available_modalities = [\"seg\"]\n",
    "        modality_dd.options = available_modalities\n",
    "        modality_dd.value = _default_modality(current_case_modalities)\n",
    "\n",
    "        seg_path = current_case_modalities[\"seg\"]\n",
    "        seg = _load_nifti_array(seg_path, is_segmentation=True)\n",
    "        unique_labels = sorted([int(x) for x in np.unique(seg)])\n",
    "        current_seg_unique = unique_labels\n",
    "        nonzero_labels = [l for l in unique_labels if l != 0]\n",
    "        labels_ms.options = [(str(l), l) for l in nonzero_labels]\n",
    "        labels_ms.value = tuple(nonzero_labels)\n",
    "\n",
    "        _update_slice_slider_range()\n",
    "\n",
    "        summary = summarize_segmentation_labels(str(seg_path))\n",
    "        items = [f\"<b>{k}</b>: {v}\" for k, v in sorted(summary.items())]\n",
    "        label_summary_html.value = f\"Label voxel counts: {' | '.join(items)}\"\n",
    "\n",
    "        info_html.value = \"All images are reoriented to <b>RAS+</b> for consistent viewing.\"\n",
    "\n",
    "        _render()\n",
    "\n",
    "    def _update_slice_slider_range(change=None):\n",
    "        vol_path = current_case_modalities.get(modality_dd.value) or current_case_modalities[\"seg\"]\n",
    "        vol = _load_nifti_array(vol_path, is_segmentation=(modality_dd.value == \"seg\"))\n",
    "        axis = plane_rb.value\n",
    "        max_idx = int(vol.shape[axis]) - 1\n",
    "        slice_slider.max = max_idx\n",
    "        slice_slider.value = max(0, min(max_idx, max_idx // 2))\n",
    "\n",
    "    def _render(change=None):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "\n",
    "            case = case_dd.value\n",
    "            mods = current_case_modalities\n",
    "            img_path = mods.get(modality_dd.value) or mods[\"seg\"]\n",
    "            seg_path = mods[\"seg\"]\n",
    "\n",
    "            img_vol = _load_nifti_array(img_path, is_segmentation=False)\n",
    "            seg_vol = _load_nifti_array(seg_path, is_segmentation=True)\n",
    "\n",
    "            # Safety: ensure shapes match for overlay\n",
    "            if img_vol.shape != seg_vol.shape:\n",
    "                warnings.warn(\n",
    "                    f\"Shape mismatch after RAS reorientation: image {img_vol.shape} vs seg {seg_vol.shape}. Overlay may be misaligned.\")\n",
    "\n",
    "            axis = plane_rb.value\n",
    "            idx = slice_slider.value\n",
    "\n",
    "            # Bound idx if shape mismatch on chosen axis\n",
    "            max_axis = min(img_vol.shape[axis], seg_vol.shape[axis]) - 1\n",
    "            idx = min(idx, max_axis)\n",
    "\n",
    "            img_slice = _extract_slice(img_vol, axis, idx)\n",
    "            seg_slice = _extract_slice(seg_vol, axis, idx)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "            ax.imshow(_normalize_image(img_slice, norm_cb.value), cmap=\"gray\")\n",
    "            ax.set_title(f\"{case} | {modality_dd.value.upper()} | {['Sagittal','Coronal','Axial'][axis]}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            colors_map = _default_label_colors(current_seg_unique)\n",
    "\n",
    "            selected_labels = list(labels_ms.value) if labels_ms.value else []\n",
    "            for l in selected_labels:\n",
    "                if l == 0:\n",
    "                    continue\n",
    "                mask = (seg_slice == l)\n",
    "                if not np.any(mask):\n",
    "                    continue\n",
    "                color_rgba = to_rgba(colors_map.get(l, \"#9467bd\"), alpha=alpha_slider.value)\n",
    "                if contour_cb.value:\n",
    "                    ax.contour(mask.astype(float), levels=[0.5], colors=[color_rgba], linewidths=1.5)\n",
    "                else:\n",
    "                    cmap = ListedColormap([(0, 0, 0, 0), color_rgba])\n",
    "                    ax.imshow(mask.astype(int), cmap=cmap, interpolation=\"none\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    # Wire callbacks\n",
    "    case_dd.observe(_update_modality_options, names=\"value\")\n",
    "    modality_dd.observe(_update_slice_slider_range, names=\"value\")\n",
    "    plane_rb.observe(_update_slice_slider_range, names=\"value\")\n",
    "    slice_slider.observe(_render, names=\"value\")\n",
    "    labels_ms.observe(_render, names=\"value\")\n",
    "    alpha_slider.observe(_render, names=\"value\")\n",
    "    contour_cb.observe(_render, names=\"value\")\n",
    "    norm_cb.observe(_render, names=\"value\")\n",
    "\n",
    "    # Initial layout\n",
    "    controls_row1 = HBox([case_dd, modality_dd, plane_rb, alpha_slider, contour_cb, norm_cb])\n",
    "    controls_row2 = HBox([slice_slider, labels_ms])\n",
    "    ui = VBox([controls_row1, controls_row2, label_summary_html, info_html, out])\n",
    "\n",
    "    _update_modality_options()\n",
    "    display(ui)\n",
    "\n",
    "# Example usage (uncomment and set your path):\n",
    "# launch_mask_viewer(\"/Users/chufal/projects/Datasets/PKG-BraTS-Africa/BraTS-Africa/95_Glioma\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc0f91",
   "metadata": {},
   "source": [
    "# Utility Function nnUNET (old) to review images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21632f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnU-Net style dataset utilities (imagesTr 4D, labelsTr 3D) + interactive viewer\n",
    "# Target root example: /Users/chufal/projects/DHAI-Brain-Segmentation/data_brainMRI_Segmentation\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Dropdown, SelectMultiple, IntSlider, FloatSlider, Checkbox, RadioButtons, HBox, VBox, HTML, Output, Layout\n",
    "\n",
    "# Reuse helpers from earlier cells: _load_nifti_array, _extract_slice, _normalize_image, _default_label_colors\n",
    "\n",
    "# ---------------------------\n",
    "# Parsing and discovery\n",
    "# ---------------------------\n",
    "\n",
    "def parse_nnunet_dataset(root_path: str):\n",
    "    \"\"\"Parse nnU-Net-like dataset with dataset.json, imagesTr, labelsTr.\n",
    "    Returns dict with keys: modalities (list[str]), labels_map (dict[int,str]),\n",
    "    training (list[dict{case_id, image_path, label_path}])\n",
    "    \"\"\"\n",
    "    root = Path(root_path)\n",
    "    ds_json = root / \"dataset.json\"\n",
    "    if not ds_json.exists():\n",
    "        raise FileNotFoundError(f\"dataset.json not found at: {ds_json}\")\n",
    "    with ds_json.open(\"r\") as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    # modalities ordered by numeric keys\n",
    "    modalities = [v for k, v in sorted(((int(k), v) for k, v in meta.get(\"modality\", {}).items()), key=lambda x: x[0])]\n",
    "    labels_map = {int(k): v for k, v in meta.get(\"labels\", {}).items()}\n",
    "\n",
    "    # training entries\n",
    "    training_entries = []\n",
    "    for item in meta.get(\"training\", []):\n",
    "        image_rel = item[\"image\"]\n",
    "        label_rel = item[\"label\"]\n",
    "        image_path = (root / image_rel).resolve()\n",
    "        label_path = (root / label_rel).resolve()\n",
    "        case_id = Path(image_rel).stem\n",
    "        training_entries.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"image_path\": image_path,\n",
    "            \"label_path\": label_path,\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"modalities\": modalities,\n",
    "        \"labels_map\": labels_map,\n",
    "        \"training\": training_entries,\n",
    "        \"meta\": {k: v for k, v in meta.items() if k not in {\"modality\", \"labels\", \"training\"}},\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Validation and summaries\n",
    "# ---------------------------\n",
    "\n",
    "def check_shapes_and_labels(root_path: str, compute_label_hist: bool = True, max_cases: int | None = None):\n",
    "    \"\"\"Validate that each image is 4D (last dim = num modalities) and label is 3D, and shapes align on first 3 dims.\n",
    "    Returns a list of dict per case with shapes and optional label histogram.\n",
    "    \"\"\"\n",
    "    info = parse_nnunet_dataset(root_path)\n",
    "    modalities = info[\"modalities\"]\n",
    "    num_modalities = len(modalities)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(info[\"training\"]):\n",
    "        if max_cases is not None and i >= max_cases:\n",
    "            break\n",
    "        image_path = entry[\"image_path\"]\n",
    "        label_path = entry[\"label_path\"]\n",
    "        case_id = entry[\"case_id\"]\n",
    "\n",
    "        img = nib.load(str(image_path))\n",
    "        img_ras = nib.as_closest_canonical(img)\n",
    "        img_shape = img_ras.shape\n",
    "\n",
    "        lbl = nib.load(str(label_path))\n",
    "        lbl_ras = nib.as_closest_canonical(lbl)\n",
    "        lbl_shape = lbl_ras.shape\n",
    "\n",
    "        row = {\n",
    "            \"case_id\": case_id,\n",
    "            \"image_shape\": img_shape,\n",
    "            \"label_shape\": lbl_shape,\n",
    "            \"expected_modalities\": num_modalities,\n",
    "            \"image_is_4d\": (len(img_shape) == 4),\n",
    "            \"label_is_3d\": (len(lbl_shape) == 3),\n",
    "            \"modalities_match\": (len(img_shape) == 4 and img_shape[3] == num_modalities),\n",
    "            \"spatial_match\": (len(lbl_shape) == 3 and len(img_shape) >= 3 and tuple(img_shape[:3]) == tuple(lbl_shape[:3])),\n",
    "        }\n",
    "        if compute_label_hist:\n",
    "            # Use cached loader for labels to avoid re-reading if already in cache\n",
    "            lbl_arr = _load_nifti_array(label_path, is_segmentation=True)\n",
    "            uniq, cnt = np.unique(lbl_arr, return_counts=True)\n",
    "            row[\"label_hist\"] = {int(u): int(c) for u, c in zip(uniq, cnt)}\n",
    "        results.append(row)\n",
    "\n",
    "    # Print brief summary\n",
    "    bad = [r for r in results if not (r[\"image_is_4d\"] and r[\"label_is_3d\"] and r[\"modalities_match\"] and r[\"spatial_match\"]) ]\n",
    "    print(f\"Checked {len(results)} cases. Problems: {len(bad)}\")\n",
    "    for r in bad[:10]:\n",
    "        print(f\"- {r['case_id']}: image {r['image_shape']}, label {r['label_shape']} (modalities ok? {r['modalities_match']}, spatial ok? {r['spatial_match']})\")\n",
    "    if len(bad) > 10:\n",
    "        print(f\"... and {len(bad) - 10} more\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# ---------------------------\n",
    "# Interactive viewer for nnU-Net 4D images\n",
    "# ---------------------------\n",
    "\n",
    "def launch_nnunet_viewer(root_path: str):\n",
    "    \"\"\"Interactive viewer for nnU-Net-style dataset.\n",
    "    - Select case\n",
    "    - Select modality (channel of 4D image)\n",
    "    - Select plane and slice\n",
    "    - Overlay labels (filled or contours), with alpha control\n",
    "    All volumes are reoriented to RAS+.\n",
    "    \"\"\"\n",
    "    info = parse_nnunet_dataset(root_path)\n",
    "    cases = info[\"training\"]\n",
    "    modalities = info[\"modalities\"]\n",
    "\n",
    "    if not cases:\n",
    "        raise RuntimeError(\"No training cases found in dataset.json\")\n",
    "\n",
    "    case_ids = [c[\"case_id\"] for c in cases]\n",
    "\n",
    "    # Widgets\n",
    "    case_dd = Dropdown(options=case_ids, description=\"Case:\", layout=Layout(width=\"320px\"))\n",
    "    modality_dd = Dropdown(options=[(m, idx) for idx, m in enumerate(modalities)], value=0, description=\"Modality:\", layout=Layout(width=\"240px\"))\n",
    "    plane_rb = RadioButtons(options=[(\"Axial\", 2), (\"Coronal\", 1), (\"Sagittal\", 0)], description=\"Plane:\", layout=Layout(width=\"220px\"))\n",
    "    slice_slider = IntSlider(description=\"Slice:\", min=0, max=1, value=0, continuous_update=False, layout=Layout(width=\"420px\"))\n",
    "    alpha_slider = FloatSlider(description=\"Alpha:\", min=0.1, max=1.0, step=0.05, value=0.5, readout_format=\".2f\", layout=Layout(width=\"220px\"))\n",
    "    contour_cb = Checkbox(value=False, description=\"Contour only\")\n",
    "    norm_cb = Checkbox(value=True, description=\"Normalize image\")\n",
    "\n",
    "    summary_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    out = Output(layout=Layout(border=\"1px solid #ddd\"))\n",
    "\n",
    "    # State\n",
    "    current_img4d = None\n",
    "    current_lbl = None\n",
    "    current_unique_labels = []\n",
    "\n",
    "    def _load_case(case_id: str):\n",
    "        nonlocal current_img4d, current_lbl, current_unique_labels\n",
    "        entry = next(c for c in cases if c[\"case_id\"] == case_id)\n",
    "        img4d = _load_nifti_array(entry[\"image_path\"])  # float32, RAS+\n",
    "        lbl = _load_nifti_array(entry[\"label_path\"], is_segmentation=True)  # int16, RAS+\n",
    "        if img4d.ndim != 4:\n",
    "            raise ValueError(f\"Image is not 4D for case {case_id}: shape {img4d.shape}\")\n",
    "        if lbl.ndim != 3:\n",
    "            raise ValueError(f\"Label is not 3D for case {case_id}: shape {lbl.shape}\")\n",
    "        if img4d.shape[:3] != lbl.shape:\n",
    "            warnings.warn(f\"Spatial mismatch: image {img4d.shape} vs label {lbl.shape}\")\n",
    "        current_img4d = img4d\n",
    "        current_lbl = lbl\n",
    "        current_unique_labels = sorted(int(x) for x in np.unique(lbl))\n",
    "\n",
    "        # Update slice slider\n",
    "        axis = plane_rb.value\n",
    "        max_idx = int(min(img4d.shape[axis], lbl.shape[axis])) - 1\n",
    "        slice_slider.max = max_idx\n",
    "        slice_slider.value = max(0, min(max_idx, max_idx // 2))\n",
    "\n",
    "        # Update summary\n",
    "        uniq, cnt = np.unique(lbl, return_counts=True)\n",
    "        items = [f\"<b>{int(u)}</b>: {int(c)}\" for u, c in sorted(zip(uniq, cnt))]\n",
    "        summary_html.value = \"Label voxel counts: \" + \" | \".join(items)\n",
    "\n",
    "    def _render(change=None):\n",
    "        if current_img4d is None or current_lbl is None:\n",
    "            _load_case(case_dd.value)\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            axis = plane_rb.value\n",
    "            idx = min(slice_slider.value, min(current_img4d.shape[axis], current_lbl.shape[axis]) - 1)\n",
    "            chan = modality_dd.value or 0\n",
    "\n",
    "            # Extract slice of selected modality\n",
    "            img3d = current_img4d[..., chan]\n",
    "            img_slice = _extract_slice(img3d, axis, idx)\n",
    "            lbl_slice = _extract_slice(current_lbl, axis, idx)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6.5, 6.5))\n",
    "            ax.imshow(_normalize_image(img_slice, norm_cb.value), cmap=\"gray\")\n",
    "            ax.set_title(f\"{case_dd.value} | {modalities[chan]} | {['Sagittal','Coronal','Axial'][axis]}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Colors for labels (use default helper; include 0 in unique set for mapping but skip rendering 0)\n",
    "            colors_map = _default_label_colors(current_unique_labels)\n",
    "            for l in [x for x in current_unique_labels if x != 0]:\n",
    "                mask = (lbl_slice == l)\n",
    "                if not np.any(mask):\n",
    "                    continue\n",
    "                from matplotlib.colors import to_rgba\n",
    "                color_rgba = to_rgba(colors_map.get(l, \"#9467bd\"), alpha=alpha_slider.value)\n",
    "                if contour_cb.value:\n",
    "                    ax.contour(mask.astype(float), levels=[0.5], colors=[color_rgba], linewidths=1.5)\n",
    "                else:\n",
    "                    from matplotlib.colors import ListedColormap\n",
    "                    cmap = ListedColormap([(0, 0, 0, 0), color_rgba])\n",
    "                    ax.imshow(mask.astype(int), cmap=cmap, interpolation=\"none\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    # Wire callbacks\n",
    "    def _on_case_change(change):\n",
    "        if change[\"name\"] == \"value\" and change[\"new\"] != change[\"old\"]:\n",
    "            _load_case(change[\"new\"])\n",
    "            _render()\n",
    "\n",
    "    case_dd.observe(_on_case_change, names=\"value\")\n",
    "    modality_dd.observe(_render, names=\"value\")\n",
    "    plane_rb.observe(lambda ch: _load_case(case_dd.value) or _render(), names=\"value\")\n",
    "    slice_slider.observe(_render, names=\"value\")\n",
    "    alpha_slider.observe(_render, names=\"value\")\n",
    "    contour_cb.observe(_render, names=\"value\")\n",
    "    norm_cb.observe(_render, names=\"value\")\n",
    "\n",
    "    # Layout and init\n",
    "    controls = HBox([case_dd, modality_dd, plane_rb, alpha_slider, contour_cb, norm_cb])\n",
    "    ui = VBox([controls, slice_slider, summary_html, out])\n",
    "\n",
    "    _load_case(case_dd.value)\n",
    "    _render()\n",
    "    display(ui)\n",
    "\n",
    "# Example usage:\n",
    "# root = \"/Users/chufal/projects/DHAI-Brain-Segmentation/data_brainMRI_Segmentation\"\n",
    "# check_shapes_and_labels(root)\n",
    "# launch_nnunet_viewer(root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/chufal/projects/DHAI-Brain-Segmentation/derived/segmentation_t1c_binary\"\n",
    "results = check_shapes_and_labels(root)\n",
    "len(results), results[0] \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ec689",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868325db",
   "metadata": {},
   "source": [
    "# Utility Function to review images for nnUNET (new version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eba873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override nnU-Net viewer to include selectable labels (0,1,2,3,...)\n",
    "from ipywidgets import Dropdown, SelectMultiple, IntSlider, FloatSlider, Checkbox, RadioButtons, HBox, VBox, HTML, Output, Layout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Reuses: parse_nnunet_dataset, _load_nifti_array, _extract_slice, _normalize_image, _default_label_colors\n",
    "\n",
    "def launch_nnunet_viewer(root_path: str):\n",
    "    \"\"\"Interactive viewer for nnU-Net-style dataset with label selection.\n",
    "    - Select case\n",
    "    - Select modality (channel of 4D image)\n",
    "    - Select plane and slice\n",
    "    - Select labels to overlay (multi-select, includes 0 if present)\n",
    "    - Overlay filled or contours, with alpha control\n",
    "    All volumes are reoriented to RAS+.\n",
    "    \"\"\"\n",
    "    info = parse_nnunet_dataset(root_path)\n",
    "    cases = info[\"training\"]\n",
    "    modalities = info[\"modalities\"]\n",
    "\n",
    "    if not cases:\n",
    "        raise RuntimeError(\"No training cases found in dataset.json\")\n",
    "\n",
    "    case_ids = [c[\"case_id\"] for c in cases]\n",
    "\n",
    "    # Widgets\n",
    "    case_dd = Dropdown(options=case_ids, description=\"Case:\", layout=Layout(width=\"320px\"))\n",
    "    modality_dd = Dropdown(options=[(m, idx) for idx, m in enumerate(modalities)], value=0, description=\"Modality:\", layout=Layout(width=\"240px\"))\n",
    "    plane_rb = RadioButtons(options=[(\"Axial\", 2), (\"Coronal\", 1), (\"Sagittal\", 0)], description=\"Plane:\", layout=Layout(width=\"220px\"))\n",
    "    slice_slider = IntSlider(description=\"Slice:\", min=0, max=1, value=0, continuous_update=False, layout=Layout(width=\"420px\"))\n",
    "    labels_ms = SelectMultiple(options=[], description=\"Labels:\", layout=Layout(width=\"200px\", height=\"160px\"))\n",
    "    alpha_slider = FloatSlider(description=\"Alpha:\", min=0.1, max=1.0, step=0.05, value=0.5, readout_format=\".2f\", layout=Layout(width=\"220px\"))\n",
    "    contour_cb = Checkbox(value=False, description=\"Contour only\")\n",
    "    norm_cb = Checkbox(value=True, description=\"Normalize image\")\n",
    "\n",
    "    summary_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    out = Output(layout=Layout(border=\"1px solid #ddd\"))\n",
    "\n",
    "    # State\n",
    "    current_img4d = None\n",
    "    current_lbl = None\n",
    "    current_unique_labels = []\n",
    "\n",
    "    def _load_case(case_id: str):\n",
    "        nonlocal current_img4d, current_lbl, current_unique_labels\n",
    "        entry = next(c for c in cases if c[\"case_id\"] == case_id)\n",
    "        img4d = _load_nifti_array(entry[\"image_path\"])  # float32, RAS+\n",
    "        lbl = _load_nifti_array(entry[\"label_path\"], is_segmentation=True)  # int16, RAS+\n",
    "        if img4d.ndim != 4:\n",
    "            raise ValueError(f\"Image is not 4D for case {case_id}: shape {img4d.shape}\")\n",
    "        if lbl.ndim != 3:\n",
    "            raise ValueError(f\"Label is not 3D for case {case_id}: shape {lbl.shape}\")\n",
    "        if img4d.shape[:3] != lbl.shape:\n",
    "            warnings.warn(f\"Spatial mismatch: image {img4d.shape} vs label {lbl.shape}\")\n",
    "        current_img4d = img4d\n",
    "        current_lbl = lbl\n",
    "        current_unique_labels = sorted(int(x) for x in np.unique(lbl))\n",
    "\n",
    "        # Update labels selector (default to all non-zero if available, otherwise include 0)\n",
    "        nonzero = [l for l in current_unique_labels if l != 0]\n",
    "        options = [(str(l), l) for l in current_unique_labels]\n",
    "        labels_ms.options = options\n",
    "        labels_ms.value = tuple(nonzero if nonzero else current_unique_labels)\n",
    "\n",
    "        # Update slice slider\n",
    "        axis = plane_rb.value\n",
    "        max_idx = int(min(img4d.shape[axis], lbl.shape[axis])) - 1\n",
    "        slice_slider.max = max_idx\n",
    "        slice_slider.value = max(0, min(max_idx, max_idx // 2))\n",
    "\n",
    "        # Update summary\n",
    "        uniq, cnt = np.unique(lbl, return_counts=True)\n",
    "        items = [f\"<b>{int(u)}</b>: {int(c)}\" for u, c in sorted(zip(uniq, cnt))]\n",
    "        summary_html.value = \"Label voxel counts: \" + \" | \".join(items)\n",
    "\n",
    "    def _render(change=None):\n",
    "        if current_img4d is None or current_lbl is None:\n",
    "            _load_case(case_dd.value)\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            axis = plane_rb.value\n",
    "            idx = min(slice_slider.value, min(current_img4d.shape[axis], current_lbl.shape[axis]) - 1)\n",
    "            chan = modality_dd.value or 0\n",
    "\n",
    "            # Extract slice of selected modality\n",
    "            img3d = current_img4d[..., chan]\n",
    "            img_slice = _extract_slice(img3d, axis, idx)\n",
    "            lbl_slice = _extract_slice(current_lbl, axis, idx)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6.5, 6.5))\n",
    "            ax.imshow(_normalize_image(img_slice, norm_cb.value), cmap=\"gray\")\n",
    "            ax.set_title(f\"{case_dd.value} | {modalities[chan]} | {['Sagittal','Coronal','Axial'][axis]}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Colors and selected labels\n",
    "            colors_map = _default_label_colors(current_unique_labels)\n",
    "            selected_labels = list(labels_ms.value) if labels_ms.value else []\n",
    "            for l in selected_labels:\n",
    "                mask = (lbl_slice == l)\n",
    "                if not np.any(mask):\n",
    "                    continue\n",
    "                from matplotlib.colors import to_rgba, ListedColormap\n",
    "                color_rgba = to_rgba(colors_map.get(l, \"#9467bd\"), alpha=alpha_slider.value)\n",
    "                if contour_cb.value:\n",
    "                    ax.contour(mask.astype(float), levels=[0.5], colors=[color_rgba], linewidths=1.5)\n",
    "                else:\n",
    "                    cmap = ListedColormap([(0, 0, 0, 0), color_rgba])\n",
    "                    ax.imshow(mask.astype(int), cmap=cmap, interpolation=\"none\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    # Callbacks\n",
    "    def _on_case_change(change):\n",
    "        if change[\"name\"] == \"value\" and change[\"new\"] != change[\"old\"]:\n",
    "            _load_case(change[\"new\"])\n",
    "            _render()\n",
    "\n",
    "    case_dd.observe(_on_case_change, names=\"value\")\n",
    "    modality_dd.observe(_render, names=\"value\")\n",
    "    plane_rb.observe(lambda ch: _load_case(case_dd.value) or _render(), names=\"value\")\n",
    "    slice_slider.observe(_render, names=\"value\")\n",
    "    labels_ms.observe(_render, names=\"value\")\n",
    "    alpha_slider.observe(_render, names=\"value\")\n",
    "    contour_cb.observe(_render, names=\"value\")\n",
    "    norm_cb.observe(_render, names=\"value\")\n",
    "\n",
    "    # Layout and init\n",
    "    controls_row1 = HBox([case_dd, modality_dd, plane_rb, alpha_slider, contour_cb, norm_cb])\n",
    "    controls_row2 = HBox([slice_slider, labels_ms])\n",
    "    ui = VBox([controls_row1, controls_row2, summary_html, out])\n",
    "\n",
    "    _load_case(case_dd.value)\n",
    "    _render()\n",
    "    display(ui)\n",
    "\n",
    "# Example:\n",
    "# launch_nnunet_viewer(\"/Users/chufal/projects/DHAI-Brain-Segmentation/data_brainMRI_Segmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12956dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/chufal/projects/DHAI-Brain-Segmentation/derived/segmentation_t1c_binary\"\n",
    "launch_nnunet_viewer(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daec56a",
   "metadata": {},
   "source": [
    "# Utility Function 2 to review images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized RAS+ viewer for multi-label segmentations and multiple binary masks\n",
    "# Supports: BraTS-like, BCBM-RadioGenomics, MU-Glioma-Post (timepoints), Pretreat-MetsToBrain, UCSD-PTGBM, UPENN-GBM (separate mask dir)\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import warnings\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import (\n",
    "    Dropdown, SelectMultiple, IntSlider, FloatSlider, Checkbox, RadioButtons,\n",
    "    HBox, VBox, Output, HTML, Layout\n",
    ")\n",
    "from matplotlib.colors import ListedColormap, to_rgba\n",
    "\n",
    "# Assumes helpers from the earlier cell exist: _load_nifti_array, _normalize_image, _extract_slice\n",
    "\n",
    "# ---------------------------\n",
    "# Case discovery (dataset-specific and auto)\n",
    "# ---------------------------\n",
    "\n",
    "CaseSpec = Dict[str, object]  # keys: case_id, image_path, multilabel_seg_path, binary_masks (list[{name, path}]), meta\n",
    "MaskSpec = Dict[str, str]     # keys: name, path\n",
    "\n",
    "_re_ext = r\"\\.nii(\\.gz)?$\"\n",
    "\n",
    "\n",
    "def _first_existing(files: List[Path]) -> Optional[Path]:\n",
    "    return next((p for p in files if p is not None and p.exists()), None)\n",
    "\n",
    "\n",
    "def _find_in_dir(dir_path: Path, pattern: str) -> List[Path]:\n",
    "    regex = re.compile(pattern, re.IGNORECASE)\n",
    "    nii = list(dir_path.glob(\"*.nii\")) + list(dir_path.glob(\"*.nii.gz\"))\n",
    "    return [p for p in nii if regex.search(p.name)]\n",
    "\n",
    "\n",
    "# ---- BraTS-like: one image modality + one multi-label seg in same folder or subfolders ----\n",
    "\n",
    "def _discover_brats_like(root: Path) -> Dict[str, CaseSpec]:\n",
    "    cases: Dict[str, CaseSpec] = {}\n",
    "    def find_modality(files: List[Path]) -> Optional[Path]:\n",
    "        priority = [r\"t1c\", r\"flair\", r\"t2\", r\"t1\"]\n",
    "        for key in priority:\n",
    "            for f in files:\n",
    "                if re.search(key, f.name, re.IGNORECASE):\n",
    "                    return f\n",
    "        return None\n",
    "    if list(root.glob(\"*.nii\")) or list(root.glob(\"*.nii.gz\")):\n",
    "        files = list(root.glob(\"*.nii\")) + list(root.glob(\"*.nii.gz\"))\n",
    "        segs = [f for f in files if re.search(r\"seg\", f.name, re.IGNORECASE)]\n",
    "        if segs:\n",
    "            image = find_modality(files)\n",
    "            cases[root.name] = {\n",
    "                \"case_id\": root.name,\n",
    "                \"image_path\": image,\n",
    "                \"multilabel_seg_path\": segs[0],\n",
    "                \"binary_masks\": [],\n",
    "                \"meta\": {\"dataset\": \"brats_like\"},\n",
    "            }\n",
    "    else:\n",
    "        for sub in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "            files = list(sub.glob(\"*.nii\")) + list(sub.glob(\"*.nii.gz\"))\n",
    "            if not files:\n",
    "                continue\n",
    "            segs = [f for f in files if re.search(r\"seg\", f.name, re.IGNORECASE)]\n",
    "            if segs:\n",
    "                image = find_modality(files)\n",
    "                cases[sub.name] = {\n",
    "                    \"case_id\": sub.name,\n",
    "                    \"image_path\": image,\n",
    "                    \"multilabel_seg_path\": segs[0],\n",
    "                    \"binary_masks\": [],\n",
    "                    \"meta\": {\"dataset\": \"brats_like\"},\n",
    "                }\n",
    "    return cases\n",
    "\n",
    "\n",
    "# ---- BCBM-RadioGenomics: one image *_image* and multiple *_mask_* in same folder ----\n",
    "\n",
    "def _discover_bcbm_radiogenomics(root: Path) -> Dict[str, CaseSpec]:\n",
    "    cases: Dict[str, CaseSpec] = {}\n",
    "    target_dirs = [root] if (list(root.glob(\"*.nii\")) or list(root.glob(\"*.nii.gz\"))) else [p for p in root.iterdir() if p.is_dir()]\n",
    "    for d in target_dirs:\n",
    "        images = _find_in_dir(d, rf\"_image.*{_re_ext}\")\n",
    "        masks = _find_in_dir(d, rf\"_mask_.*{_re_ext}\")\n",
    "        if not images and not masks:\n",
    "            continue\n",
    "        image = images[0] if images else None\n",
    "        mask_specs: List[MaskSpec] = []\n",
    "        for m in masks:\n",
    "            # robust mask name: remove extension then strip everything up to first _mask_\n",
    "            stem = re.sub(r\"\\.nii(\\.gz)?$\", \"\", m.name, flags=re.IGNORECASE)\n",
    "            mname = re.sub(r\"^.*?_mask_\", \"\", stem, flags=re.IGNORECASE)\n",
    "            mask_specs.append({\"name\": mname, \"path\": str(m)})\n",
    "        case_id = d.name\n",
    "        cases[case_id] = {\n",
    "            \"case_id\": case_id,\n",
    "            \"image_path\": image,\n",
    "            \"multilabel_seg_path\": None,\n",
    "            \"binary_masks\": mask_specs,\n",
    "            \"meta\": {\"dataset\": \"bcbm_radiogenomics\"},\n",
    "        }\n",
    "    return cases\n",
    "\n",
    "\n",
    "# ---- MU-Glioma-Post: Patient/Timepoint_* folders ----\n",
    "\n",
    "def _discover_mu_glioma_post(root: Path) -> Dict[str, CaseSpec]:\n",
    "    cases: Dict[str, CaseSpec] = {}\n",
    "    patient_dirs = [root] if any(p.name.startswith(\"Timepoint_\") for p in root.iterdir() if p.is_dir()) else [p for p in root.iterdir() if p.is_dir()]\n",
    "    for patient in patient_dirs:\n",
    "        tps = [patient] if patient.name.startswith(\"Timepoint_\") else [p for p in patient.iterdir() if p.is_dir() and p.name.startswith(\"Timepoint_\")]\n",
    "        for tp in tps:\n",
    "            images = _find_in_dir(tp, rf\"brain_t1c{_re_ext}\")\n",
    "            masks = _find_in_dir(tp, rf\"tumorMask{_re_ext}\")\n",
    "            image = images[0] if images else None\n",
    "            mask_specs = [{\"name\": \"tumorMask\", \"path\": str(masks[0])}] if masks else []\n",
    "            if not image and not mask_specs:\n",
    "                continue\n",
    "            case_id = f\"{patient.name}_{tp.name}\" if patient != tp else tp.name\n",
    "            cases[case_id] = {\n",
    "                \"case_id\": case_id,\n",
    "                \"image_path\": image,\n",
    "                \"multilabel_seg_path\": None,\n",
    "                \"binary_masks\": mask_specs,\n",
    "                \"meta\": {\"dataset\": \"mu_glioma_post\", \"patient\": patient.name, \"timepoint\": tp.name},\n",
    "            }\n",
    "    return cases\n",
    "\n",
    "\n",
    "# ---- Pretreat-MetsToBrain: *-t1c.nii* and *-seg.nii* ----\n",
    "\n",
    "def _discover_pretreat_mets(root: Path) -> Dict[str, CaseSpec]:\n",
    "    cases: Dict[str, CaseSpec] = {}\n",
    "    target_dirs = [root] if (list(root.glob(\"*.nii\")) or list(root.glob(\"*.nii.gz\"))) else [p for p in root.iterdir() if p.is_dir()]\n",
    "    for d in target_dirs:\n",
    "        images = _find_in_dir(d, rf\"-t1c{_re_ext}\")\n",
    "        segs = _find_in_dir(d, rf\"-seg{_re_ext}\")\n",
    "        if not images and not segs:\n",
    "            continue\n",
    "        case_id = d.name\n",
    "        cases[case_id] = {\n",
    "            \"case_id\": case_id,\n",
    "            \"image_path\": images[0] if images else None,\n",
    "            \"multilabel_seg_path\": segs[0] if segs else None,\n",
    "            \"binary_masks\": [],\n",
    "            \"meta\": {\"dataset\": \"pretreat_mets\"},\n",
    "        }\n",
    "    return cases\n",
    "\n",
    "\n",
    "# ---- UCSD-PTGBM: many files, image *T1post*, masks *total_cellular_tumor_seg* (binary) and/or *BraTS_tumor_seg* (multi) ----\n",
    "\n",
    "def _discover_ucsd_ptgbm(root: Path) -> Dict[str, CaseSpec]:\n",
    "    cases: Dict[str, CaseSpec] = {}\n",
    "    target_dirs = [root] if (list(root.glob(\"*.nii\")) or list(root.glob(\"*.nii.gz\"))) else [p for p in root.iterdir() if p.is_dir()]\n",
    "    for d in target_dirs:\n",
    "        images = _find_in_dir(d, rf\"T1post{_re_ext}\")\n",
    "        bin_masks = _find_in_dir(d, rf\"total_cellular_tumor_seg{_re_ext}\")\n",
    "        multi_masks = _find_in_dir(d, rf\"BraTS_tumor_seg{_re_ext}\")\n",
    "        if not images and not bin_masks and not multi_masks:\n",
    "            continue\n",
    "        mask_specs = [{\"name\": \"total_cellular_tumor_seg\", \"path\": str(bin_masks[0])}] if bin_masks else []\n",
    "        case_id = d.name\n",
    "        cases[case_id] = {\n",
    "            \"case_id\": case_id,\n",
    "            \"image_path\": images[0] if images else None,\n",
    "            \"multilabel_seg_path\": multi_masks[0] if multi_masks else None,\n",
    "            \"binary_masks\": mask_specs,\n",
    "            \"meta\": {\"dataset\": \"ucsd_ptgbm\"},\n",
    "        }\n",
    "    return cases\n",
    "\n",
    "\n",
    "# ---- UPENN-GBM: images in image_root; masks in separate mask_dir ----\n",
    "\n",
    "def _discover_upenn_gbm(image_root: Path, mask_dir: Optional[Path], mask_source: Optional[str] = None) -> Dict[str, CaseSpec]:\n",
    "    cases: Dict[str, CaseSpec] = {}\n",
    "    if not image_root.exists():\n",
    "        return cases\n",
    "\n",
    "    # Determine image search root (commonly images_structural_unstripped)\n",
    "    images_root_dir = image_root / \"images_structural_unstripped\" if (image_root / \"images_structural_unstripped\").exists() else image_root\n",
    "\n",
    "    # Build list of mask directories. If mask_source specified, use only that folder under image_root when present.\n",
    "    mask_dirs: List[Path] = []\n",
    "    valid_sources = {\"images_segm\", \"automated_segm\"}\n",
    "    if mask_source in valid_sources:\n",
    "        p = image_root / mask_source\n",
    "        if p.exists():\n",
    "            mask_dirs = [p]\n",
    "        elif mask_dir and mask_dir.exists():\n",
    "            mask_dirs = [mask_dir]\n",
    "    else:\n",
    "        if mask_dir and mask_dir.exists():\n",
    "            mask_dirs.append(mask_dir)\n",
    "        for sub in [\"images_segm\", \"automated_segm\"]:\n",
    "            p = image_root / sub\n",
    "            if p.exists():\n",
    "                mask_dirs.append(p)\n",
    "\n",
    "    id_re_img = re.compile(r\"(UPENN-GBM-\\d{5}_\\d{2})_T1GD_unstripped\", re.IGNORECASE)\n",
    "    id_re_segm = re.compile(r\"(UPENN-GBM-\\d{5}_\\d{2})_segm\", re.IGNORECASE)\n",
    "    id_re_auto = re.compile(r\"(UPENN-GBM-\\d{5}_\\d{2})_automated_approx_segm\", re.IGNORECASE)\n",
    "\n",
    "    # Index images by id (recursive under images_root_dir)\n",
    "    id_to_image: Dict[str, Path] = {}\n",
    "    image_files = list(images_root_dir.rglob(\"*.nii\")) + list(images_root_dir.rglob(\"*.nii.gz\"))\n",
    "    for f in image_files:\n",
    "        m = id_re_img.match(f.stem)\n",
    "        if m:\n",
    "            id_to_image[m.group(1)] = f\n",
    "\n",
    "    # Index masks from all known mask dirs\n",
    "    id_to_mask_primary: Dict[str, Path] = {}\n",
    "    id_to_mask_auto: Dict[str, Path] = {}\n",
    "    for md in mask_dirs:\n",
    "        mask_files = list(md.rglob(\"*.nii\")) + list(md.rglob(\"*.nii.gz\"))\n",
    "        for mfile in mask_files:\n",
    "            s = mfile.stem\n",
    "            m1 = id_re_segm.match(s)\n",
    "            if m1 and m1.group(1) not in id_to_mask_primary:\n",
    "                id_to_mask_primary[m1.group(1)] = mfile\n",
    "                continue\n",
    "            m2 = id_re_auto.match(s)\n",
    "            if m2 and m2.group(1) not in id_to_mask_auto:\n",
    "                id_to_mask_auto[m2.group(1)] = mfile\n",
    "\n",
    "    # Build cases by image id; prefer primary segm, otherwise automated approx as fallback\n",
    "    for cid, img_path in id_to_image.items():\n",
    "        seg_path = id_to_mask_primary.get(cid) or id_to_mask_auto.get(cid)\n",
    "        cases[cid] = {\n",
    "            \"case_id\": cid,\n",
    "            \"image_path\": img_path,\n",
    "            \"multilabel_seg_path\": seg_path,\n",
    "            \"binary_masks\": [],\n",
    "            \"meta\": {\"dataset\": \"upenn_gbm\", \"has_automated\": bool(cid in id_to_mask_auto and cid not in id_to_mask_primary)},\n",
    "        }\n",
    "\n",
    "    return cases\n",
    "\n",
    "\n",
    "# ---- Auto routing ----\n",
    "\n",
    "def discover_cases_flexible(root_path: str, mask_dir: Optional[str] = None, dataset_hint: Optional[str] = None, upenn_mask_source: Optional[str] = None) -> Dict[str, CaseSpec]:\n",
    "    root = Path(root_path)\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"Path not found: {root_path}\")\n",
    "    mask_path = Path(mask_dir) if mask_dir else None\n",
    "\n",
    "    if dataset_hint:\n",
    "        hint = dataset_hint.lower()\n",
    "        if hint in {\"brats_like\", \"brats\"}:\n",
    "            return _discover_brats_like(root)\n",
    "        if hint in {\"bcbm_radiogenomics\", \"bcbm\"}:\n",
    "            return _discover_bcbm_radiogenomics(root)\n",
    "        if hint in {\"mu_glioma_post\", \"mu\"}:\n",
    "            return _discover_mu_glioma_post(root)\n",
    "        if hint in {\"pretreat_mets\", \"mets\"}:\n",
    "            return _discover_pretreat_mets(root)\n",
    "        if hint in {\"ucsd_ptgbm\", \"ucsd\"}:\n",
    "            return _discover_ucsd_ptgbm(root)\n",
    "        if hint in {\"upenn_gbm\", \"upenn\"}:\n",
    "            return _discover_upenn_gbm(root, mask_path, mask_source=upenn_mask_source)\n",
    "        raise ValueError(f\"Unknown dataset_hint: {dataset_hint}\")\n",
    "\n",
    "    # Auto-detect heuristics\n",
    "    root_name = root.name.lower()\n",
    "    # Strong hints by path name\n",
    "    if \"upenn-gbm\" in root_name or (mask_path and \"images_segm\" in str(mask_path)):\n",
    "        return _discover_upenn_gbm(root, mask_path, mask_source=upenn_mask_source)\n",
    "    if \"ucsd-ptgbm\" in root_name or \"ptgbm\" in root_name:\n",
    "        return _discover_ucsd_ptgbm(root)\n",
    "    if \"pretreat-mets\" in root_name or \"mets\" in root_name:\n",
    "        return _discover_pretreat_mets(root)\n",
    "    if \"glioma-post\" in root_name:\n",
    "        return _discover_mu_glioma_post(root)\n",
    "    if \"radiogenomics\" in root_name or any(\"_mask_\" in f.name for f in root.glob(\"**/*.nii*\")):\n",
    "        # presence of *_mask_* suggests BCBM schema\n",
    "        return _discover_bcbm_radiogenomics(root)\n",
    "    # fallback\n",
    "    return _discover_brats_like(root)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Summaries\n",
    "# ---------------------------\n",
    "\n",
    "def summarize_binary_mask(mask_path: str) -> int:\n",
    "    \"\"\"Return foreground voxel count (>0) for a binary mask (after RAS reorientation).\"\"\"\n",
    "    vol = _load_nifti_array(Path(mask_path), is_segmentation=True)\n",
    "    return int(np.count_nonzero(vol))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Generalized viewer\n",
    "# ---------------------------\n",
    "\n",
    "def launch_flexible_mask_viewer(root_path: str, mask_dir: Optional[str] = None, dataset_hint: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Interactive viewer across datasets. Handles either a multi-label segmentation, multiple binary masks, or both.\n",
    "    All volumes are reoriented to RAS+.\n",
    "    \"\"\"\n",
    "    # For UPENN-GBM we first let the user choose between images_segm and automated_segm\n",
    "    is_upenn = (dataset_hint or '').lower() in {'upenn_gbm', 'upenn'} or ('upenn-gbm' in Path(root_path).name.lower())\n",
    "    upenn_source_dd = None\n",
    "    if is_upenn:\n",
    "        upenn_source_dd = Dropdown(options=[('images_segm', 'images_segm'), ('automated_segm', 'automated_segm')], description='UPENN masks:', layout=Layout(width='260px'))\n",
    "        # initial discovery uses images_segm by default\n",
    "        cases = discover_cases_flexible(root_path, mask_dir=mask_dir, dataset_hint=dataset_hint, upenn_mask_source=upenn_source_dd.value)\n",
    "    else:\n",
    "        cases = discover_cases_flexible(root_path, mask_dir=mask_dir, dataset_hint=dataset_hint)\n",
    "\n",
    "    if not cases:\n",
    "        raise RuntimeError(\"No cases found at the provided path(s).\")\n",
    "\n",
    "    case_ids = sorted(cases.keys())\n",
    "\n",
    "    # Widgets\n",
    "    case_dd = Dropdown(options=case_ids, description=\"Case:\", layout=Layout(width=\"320px\"))\n",
    "    source_dd = Dropdown(options=[], description=\"Source:\", layout=Layout(width=\"220px\"))\n",
    "    plane_rb = RadioButtons(options=[(\"Axial\", 2), (\"Coronal\", 1), (\"Sagittal\", 0)],\n",
    "                            description=\"Plane:\", layout=Layout(width=\"220px\"))\n",
    "    slice_slider = IntSlider(description=\"Slice:\", min=0, max=1, value=0, continuous_update=False, layout=Layout(width=\"420px\"))\n",
    "    labels_ms = SelectMultiple(options=[], description=\"Labels:\", layout=Layout(width=\"200px\", height=\"180px\"))\n",
    "    masks_ms = SelectMultiple(options=[], description=\"Masks:\", layout=Layout(width=\"280px\", height=\"220px\"))\n",
    "    alpha_slider = FloatSlider(description=\"Alpha:\", min=0.1, max=1.0, step=0.05, value=0.5, readout_format=\".2f\", layout=Layout(width=\"220px\"))\n",
    "    contour_cb = Checkbox(value=False, description=\"Contour only\")\n",
    "    norm_cb = Checkbox(value=True, description=\"Normalize image\")\n",
    "\n",
    "    summary_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    legend_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    info_html = HTML(value=\"All images are reoriented to <b>RAS+</b>.\", layout=Layout(width=\"100%\"))\n",
    "    out = Output(layout=Layout(border=\"1px solid #ddd\"))\n",
    "\n",
    "    # State\n",
    "    current_case: CaseSpec = {}\n",
    "    current_label_values: List[int] = []\n",
    "    mask_name_to_color: Dict[str, str] = {}\n",
    "\n",
    "    def _update_source_options(change=None):\n",
    "        nonlocal current_case, current_label_values, mask_name_to_color\n",
    "        cid = case_dd.value\n",
    "        current_case = cases[cid]\n",
    "\n",
    "        # Determine available sources\n",
    "        has_multi = current_case.get(\"multilabel_seg_path\") is not None\n",
    "        has_masks = bool(current_case.get(\"binary_masks\"))\n",
    "        options = []\n",
    "        if has_multi:\n",
    "            options.append((\"Multi-label segmentation\", \"multi\"))\n",
    "        if has_masks:\n",
    "            options.append((\"Binary masks\", \"masks\"))\n",
    "        if not options:\n",
    "            options = [(\"No overlays\", \"none\")]\n",
    "        source_dd.options = options\n",
    "        source_dd.value = options[0][1]\n",
    "\n",
    "        # Setup per-source UI\n",
    "        if has_multi:\n",
    "            seg_path = current_case[\"multilabel_seg_path\"]\n",
    "            seg = _load_nifti_array(Path(seg_path), is_segmentation=True)\n",
    "            current_label_values = sorted(int(x) for x in np.unique(seg))\n",
    "            nonzero = [l for l in current_label_values if l != 0]\n",
    "            labels_ms.options = [(str(l), l) for l in nonzero]\n",
    "            labels_ms.value = tuple(nonzero)\n",
    "        else:\n",
    "            current_label_values = []\n",
    "            labels_ms.options = []\n",
    "            labels_ms.value = ()\n",
    "\n",
    "        if has_masks:\n",
    "            names = [m[\"name\"] for m in current_case[\"binary_masks\"]]\n",
    "            masks_ms.options = [(n, n) for n in names]\n",
    "            masks_ms.value = tuple(names)\n",
    "            # Assign colors\n",
    "            cmap = plt.get_cmap(\"tab20\")\n",
    "            mask_name_to_color = {n: cmap(i % cmap.N) for i, n in enumerate(names)}\n",
    "        else:\n",
    "            masks_ms.options = []\n",
    "            masks_ms.value = ()\n",
    "            mask_name_to_color = {}\n",
    "\n",
    "        _update_slice_slider_range()\n",
    "        _render()\n",
    "\n",
    "    def _get_base_volume() -> np.ndarray:\n",
    "        # Prefer image_path; else fall back to multi-label seg; else first mask\n",
    "        if current_case.get(\"image_path\") is not None:\n",
    "            return _load_nifti_array(Path(current_case[\"image_path\"]))\n",
    "        if current_case.get(\"multilabel_seg_path\") is not None:\n",
    "            return _load_nifti_array(Path(current_case[\"multilabel_seg_path\"]))\n",
    "        masks = current_case.get(\"binary_masks\") or []\n",
    "        if masks:\n",
    "            return _load_nifti_array(Path(masks[0][\"path\"]))\n",
    "        raise RuntimeError(\"No image or overlays available for base display.\")\n",
    "\n",
    "    def _update_slice_slider_range(change=None):\n",
    "        vol = _get_base_volume()\n",
    "        axis = plane_rb.value\n",
    "        max_idx = int(vol.shape[axis]) - 1\n",
    "        slice_slider.max = max_idx\n",
    "        slice_slider.value = max(0, min(max_idx, max_idx // 2))\n",
    "\n",
    "    def _render(change=None):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            try:\n",
    "                base_vol = _get_base_volume()\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading base volume: {e}\")\n",
    "                return\n",
    "\n",
    "            axis = plane_rb.value\n",
    "            idx = slice_slider.value\n",
    "            if idx >= base_vol.shape[axis]:\n",
    "                idx = max(0, base_vol.shape[axis] - 1)\n",
    "\n",
    "            base_slice = _extract_slice(base_vol, axis, idx)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6.5, 6.5))\n",
    "            ax.imshow(_normalize_image(base_slice, norm_cb.value), cmap=\"gray\")\n",
    "            ax.set_title(f\"{case_dd.value} | {['Sagittal','Coronal','Axial'][axis]}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            source = source_dd.value\n",
    "            summary_text = []\n",
    "            legend_text = []\n",
    "\n",
    "            if source == \"multi\" and current_case.get(\"multilabel_seg_path\"):\n",
    "                seg_vol = _load_nifti_array(Path(current_case[\"multilabel_seg_path\"]), is_segmentation=True)\n",
    "                if seg_vol.shape != base_vol.shape:\n",
    "                    warnings.warn(f\"Shape mismatch: base {base_vol.shape} vs seg {seg_vol.shape}\")\n",
    "                seg_slice = _extract_slice(seg_vol, axis, min(idx, seg_vol.shape[axis] - 1))\n",
    "\n",
    "                selected_labels = list(labels_ms.value) if labels_ms.value else []\n",
    "                # Use existing default colors for labels\n",
    "                from matplotlib.colors import to_hex\n",
    "                colors_map = _default_label_colors(current_label_values) if '_default_label_colors' in globals() else {}\n",
    "                for l in selected_labels:\n",
    "                    if l == 0:\n",
    "                        continue\n",
    "                    mask = (seg_slice == l)\n",
    "                    if not np.any(mask):\n",
    "                        continue\n",
    "                    color_rgba = to_rgba(colors_map.get(l, \"#9467bd\"), alpha=alpha_slider.value)\n",
    "                    if contour_cb.value:\n",
    "                        ax.contour(mask.astype(float), levels=[0.5], colors=[color_rgba], linewidths=1.5)\n",
    "                    else:\n",
    "                        cmap = ListedColormap([(0, 0, 0, 0), color_rgba])\n",
    "                        ax.imshow(mask.astype(int), cmap=cmap, interpolation=\"none\")\n",
    "                    summary_text.append(f\"Label <b>{l}</b>: {int(np.count_nonzero(seg_vol == l))}\")\n",
    "                    legend_text.append(f\"<span style='color:{to_hex(color_rgba)}'></span> Label {l}\")\n",
    "\n",
    "            elif source == \"masks\" and current_case.get(\"binary_masks\"):\n",
    "                # Render each selected mask over base\n",
    "                from matplotlib.colors import to_hex\n",
    "                selected_names = list(masks_ms.value) if masks_ms.value else []\n",
    "                for name in selected_names:\n",
    "                    mpath = next((m[\"path\"] for m in current_case[\"binary_masks\"] if m[\"name\"] == name), None)\n",
    "                    if not mpath:\n",
    "                        continue\n",
    "                    mvol = _load_nifti_array(Path(mpath), is_segmentation=True)\n",
    "                    if mvol.shape != base_vol.shape:\n",
    "                        warnings.warn(f\"Shape mismatch: base {base_vol.shape} vs mask {mvol.shape} ({name})\")\n",
    "                    mslice = _extract_slice(mvol, axis, min(idx, mvol.shape[axis] - 1))\n",
    "                    mask = mslice > 0\n",
    "                    if not np.any(mask):\n",
    "                        continue\n",
    "                    col = mask_name_to_color.get(name, (0.58, 0.56, 0.74, 1.0))\n",
    "                    color_rgba = (col[0], col[1], col[2], alpha_slider.value)\n",
    "                    if contour_cb.value:\n",
    "                        ax.contour(mask.astype(float), levels=[0.5], colors=[color_rgba], linewidths=1.5)\n",
    "                    else:\n",
    "                        cmap = ListedColormap([(0, 0, 0, 0), color_rgba])\n",
    "                        ax.imshow(mask.astype(int), cmap=cmap, interpolation=\"none\")\n",
    "                    total = int(np.count_nonzero(mvol))\n",
    "                    summary_text.append(f\"Mask <b>{name}</b>: {total}\")\n",
    "                    legend_text.append(f\"<span style='color:{to_hex(color_rgba)}'></span> {name}\")\n",
    "\n",
    "            summary_html.value = \" | \".join(summary_text) if summary_text else \"\"\n",
    "            legend_html.value = \"Legend: \" + (\" | \".join(legend_text) if legend_text else \"(none)\")\n",
    "            plt.show()\n",
    "\n",
    "    # Wire callbacks\n",
    "    case_dd.observe(_update_source_options, names=\"value\")\n",
    "    source_dd.observe(_render, names=\"value\")\n",
    "    plane_rb.observe(_update_slice_slider_range, names=\"value\")\n",
    "    slice_slider.observe(_render, names=\"value\")\n",
    "    labels_ms.observe(_render, names=\"value\")\n",
    "    masks_ms.observe(_render, names=\"value\")\n",
    "    alpha_slider.observe(_render, names=\"value\")\n",
    "    contour_cb.observe(_render, names=\"value\")\n",
    "    norm_cb.observe(_render, names=\"value\")\n",
    "\n",
    "    # Layout\n",
    "    controls_row1 = HBox([case_dd, source_dd, plane_rb, alpha_slider, contour_cb, norm_cb])\n",
    "    controls_row2 = HBox([slice_slider, labels_ms, masks_ms])\n",
    "    # If UPENN, include the mask source selector and wire its callback to re-discover cases\n",
    "    if upenn_source_dd is not None:\n",
    "        def _on_upenn_source_change(change):\n",
    "            nonlocal cases\n",
    "            if change['name'] == 'value' and change['new'] != change['old']:\n",
    "                cases = discover_cases_flexible(root_path, mask_dir=mask_dir, dataset_hint=dataset_hint, upenn_mask_source=change['new'])\n",
    "                # refresh case list\n",
    "                with out:\n",
    "                    out.clear_output()\n",
    "                new_ids = sorted(cases.keys())\n",
    "                case_dd.options = new_ids\n",
    "                if new_ids:\n",
    "                    case_dd.value = new_ids[0]\n",
    "        upenn_source_dd.observe(_on_upenn_source_change, names='value')\n",
    "        controls_row0 = HBox([upenn_source_dd])\n",
    "        ui = VBox([controls_row0, controls_row1, controls_row2, summary_html, legend_html, info_html, out])\n",
    "    else:\n",
    "        ui = VBox([controls_row1, controls_row2, summary_html, legend_html, info_html, out])\n",
    "\n",
    "    _update_source_options()\n",
    "    display(ui)\n",
    "\n",
    "# Example usage presets (uncomment to use):\n",
    "# launch_flexible_mask_viewer(\"/path/to/BCBM_KSC_curated_data\", dataset_hint=\"bcbm_radiogenomics\")\n",
    "# launch_flexible_mask_viewer(\"/path/to/MU-Glioma-Post\", dataset_hint=\"mu_glioma_post\")\n",
    "# launch_flexible_mask_viewer(\"/path/to/Pretreat-MetsToBrain-Masks\", dataset_hint=\"pretreat_mets\")\n",
    "# launch_flexible_mask_viewer(\"/path/to/UCSD-PTGBM\", dataset_hint=\"ucsd_ptgbm\")\n",
    "# launch_flexible_mask_viewer(\"/path/to/UPENN-GBM/NIfTI-files\", mask_dir=\"/path/to/UPENN-GBM/NIfTI-files/images_segm\", dataset_hint=\"upenn_gbm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e529a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/chufal/projects/Datasets/PKG-BCBM-RadioGenomics_Images_Masks_Dec2024/BCBM_KSC_curated_data/\"\n",
    "results = launch_flexible_mask_viewer(root, dataset_hint=\"bcbm_radiogenomics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fb8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_nnunet_viewer(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3c117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c321d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfed43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e93b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98938638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a22265",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_flexible_mask_viewer(\"/Users/chufal/projects/Datasets/PKG-UPENN-GBM-NIfTI/UPENN-GBM/NIfTI-files\",\n",
    "                            dataset_hint=\"upenn_gbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_flexible_mask_viewer(\"/Users/chufal/projects/Datasets/PKG-BCBM-RadioGenomics_Images_Masks_Dec2024/BCBM_KSC_curated_data\",\n",
    "                            mask_dir=\"images_segm\",\n",
    "                            dataset_hint=\"bcbm_radiogenomics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d17186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00733fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99613a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fe58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc89a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391473b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b932a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3020c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef289e23-5de3-49c9-934d-6f84d2339dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6fd6ec-d881-4082-bbad-7916775dde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face access token\n",
    "hf_access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2501b-1839-4c71-94f5-1502d7412b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "data_folder_tr = \"/Users/chufal/Downloads/DHAI_capstone_project/data_brainMRI_Segmentation/imagesTr/\"\n",
    "data_folder_ts = \"/Users/chufal/Downloads/DHAI_capstone_project/data_brainMRI_Segmentation/imagesTs/\"\n",
    "data_folder_labels_tr = \"/Users/chufal/Downloads/DHAI_capstone_project/data_brainMRI_Segmentation/labelsTr/\"\n",
    "data_folder_dataset = \"/Users/chufal/Downloads/DHAI_capstone_project/data_brainMRI_Segmentation/dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712b384-be2c-4f34-92aa-6b8d34bba22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_tr_images_names = os.listdir(data_folder_tr)\n",
    "mri_ts_images_names = os.listdir(data_folder_ts)\n",
    "img_path_tr = os.path.join(data_folder_tr,mri_tr_images_names[20])\n",
    "img_path_ts = os.path.join(data_folder_ts,mri_ts_images_names[20])\n",
    "img_tr = nib.load(img_path_tr)\n",
    "img_ts = nib.load(img_path_ts)\n",
    "img_data_tr = img_tr.get_fdata()\n",
    "img_data_ts = img_ts.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bb7c1-5811-469f-a42d-9c0c4c691092",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_tr.shape, img_data_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ede0b",
   "metadata": {},
   "source": [
    "## MR images are 4 channels (240, 240, 155, 4) here 4 represents channel\n",
    "- Channel 0 - Flair\n",
    "- Channel 1 - T1w\n",
    "- Channel 2 - T1Gd\n",
    "- Channel 3 - T2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dde03f-edbb-459b-8962-d193a4e52c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Channel 2 T1Gd post contrast image\n",
    "plt.imshow(img_data_tr[:,:,106,2], cmap='gray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0ad4e-5c98-40fe-972e-88557185005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba610069",
   "metadata": {},
   "source": [
    "# Exploring MU Glioblastoma dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25c311-faae-4a01-9b76-455199b42f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b72179-405f-4079-959d-e745429a94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1) Index helper (reuseable) ----\n",
    "def build_patient_timepoint_index(dataset_root: str):\n",
    "    root = Path(dataset_root)\n",
    "    assert root.is_dir(), f\"{dataset_root} not found\"\n",
    "    modality_tokens = {\n",
    "        \"brain_t2w\": \"t2w\",\n",
    "        \"brain_t2f\": \"t2f\",\n",
    "        \"brain_t1n\": \"t1n\",\n",
    "        \"brain_t1c\": \"t1c\",\n",
    "        \"tumorMask\": \"mask\",\n",
    "    }\n",
    "    def timepoint_sort_key(tp_name: str):\n",
    "        m = re.search(r\"Timepoint_(\\d+)\", tp_name)\n",
    "        return int(m.group(1)) if m else 0\n",
    "\n",
    "    index = {}\n",
    "    for patient_dir in sorted([d for d in Path(dataset_root).iterdir() if d.is_dir()]):\n",
    "        patient_key = patient_dir.name\n",
    "        tp_map = {}\n",
    "        timepoint_dirs = [d for d in patient_dir.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n",
    "        timepoint_dirs = sorted(timepoint_dirs, key=lambda d: timepoint_sort_key(d.name))\n",
    "\n",
    "        for tp_dir in timepoint_dirs:\n",
    "            files = [f for f in tp_dir.iterdir() if f.is_file() and f.suffixes == ['.nii', '.gz']]\n",
    "            entry = {}\n",
    "            for f in files:\n",
    "                fname = f.name\n",
    "                for token, key in modality_tokens.items():\n",
    "                    if token in fname:\n",
    "                        entry[key] = str(f)\n",
    "                        break\n",
    "            expected = set(modality_tokens.values())\n",
    "            missing = expected - set(entry.keys())\n",
    "            if missing:\n",
    "                print(f\"[WARN] {patient_key}/{tp_dir.name} missing: {sorted(missing)}\")\n",
    "            tp_map[tp_dir.name] = entry\n",
    "        if tp_map:\n",
    "            index[patient_key] = tp_map\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c048f-35a2-4658-a8d9-9590f4279f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2) Build index and collect 36 slices for PatientID_0007 ----\n",
    "dataset_path = \"/Users/chufal/projects/Datasets/PKG-MU-Glioma-Post/MU-Glioma-Post\"\n",
    "patient_id = \"PatientID_0009\"\n",
    "modality = \"t1c\"   # change to 't2w', 't2f', or 't1n' if desired\n",
    "total_slices = 36  # well build 6x6\n",
    "\n",
    "idx = build_patient_timepoint_index(dataset_path)\n",
    "assert patient_id in idx, f\"{patient_id} not found in dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf1d49-fc04-4877-aff2-2cc1ff692fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort timepoints numerically\n",
    "def tp_num(tp): \n",
    "    m = re.search(r\"Timepoint_(\\d+)\", tp)\n",
    "    return int(m.group(1)) if m else 0\n",
    "timepoints = sorted(idx[patient_id].keys(), key=tp_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec47fd-bbc8-496b-bff4-aa655f05f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []  # (mri_slice, mask_slice, tp_name, z)\n",
    "\n",
    "# Distribute slices across timepoints as evenly as possible\n",
    "num_tp = len(timepoints)\n",
    "if num_tp == 0:\n",
    "    raise RuntimeError(f\"No timepoints found for {patient_id}\")\n",
    "per_tp = ceil(total_slices / num_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e130df-132b-4674-ac9e-730014991c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tp in timepoints:\n",
    "    entry = idx[patient_id][tp]\n",
    "    if modality not in entry or \"mask\" not in entry:\n",
    "        print(f\"[SKIP] {patient_id}/{tp}: missing {modality} or mask\")\n",
    "        continue\n",
    "\n",
    "    img = nib.load(entry[modality]).get_fdata(dtype=np.float32)\n",
    "    msk = nib.load(entry[\"mask\"]).get_fdata(dtype=np.float32)\n",
    "\n",
    "    # Match your earlier orientation\n",
    "    img = np.rot90(img)\n",
    "    msk = np.rot90(msk)\n",
    "\n",
    "    # Ensure 3D\n",
    "    assert img.ndim == 3 and msk.ndim == 3, \"Expecting 3D volumes\"\n",
    "\n",
    "    D = img.shape[0]\n",
    "    if D < per_tp:\n",
    "        z_indices = list(range(D))  # take all available\n",
    "    else:\n",
    "        z_indices = np.linspace(0, D-1, per_tp, dtype=int).tolist()\n",
    "\n",
    "    # Normalize MRI per-slice for display; mask is shown as labels\n",
    "    for z in z_indices:\n",
    "        mri_slice = img[z]\n",
    "        # min-max normalize for display\n",
    "        mri_min, mri_max = mri_slice.min(), mri_slice.max()\n",
    "        if mri_max > mri_min:\n",
    "            mri_slice = (mri_slice - mri_min) / (mri_max - mri_min)\n",
    "        else:\n",
    "            mri_slice = np.zeros_like(mri_slice)\n",
    "\n",
    "        mask_slice = msk[z]\n",
    "        pairs.append((mri_slice, mask_slice, tp, z))\n",
    "        if len(pairs) >= total_slices:\n",
    "            break\n",
    "    if len(pairs) >= total_slices:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf5694-5582-4c84-81b4-5ef810535c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pairs) < total_slices:\n",
    "    print(f\"[INFO] Only {len(pairs)} slices collected (fewer timepoints/slices than 36).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b3aa1-9893-47b5-afbb-d87724449cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3) Plot 6x6 MRI grid ----\n",
    "rows, cols = 6, 6\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 14))\n",
    "for i in range(rows * cols):\n",
    "    ax = axes[i // cols, i % cols]\n",
    "    if i < len(pairs):\n",
    "        mri_slice, _, tp, z = pairs[i]\n",
    "        ax.imshow(mri_slice, cmap=\"gray\")\n",
    "        ax.set_title(f\"{tp} | z={z}\", fontsize=8)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(f\"{patient_id} - {modality.upper()} | MRI slices (6x6)\", y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecba066-97ad-4644-8f91-735733f311a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4) Plot 6x6 Mask grid (discrete colormap) ----\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 14))\n",
    "for i in range(rows * cols):\n",
    "    ax = axes[i // cols, i % cols]\n",
    "    if i < len(pairs):\n",
    "        _, mask_slice, tp, z = pairs[i]\n",
    "        ax.imshow(mask_slice, cmap=\"Reds\", interpolation=\"nearest\")\n",
    "        ax.set_title(f\"{tp} | z={z}\", fontsize=8)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(f\"{patient_id} - Mask slices (6x6)\", y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0372442-c5ce-4174-ac9d-ff1889953793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tp_num(tp_name: str):\n",
    "    m = re.search(r\"Timepoint_(\\d+)\", tp_name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "def list_available(dataset_root: str, patient_id: str):\n",
    "    \"\"\"Print available timepoints and modalities for the given patient.\"\"\"\n",
    "    root = Path(dataset_root)\n",
    "    if not (root.exists() and root.is_dir()):\n",
    "        print(f\"[ERROR] Dataset root not found: {dataset_root}\")\n",
    "        return\n",
    "    patient_dir = root / patient_id\n",
    "    if not patient_dir.is_dir():\n",
    "        print(f\"[ERROR] Patient not found: {patient_id}\")\n",
    "        print(\"Available patients (first 20):\")\n",
    "        for d in list(sorted([p.name for p in root.iterdir() if p.is_dir()]))[:20]:\n",
    "            print(\" -\", d)\n",
    "        return\n",
    "    tps = [d for d in patient_dir.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n",
    "    tps = sorted(tps, key=lambda d: _tp_num(d.name))\n",
    "    print(f\"Patient {patient_id} timepoints: {[d.name for d in tps]}\")\n",
    "    for tp in tps:\n",
    "        files = [f for f in tp.iterdir() if f.is_file() and f.suffixes == ['.nii', '.gz']]\n",
    "        mods = []\n",
    "        for f in files:\n",
    "            n = f.name\n",
    "            for token in [\"brain_t2w\",\"brain_t2f\",\"brain_t1n\",\"brain_t1c\",\"tumorMask\"]:\n",
    "                if token in n:\n",
    "                    mods.append(token)\n",
    "        print(f\" - {tp.name}: {sorted(set(mods))}\")\n",
    "\n",
    "def show_mri_slice_with_and_without_mask(\n",
    "    dataset_root: str,\n",
    "    patient_id: str,\n",
    "    modality: str = \"t1c\",        # one of: 't1c','t1n','t2w','t2f'\n",
    "    timepoint_no: int | None = 1, # numeric part in 'Timepoint_X'; if None uses first available\n",
    "    slice_no: int | None = None,  # if None, uses middle slice\n",
    "    overlay_multiclass: bool = True,\n",
    "    mask_alpha: float = 0.4,\n",
    "    strict: bool = False,         # if True, raise ValueError instead of graceful return\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if plotted, False if gracefully skipped (or raises if strict=True).\n",
    "    \"\"\"\n",
    "    # Resolve dataset/patient\n",
    "    root = Path(dataset_root)\n",
    "    if not root.is_dir():\n",
    "        msg = f\"Dataset root not found: {dataset_root}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg); return False\n",
    "\n",
    "    patient_dir = root / patient_id\n",
    "    if not patient_dir.is_dir():\n",
    "        msg = f\"Patient not found: {patient_id}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg)\n",
    "        list_available(dataset_root, patient_id)  # will print available patients/timepoints\n",
    "        return False\n",
    "\n",
    "    # Collect timepoints\n",
    "    tp_dirs = [d for d in patient_dir.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n",
    "    tp_dirs = sorted(tp_dirs, key=lambda d: _tp_num(d.name))\n",
    "    if not tp_dirs:\n",
    "        msg = f\"No timepoints found for {patient_id}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg); return False\n",
    "\n",
    "    # Resolve requested timepoint\n",
    "    if timepoint_no is None:\n",
    "        tp_dir = tp_dirs[0]\n",
    "    else:\n",
    "        requested = f\"Timepoint_{timepoint_no}\"\n",
    "        tp_map = {d.name: d for d in tp_dirs}\n",
    "        if requested not in tp_map:\n",
    "            msg = f\"{requested} not found for {patient_id}. Available: {list(tp_map.keys())}\"\n",
    "            if strict: raise ValueError(msg)\n",
    "            print(\"[WARN]\", msg)\n",
    "            return False\n",
    "        tp_dir = tp_map[requested]\n",
    "\n",
    "    # Resolve files for modalities/mask\n",
    "    files = [f for f in tp_dir.iterdir() if f.is_file() and f.suffixes == ['.nii', '.gz']]\n",
    "    def find_path(token: str):\n",
    "        for f in files:\n",
    "            if token in f.name:\n",
    "                return f\n",
    "        return None\n",
    "\n",
    "    token_by_mod = {\"t2w\":\"brain_t2w\",\"t2f\":\"brain_t2f\",\"t1n\":\"brain_t1n\",\"t1c\":\"brain_t1c\"}\n",
    "    token = token_by_mod.get(modality.lower())\n",
    "    if token is None:\n",
    "        msg = f\"Unknown modality '{modality}'. Use one of {list(token_by_mod.keys())}.\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg); return False\n",
    "\n",
    "    img_path = find_path(token)\n",
    "    mask_path = find_path(\"tumorMask\")\n",
    "\n",
    "    if img_path is None or mask_path is None:\n",
    "        msg = f\"Missing files in {tp_dir.name} for {patient_id}: \" + \\\n",
    "              f\"{'image missing' if img_path is None else ''} {'mask missing' if mask_path is None else ''}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[WARN]\", msg)\n",
    "        print(\"Available tokens in this timepoint:\")\n",
    "        for f in files: print(\" -\", f.name)\n",
    "        return False\n",
    "\n",
    "    # Load volumes\n",
    "    img = nib.load(str(img_path)).get_fdata(dtype=np.float32)\n",
    "    msk = nib.load(str(mask_path)).get_fdata(dtype=np.float32)\n",
    "\n",
    "    # Orientation consistent with earlier usage\n",
    "    img = np.rot90(img)\n",
    "    msk = np.rot90(msk)\n",
    "\n",
    "    if img.ndim != 3 or msk.ndim != 3:\n",
    "        msg = f\"Expected 3D volumes, got shapes {img.shape}, {msk.shape}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg); return False\n",
    "\n",
    "    depth = img.shape[0]\n",
    "    if slice_no is None:\n",
    "        used_slice = depth // 2\n",
    "    else:\n",
    "        if not (0 <= slice_no < depth):\n",
    "            if strict:\n",
    "                raise ValueError(f\"slice_no {slice_no} out of range [0, {depth-1}]\")\n",
    "            print(f\"[WARN] slice_no {slice_no} out of range for depth {depth}. Using middle slice.\")\n",
    "            used_slice = depth // 2\n",
    "        else:\n",
    "            used_slice = slice_no\n",
    "\n",
    "    mri_slice = img[used_slice]\n",
    "    mask_slice = msk[used_slice]\n",
    "\n",
    "    # Normalize MRI per-slice for display\n",
    "    mn, mx = mri_slice.min(), mri_slice.max()\n",
    "    mri_disp = (mri_slice - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(mri_slice)\n",
    "\n",
    "    # Overlay transparency only for mask > 0\n",
    "    nonzero = (mask_slice > 0).astype(np.float32)\n",
    "    alpha = nonzero * mask_alpha\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    title_base = f\"{patient_id} | {tp_dir.name} | {modality.upper()} | z={used_slice}\"\n",
    "\n",
    "    axes[0].imshow(mri_disp, cmap=\"gray\")\n",
    "    axes[0].set_title(title_base)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(mri_disp, cmap=\"gray\")\n",
    "    if overlay_multiclass:\n",
    "        axes[1].imshow(mask_slice, cmap=\"nipy_spectral\", alpha=alpha)\n",
    "    else:\n",
    "        axes[1].imshow(nonzero, cmap=\"Reds\", alpha=alpha)\n",
    "    axes[1].set_title(\"Overlay\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ceddf5-6cea-479c-aee1-204fa830e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/chufal/projects/Datasets/PKG-MU-Glioma-Post/MU-Glioma-Post\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If youre unsure which timepoints exist:\n",
    "list_available(dataset_path, \"PatientID_0009\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca97d29-4e29-44bd-be58-cf5bfa4ad5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then display (returns True/False instead of asserting)\n",
    "ok = show_mri_slice_with_and_without_mask(\n",
    "    dataset_root=dataset_path,\n",
    "    patient_id=\"PatientID_0009\",\n",
    "    modality=\"t2w\",\n",
    "    timepoint_no=2,     # set to an existing timepoint number, or None to use the first\n",
    "    slice_no=80,        # any int; will auto-correct to middle if out of range\n",
    "    overlay_multiclass=True,\n",
    "    mask_alpha=0.6,\n",
    "    strict=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e542fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd4459-d650-44c4-927e-d5f3f66cca02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mask_file(mask_path: str, print_values_limit: int = 20):\n",
    "    mask_path = Path(mask_path)\n",
    "    if not mask_path.is_file():\n",
    "        raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "    img = nib.load(str(mask_path))\n",
    "    arr_on_disk = np.asanyarray(img.dataobj)  # uses on-disk dtype (often int for labels)\n",
    "\n",
    "    print(f\"File: {mask_path.name}\")\n",
    "    print(f\"Shape: {arr_on_disk.shape}\")\n",
    "    print(f\"On-disk dtype: {arr_on_disk.dtype}\")\n",
    "    if arr_on_disk.ndim == 4:\n",
    "        print(\"Note: 4D mask detected (channels). Treat each channel as a separate class/probability map.\")\n",
    "\n",
    "    # Basic stats\n",
    "    data_min = float(arr_on_disk.min())\n",
    "    data_max = float(arr_on_disk.max())\n",
    "    num_vox = arr_on_disk.size\n",
    "    num_nonzero = int((arr_on_disk != 0).sum())\n",
    "    print(f\"Value range: [{data_min}, {data_max}]\")\n",
    "    print(f\"Non-zero voxels: {num_nonzero} ({num_nonzero/num_vox:.4%})\")\n",
    "\n",
    "    # Unique label analysis\n",
    "    if arr_on_disk.dtype.kind in (\"i\", \"u\"):  # integer labels\n",
    "        uniq, counts = np.unique(arr_on_disk, return_counts=True)\n",
    "        # Summarize\n",
    "        print(f\"Unique integer values ({len(uniq)}): {uniq[:print_values_limit]}\")\n",
    "        if len(uniq) > print_values_limit:\n",
    "            print(\"... (truncated)\")\n",
    "        nonzero_labels = [int(v) for v in uniq if v != 0]\n",
    "        if set(uniq).issubset({0, 1}):\n",
    "            print(\"Mask type: Binary (0=background, 1=lesion)\")\n",
    "        elif len(nonzero_labels) > 0:\n",
    "            print(f\"Mask type: Multi-class with labels (excluding 0): {nonzero_labels[:print_values_limit]}\")\n",
    "            if len(nonzero_labels) > print_values_limit:\n",
    "                print(\"... (truncated)\")\n",
    "        else:\n",
    "            print(\"Mask appears empty (no labels > 0).\")\n",
    "\n",
    "    else:\n",
    "        # float mask: check if effectively discrete integers\n",
    "        is_int_like = np.isclose(arr_on_disk, np.round(arr_on_disk), atol=1e-3)\n",
    "        frac_int_like = float(is_int_like.mean())\n",
    "        print(f\"Float mask: {frac_int_like:.2%} of voxels are within 1e-3 of an integer.\")\n",
    "        if frac_int_like > 0.999:\n",
    "            rounded = np.round(arr_on_disk).astype(np.int32)\n",
    "            uniq, counts = np.unique(rounded, return_counts=True)\n",
    "            print(f\"Unique rounded values ({len(uniq)}): {uniq[:print_values_limit]}\")\n",
    "            if len(uniq) > print_values_limit:\n",
    "                print(\"... (truncated)\")\n",
    "            nonzero_labels = [int(v) for v in uniq if v != 0]\n",
    "            if set(uniq).issubset({0, 1}):\n",
    "                print(\"Mask type (after rounding): Binary\")\n",
    "            elif len(nonzero_labels) > 0:\n",
    "                print(f\"Mask type (after rounding): Multi-class with labels (excluding 0): {nonzero_labels[:print_values_limit]}\")\n",
    "                if len(nonzero_labels) > print_values_limit:\n",
    "                    print(\"... (truncated)\")\n",
    "            else:\n",
    "                print(\"Mask appears empty after rounding.\")\n",
    "        else:\n",
    "            print(\"Mask appears continuous/probabilistic (not discrete labels).\")\n",
    "            # Show a small quantile summary\n",
    "            qs = np.quantile(arr_on_disk, [0, 0.25, 0.5, 0.75, 1.0])\n",
    "            print(f\"Quantiles: min={qs[0]:.4g}, Q1={qs[1]:.4g}, median={qs[2]:.4g}, Q3={qs[3]:.4g}, max={qs[4]:.4g}\")\n",
    "\n",
    "def quick_show_mask(mask_path: str, slice_index: int | None = None):\n",
    "    arr = np.asanyarray(nib.load(mask_path).dataobj)\n",
    "    if arr.ndim == 4:\n",
    "        arr = arr[..., 0]\n",
    "        print(\"Visualizing first channel of 4D mask.\")\n",
    "    if slice_index is None:\n",
    "        slice_index = arr.shape[2] // 2\n",
    "    # If youve been using np.rot90 elsewhere, apply here for consistency:\n",
    "    vol = np.rot90(arr, axes=(0,1))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(vol[:,:,slice_index], cmap=\"nipy_spectral\", interpolation=\"nearest\")\n",
    "    plt.title(f\"Mask slice z={slice_index}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db83a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: adjust root if needed\n",
    "dataset_root = \"/Users/chufal/projects/Datasets/PKG-MU-Glioma-Post/MU-Glioma-Post\"\n",
    "mask_path = f\"{dataset_root}/PatientID_0009/Timepoint_2/PatientID_0009_Timepoint_2_tumorMask.nii.gz\"\n",
    "analyze_mask_file(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_show_mask(mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b96b4",
   "metadata": {},
   "source": [
    "# Exploring Pretreat-MetsToBrain-Masks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40962b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_met_index(dataset_root: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        'BraTS-MET-00086-000': {\n",
    "          't2w': '/.../BraTS-MET-00086-000-t2w.nii.gz',\n",
    "          't2f': '/.../BraTS-MET-00086-000-t2f.nii.gz',\n",
    "          't1n': '/.../BraTS-MET-00086-000-t1n.nii.gz',\n",
    "          't1c': '/.../BraTS-MET-00086-000-t1c.nii.gz',\n",
    "          'seg': '/.../BraTS-MET-00086-000-seg.nii.gz'\n",
    "        },\n",
    "        ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    root = Path(dataset_root)\n",
    "    assert root.is_dir(), f\"{dataset_root} not found\"\n",
    "    token_map = {\n",
    "        r\"-t2w\\.nii\\.gz$\": \"t2w\",\n",
    "        r\"-t2f\\.nii\\.gz$\": \"t2f\",\n",
    "        r\"-t1n\\.nii\\.gz$\": \"t1n\",\n",
    "        r\"-t1c\\.nii\\.gz$\": \"t1c\",\n",
    "        r\"-seg\\.nii\\.gz$\": \"seg\",\n",
    "    }\n",
    "\n",
    "    index = {}\n",
    "    for case_dir in sorted([d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]):\n",
    "        entry = {}\n",
    "        for f in case_dir.iterdir():\n",
    "            if not (f.is_file() and f.suffixes == ['.nii', '.gz']):\n",
    "                continue\n",
    "            for pattern, key in token_map.items():\n",
    "                if re.search(pattern, f.name):\n",
    "                    entry[key] = str(f)\n",
    "                    break\n",
    "        if entry:\n",
    "            index[case_dir.name] = entry\n",
    "            missing = set(token_map.values()) - set(entry.keys())\n",
    "            if missing:\n",
    "                print(f\"[WARN] {case_dir.name} missing: {sorted(missing)}\")\n",
    "    return index\n",
    "\n",
    "def list_met_available(dataset_root: str, case_id: str):\n",
    "    idx = build_met_index(dataset_root)\n",
    "    if case_id not in idx:\n",
    "        print(f\"[ERROR] Case not found: {case_id}\")\n",
    "        print(\"Available cases (first 20):\")\n",
    "        for k in list(idx.keys())[:20]:\n",
    "            print(\" -\", k)\n",
    "        return\n",
    "    print(case_id, \"\", sorted(idx[case_id].keys()))\n",
    "    for k, v in idx[case_id].items():\n",
    "        print(f\" - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2) Mask analysis ----------\n",
    "def analyze_mask_file(mask_path: str, print_values_limit: int = 20):\n",
    "    p = Path(mask_path)\n",
    "    if not p.is_file():\n",
    "        raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "    img = nib.load(str(p))\n",
    "    arr = np.asanyarray(img.dataobj)  # on-disk dtype\n",
    "\n",
    "    print(f\"File: {p.name}\")\n",
    "    print(f\"Shape: {arr.shape}\")\n",
    "    print(f\"On-disk dtype: {arr.dtype}\")\n",
    "    data_min, data_max = float(arr.min()), float(arr.max())\n",
    "    nonzero = int((arr != 0).sum())\n",
    "    print(f\"Value range: [{data_min}, {data_max}]\")\n",
    "    print(f\"Non-zero voxels: {nonzero} ({nonzero/arr.size:.4%})\")\n",
    "\n",
    "    if arr.ndim == 4:\n",
    "        print(\"Note: 4D mask detected (channels). First channel preview will be used for quick display.\")\n",
    "\n",
    "    if arr.dtype.kind in (\"i\", \"u\"):\n",
    "        uniq = np.unique(arr)\n",
    "        print(f\"Unique integer values ({len(uniq)}): {uniq[:print_values_limit]}\")\n",
    "        if len(uniq) > print_values_limit:\n",
    "            print(\"... (truncated)\")\n",
    "        if set(uniq).issubset({0, 1}):\n",
    "            print(\"Mask type: Binary (0 background, 1 lesion)\")\n",
    "        else:\n",
    "            print(\"Mask type: Multi-class (labels > 1 present)\")\n",
    "    else:\n",
    "        is_int_like = np.isclose(arr, np.round(arr), atol=1e-3).mean()\n",
    "        print(f\"Float mask: {is_int_like:.2%} voxels are ~integers.\")\n",
    "        if is_int_like > 0.999:\n",
    "            uniq = np.unique(np.round(arr).astype(np.int32))\n",
    "            print(f\"Rounded unique values: {uniq}\")\n",
    "            if set(uniq).issubset({0, 1}):\n",
    "                print(\"Mask type (rounded): Binary\")\n",
    "            else:\n",
    "                print(\"Mask type (rounded): Multi-class\")\n",
    "        else:\n",
    "            print(\"Mask appears continuous/probabilistic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12de40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3) Single slice viewer (MRI + overlay vs MRI only) ----------\n",
    "def show_met_slice_with_and_without_mask(\n",
    "    dataset_root: str,\n",
    "    case_id: str,\n",
    "    modality: str = \"t1c\",       # 't1c','t1n','t2w','t2f'\n",
    "    slice_no: int | None = None, # None  middle slice\n",
    "    overlay_multiclass: bool = True,\n",
    "    mask_alpha: float = 0.4,\n",
    "    strict: bool = False,\n",
    ") -> bool:\n",
    "    idx = build_met_index(dataset_root)\n",
    "    if case_id not in idx:\n",
    "        msg = f\"Case not found: {case_id}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg)\n",
    "        list_met_available(dataset_root, case_id)\n",
    "        return False\n",
    "    entry = idx[case_id]\n",
    "    required = [modality.lower(), \"seg\"]\n",
    "    for key in required:\n",
    "        if key not in entry:\n",
    "            msg = f\"Missing '{key}' for {case_id}\"\n",
    "            if strict: raise ValueError(msg)\n",
    "            print(\"[WARN]\", msg)\n",
    "            list_met_available(dataset_root, case_id)\n",
    "            return False\n",
    "\n",
    "    img = nib.load(entry[modality.lower()]).get_fdata(dtype=np.float32)\n",
    "    msk = nib.load(entry[\"seg\"]).get_fdata(dtype=np.float32)\n",
    "\n",
    "    # Keep orientation consistent with earlier code\n",
    "    img = np.rot90(img)\n",
    "    msk = np.rot90(msk)\n",
    "\n",
    "    # Handle 4D mask by picking first channel if present\n",
    "    if msk.ndim == 4:\n",
    "        msk = msk[..., 0]\n",
    "\n",
    "    assert img.ndim == 3 and msk.ndim == 3, f\"Expected 3D volumes, got {img.shape}, {msk.shape}\"\n",
    "\n",
    "    depth = img.shape[0]\n",
    "    used_slice = depth // 2 if slice_no is None else max(0, min(slice_no, depth - 1))\n",
    "\n",
    "    mri_slice = img[used_slice]\n",
    "    mask_slice = msk[used_slice]\n",
    "\n",
    "    # Normalize MRI for display\n",
    "    mn, mx = mri_slice.min(), mri_slice.max()\n",
    "    mri_disp = (mri_slice - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(mri_slice)\n",
    "\n",
    "    nonzero = (mask_slice > 0).astype(np.float32)\n",
    "    alpha = nonzero * mask_alpha\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    title = f\"{case_id} | {modality.upper()} | z={used_slice}\"\n",
    "\n",
    "    axes[0].imshow(mri_disp, cmap=\"gray\")\n",
    "    axes[0].set_title(title)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(mri_disp, cmap=\"gray\")\n",
    "    if overlay_multiclass:\n",
    "        axes[1].imshow(mask_slice, cmap=\"nipy_spectral\", alpha=alpha)\n",
    "    else:\n",
    "        axes[1].imshow(nonzero, cmap=\"Reds\", alpha=alpha)\n",
    "    axes[1].set_title(\"Overlay\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_met_grids(\n",
    "    dataset_root: str,\n",
    "    case_id: str,\n",
    "    modality: str = \"t1c\",\n",
    "    total_slices: int = 36,  # 6x6\n",
    "):\n",
    "    idx = build_met_index(dataset_root)\n",
    "    assert case_id in idx, f\"{case_id} not found\"\n",
    "    entry = idx[case_id]\n",
    "    assert modality in entry and \"seg\" in entry, f\"Need {modality} and seg for {case_id}\"\n",
    "\n",
    "    img = nib.load(entry[modality]).get_fdata(dtype=np.float32)\n",
    "    msk = nib.load(entry[\"seg\"]).get_fdata(dtype=np.float32)\n",
    "\n",
    "    img = np.rot90(img)\n",
    "    msk = np.rot90(msk)\n",
    "    if msk.ndim == 4:\n",
    "        msk = msk[..., 0]\n",
    "\n",
    "    depth = img.shape[0]\n",
    "    z_indices = np.linspace(0, depth - 1, min(total_slices, depth), dtype=int)\n",
    "\n",
    "    pairs = []\n",
    "    for z in z_indices:\n",
    "        mri_slice = img[z]\n",
    "        mn, mx = mri_slice.min(), mri_slice.max()\n",
    "        mri_disp = (mri_slice - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(mri_slice)\n",
    "        mask_slice = msk[z]\n",
    "        pairs.append((mri_disp, mask_slice, z))\n",
    "\n",
    "    rows, cols = 6, 6\n",
    "    # MRI grid\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(14, 14))\n",
    "    for i in range(rows * cols):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        if i < len(pairs):\n",
    "            mri_disp, _, z = pairs[i]\n",
    "            ax.imshow(mri_disp, cmap=\"gray\")\n",
    "            ax.set_title(f\"z={z}\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"{case_id} - {modality.upper()} | MRI (6x6)\", y=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Mask grid\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(14, 14))\n",
    "    for i in range(rows * cols):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        if i < len(pairs):\n",
    "            _, mask_slice, z = pairs[i]\n",
    "            ax.imshow(mask_slice, cmap=\"nipy_spectral\", interpolation=\"nearest\")\n",
    "            ax.set_title(f\"z={z}\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"{case_id} - seg | Mask (6x6)\", y=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ccd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_root = \"/Users/chufal/projects/Datasets/PKG-Pretreat-MetsToBrain-Masks/Pretreat-MetsToBrain-Masks\"\n",
    "case = \"BraTS-MET-00248-000\"\n",
    "\n",
    "# Whats present\n",
    "list_met_available(met_root, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask properties\n",
    "idx = build_met_index(met_root)\n",
    "analyze_mask_file(idx[case][\"seg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One slice, side-by-side\n",
    "show_met_slice_with_and_without_mask(\n",
    "    dataset_root=met_root,\n",
    "    case_id=case,\n",
    "    modality=\"t2f\",     # or 't1n','t2w','t2f'\n",
    "    slice_no=150,        # or None for middle\n",
    "    overlay_multiclass=True,\n",
    "    mask_alpha=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6x6 grids (MRI + mask)\n",
    "plot_met_grids(met_root, case, modality=\"t1c\", total_slices=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ce5ca",
   "metadata": {},
   "source": [
    "# Breast Radiogenomics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume_as_DHW(path: str, rotate_k: int = 1):\n",
    "    \"\"\"\n",
    "    Load a 3D NIfTI volume and return as (D, H, W).\n",
    "    - Assumes file data is (H, W, D) on disk (common case).\n",
    "    - rotate_k applies np.rot90 k times over (H, W) for consistent view.\n",
    "    \"\"\"\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D volume, got {vol.shape}\")\n",
    "    vol = np.transpose(vol, (2, 0, 1))          # (H,W,D) -> (D,H,W)\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1, 2))  # rotate over (H,W)\n",
    "    return vol\n",
    "\n",
    "\n",
    "def build_bcbm_index(dataset_root: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        'BCBM-RadioGenomics-0-0': {\n",
    "          'image': '/path/..._image_ss_n4.nii.gz',\n",
    "          'masks': {\n",
    "             'bst': '/path/..._mask_bst.nii.gz',\n",
    "             'R-sylvian-tumor': '/path/..._mask_R-sylvian-tumor.nii.gz',\n",
    "             ...\n",
    "          }\n",
    "        },\n",
    "        ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    root = Path(dataset_root)\n",
    "    assert root.is_dir(), f\"{dataset_root} not found\"\n",
    "\n",
    "    # If the given root has a single child dir with the real cases, descend into it\n",
    "    children = [d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n",
    "    if len(children) == 1 and any((children[0] / \"dummy\").parent.exists() for _ in [0]):\n",
    "        # Heuristic: dataset_root points to the outer folder, descend to inner folder\n",
    "        inner = children[0]\n",
    "        if any((p.is_dir() for p in inner.iterdir())):\n",
    "            root = inner\n",
    "\n",
    "    index = {}\n",
    "    for case_dir in sorted([d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]):\n",
    "        image_path = None\n",
    "        masks = {}\n",
    "        for f in case_dir.iterdir():\n",
    "            if not (f.is_file() and f.suffixes == ['.nii', '.gz']):\n",
    "                continue\n",
    "            name = f.name\n",
    "            if name.endswith(\"_image_ss_n4.nii.gz\"):\n",
    "                image_path = str(f)\n",
    "            elif \"_mask_\" in name:\n",
    "                # Extract mask key after \"_mask_\"\n",
    "                key = name.split(\"_mask_\", 1)[1].replace(\".nii.gz\", \"\")\n",
    "                masks[key] = str(f)\n",
    "        if image_path:\n",
    "            index[case_dir.name] = {\"image\": image_path, \"masks\": masks}\n",
    "            missing_note = \"\" if masks else \" [WARN: no masks found]\"\n",
    "            if missing_note:\n",
    "                print(f\"[WARN] {case_dir.name}: no masks found\")\n",
    "    return index\n",
    "\n",
    "def list_bcbm_available(dataset_root: str, case_id: str):\n",
    "    idx = build_bcbm_index(dataset_root)\n",
    "    if case_id not in idx:\n",
    "        print(f\"[ERROR] Case not found: {case_id}\")\n",
    "        print(\"Available cases (first 20):\")\n",
    "        for k in list(idx.keys())[:20]:\n",
    "            print(\" -\", k)\n",
    "        return\n",
    "    entry = idx[case_id]\n",
    "    print(case_id)\n",
    "    print(\" image:\", entry.get(\"image\"))\n",
    "    print(\" masks:\", sorted(entry.get(\"masks\", {}).keys())[:50])\n",
    "\n",
    "# ---------- 2) Mask analysis (reused) ----------\n",
    "def analyze_mask_file(mask_path: str, print_values_limit: int = 20):\n",
    "    p = Path(mask_path)\n",
    "    if not p.is_file():\n",
    "        raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "    img = nib.load(str(p))\n",
    "    arr = np.asanyarray(img.dataobj)\n",
    "    print(f\"File: {p.name}\")\n",
    "    print(f\"Shape: {arr.shape}\")\n",
    "    print(f\"On-disk dtype: {arr.dtype}\")\n",
    "    data_min, data_max = float(arr.min()), float(arr.max())\n",
    "    nonzero = int((arr != 0).sum())\n",
    "    print(f\"Value range: [{data_min}, {data_max}]\")\n",
    "    print(f\"Non-zero voxels: {nonzero} ({nonzero/arr.size:.4%})\")\n",
    "    if arr.ndim == 4:\n",
    "        print(\"Note: 4D mask detected (channels).\")\n",
    "    if arr.dtype.kind in (\"i\", \"u\"):\n",
    "        uniq = np.unique(arr)\n",
    "        print(f\"Unique integer values ({len(uniq)}): {uniq[:print_values_limit]}\")\n",
    "        if set(uniq).issubset({0, 1}):\n",
    "            print(\"Mask type: Binary\")\n",
    "        else:\n",
    "            print(\"Mask type: Multi-class\")\n",
    "    else:\n",
    "        frac_int_like = np.isclose(arr, np.round(arr), atol=1e-3).mean()\n",
    "        print(f\"Float mask: {frac_int_like:.2%} voxels ~integers\")\n",
    "        if frac_int_like > 0.999:\n",
    "            uniq = np.unique(np.round(arr).astype(np.int32))\n",
    "            print(f\"Rounded uniques: {uniq}\")\n",
    "            if set(uniq).issubset({0, 1}): print(\"Mask (rounded): Binary\")\n",
    "            else: print(\"Mask (rounded): Multi-class\")\n",
    "        else:\n",
    "            print(\"Mask appears continuous/probabilistic.\")\n",
    "\n",
    "# ---------- 3) Single-slice viewer (MRI vs MRI+mask overlay) ----------\n",
    "def show_bcbm_slice_with_and_without_mask(\n",
    "    dataset_root: str,\n",
    "    case_id: str,\n",
    "    slice_no: int | None = None,   # None  middle slice\n",
    "    mask: str | list[str] = \"union\",  # \"union\" | \"multiclass\" | specific mask key or list of keys\n",
    "    mask_alpha: float = 0.4,\n",
    "    strict: bool = False,\n",
    ") -> bool:\n",
    "    idx = build_bcbm_index(dataset_root)\n",
    "    if case_id not in idx:\n",
    "        msg = f\"Case not found: {case_id}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg); list_bcbm_available(dataset_root, case_id); return False\n",
    "\n",
    "    entry = idx[case_id]\n",
    "    img = nib.load(entry[\"image\"]).get_fdata(dtype=np.float32)\n",
    "    img = np.rot90(img)\n",
    "    if img.ndim != 3:\n",
    "        msg = f\"Image must be 3D, got {img.shape}\"\n",
    "        if strict: raise ValueError(msg)\n",
    "        print(\"[ERROR]\", msg); return False\n",
    "\n",
    "    # Build mask volume as requested\n",
    "    masks = entry.get(\"masks\", {})\n",
    "    if not masks:\n",
    "        print(\"[WARN] No masks for this case; showing MRI only.\")\n",
    "        msk_vol = np.zeros_like(img)\n",
    "    else:\n",
    "        if mask == \"union\":\n",
    "            msk_vol = np.zeros_like(img, dtype=np.uint8)\n",
    "            for k, p in masks.items():\n",
    "                a = nib.load(p).get_fdata(dtype=np.float32)\n",
    "                a = np.rot90(a)\n",
    "                msk_vol |= (a > 0).astype(np.uint8)\n",
    "        elif mask == \"multiclass\":\n",
    "            msk_vol = np.zeros_like(img, dtype=np.int16)\n",
    "            for label_idx, (k, p) in enumerate(sorted(masks.items()), start=1):\n",
    "                a = nib.load(p).get_fdata(dtype=np.float32)\n",
    "                a = np.rot90(a)\n",
    "                msk_vol[a > 0] = label_idx\n",
    "        else:\n",
    "            keys = [mask] if isinstance(mask, str) else list(mask)\n",
    "            msk_vol = np.zeros_like(img, dtype=np.uint8)\n",
    "            missing = []\n",
    "            for k in keys:\n",
    "                if k not in masks:\n",
    "                    missing.append(k); continue\n",
    "                a = nib.load(masks[k]).get_fdata(dtype=np.float32)\n",
    "                a = np.rot90(a)\n",
    "                msk_vol |= (a > 0).astype(np.uint8)\n",
    "            if missing:\n",
    "                print(f\"[WARN] Missing mask keys: {missing}\")\n",
    "\n",
    "    depth = img.shape[2]\n",
    "    used_slice = depth // 2 if slice_no is None else max(0, min(slice_no, depth - 1))\n",
    "\n",
    "    mri_slice = img[used_slice]\n",
    "    mn, mx = mri_slice.min(), mri_slice.max()\n",
    "    mri_disp = (mri_slice - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(mri_slice)\n",
    "    mask_slice = msk_vol[used_slice]\n",
    "\n",
    "    nonzero = (mask_slice > 0).astype(np.float32)\n",
    "    alpha = nonzero * mask_alpha\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    title = f\"{case_id} | z={used_slice}\"\n",
    "    axes[0].imshow(mri_disp, cmap=\"gray\"); axes[0].set_aspect(\"equal\"); axes[0].set_title(title); axes[0].axis(\"off\")\n",
    "    axes[1].imshow(mri_disp, cmap=\"gray\")\n",
    "    cmap = \"nipy_spectral\" if (mask == \"multiclass\") else \"Reds\"\n",
    "    axes[1].imshow(mask_slice, cmap=cmap, alpha=alpha)\n",
    "    axes[1].set_title(f\"Overlay ({mask})\"); axes[1].set_aspect(\"equal\"); axes[1].axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "    return True\n",
    "\n",
    "\n",
    "def plot_bcbm_grids(\n",
    "    dataset_root: str,\n",
    "    case_id: str,\n",
    "    total_slices: int = 36,     # 6x6\n",
    "    mask: str | list[str] = \"union\",  # \"union\" | \"multiclass\" | specific key or list\n",
    "):\n",
    "    idx = build_bcbm_index(dataset_root)\n",
    "    assert case_id in idx, f\"{case_id} not found\"\n",
    "    entry = idx[case_id]\n",
    "\n",
    "    img = nib.load(entry[\"image\"]).get_fdata(dtype=np.float32)\n",
    "    img = np.rot90(img)\n",
    "\n",
    "    # Build mask volume similarly to single-slice\n",
    "    masks = entry.get(\"masks\", {})\n",
    "    if not masks:\n",
    "        msk_vol = np.zeros_like(img)\n",
    "    else:\n",
    "        if mask == \"union\":\n",
    "            msk_vol = np.zeros_like(img, dtype=np.uint8)\n",
    "            for _, p in masks.items():\n",
    "                a = nib.load(p).get_fdata(dtype=np.float32)\n",
    "                a = np.rot90(a)\n",
    "                msk_vol |= (a > 0).astype(np.uint8)\n",
    "        elif mask == \"multiclass\":\n",
    "            msk_vol = np.zeros_like(img, dtype=np.int16)\n",
    "            for label_idx, (_, p) in enumerate(sorted(masks.items()), start=1):\n",
    "                a = nib.load(p).get_fdata(dtype=np.float32)\n",
    "                a = np.rot90(a)\n",
    "                msk_vol[a > 0] = label_idx\n",
    "        else:\n",
    "            keys = [mask] if isinstance(mask, str) else list(mask)\n",
    "            msk_vol = np.zeros_like(img, dtype=np.uint8)\n",
    "            for k in keys:\n",
    "                if k not in masks: \n",
    "                    print(f\"[WARN] Missing mask key: {k}\"); continue\n",
    "                a = nib.load(masks[k]).get_fdata(dtype=np.float32)\n",
    "                a = np.rot90(a)\n",
    "                msk_vol |= (a > 0).astype(np.uint8)\n",
    "\n",
    "    depth = img.shape[2]\n",
    "    z_indices = np.linspace(0, depth - 1, min(total_slices, depth), dtype=int)\n",
    "\n",
    "    pairs = []\n",
    "    for z in z_indices:\n",
    "        mri_slice = img[z]\n",
    "        mn, mx = mri_slice.min(), mri_slice.max()\n",
    "        mri_disp = (mri_slice - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(mri_slice)\n",
    "        mask_slice = msk_vol[z]\n",
    "        pairs.append((mri_disp, mask_slice, z))\n",
    "\n",
    "    rows, cols = 6, 6\n",
    "    # MRI grid\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "    for i in range(rows * cols):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        if i < len(pairs):\n",
    "            mri_disp, _, z = pairs[i]\n",
    "            ax.imshow(mri_disp, cmap=\"gray\"); ax.set_title(f\"z={z}\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"{case_id} | MRI (6x6)\", y=1)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Overlay grid\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "    for i in range(rows * cols):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        if i < len(pairs):\n",
    "            mri_disp, mask_slice, z = pairs[i]\n",
    "            ax.imshow(mri_disp, cmap=\"gray\")\n",
    "            cmap = \"nipy_spectral\" if (mask == \"multiclass\") else \"Reds\"\n",
    "            # alpha = (mask_slice > 0).astype(np.float32) * 0.4\n",
    "            alpha = 0.8\n",
    "            ax.imshow(mask_slice, cmap=cmap, alpha=alpha)\n",
    "            ax.set_title(f\"z={z}\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"{case_id} | Overlay ({mask}) (6x6)\", y=1)\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcbm_root = \"/Users/chufal/projects/Datasets/PKG-BCBM-RadioGenomics_Images_Masks_Dec2024/BCBM-RadioGenomics_Images_Masks_Dec2024\"\n",
    "case = \"BCBM-RadioGenomics-0-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f3765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whats present\n",
    "list_bcbm_available(bcbm_root, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32932e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze one of the masks\n",
    "idx = build_bcbm_index(bcbm_root)\n",
    "analyze_mask_file(idx[case][\"masks\"][\"R-lat-cerebellar-tumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One slice, MRI vs overlay (union of all masks)\n",
    "show_bcbm_slice_with_and_without_mask(bcbm_root, case, slice_no=350, mask=\"union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30481c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One slice, multiclass overlay (each mask  a color)\n",
    "show_bcbm_slice_with_and_without_mask(bcbm_root, case, slice_no=350, mask=\"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403593ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6x6 grids\n",
    "plot_bcbm_grids(bcbm_root, case, total_slices=36, mask=\"multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c614694a",
   "metadata": {},
   "source": [
    "## Analysing Mask Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any 3D/4D NIfTI as (D,H,W); 4D -> first channel\n",
    "def load_volume_as_DHW(path: str, rotate_k: int = 1):\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim == 4:\n",
    "        vol = vol[..., 0]\n",
    "    if vol.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D volume, got {vol.shape} for {path}\")\n",
    "    # assume on-disk (H,W,D) -> (D,H,W)\n",
    "    vol = np.transpose(vol, (2, 0, 1))\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1, 2))\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92989c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build index for BCBM dataset: case -> image + multiple masks\n",
    "def build_bcbm_index(dataset_root: str) -> dict:\n",
    "    root = Path(dataset_root)\n",
    "    if not root.is_dir():\n",
    "        raise FileNotFoundError(f\"Dataset root not found: {dataset_root}\")\n",
    "    # If the given root contains a single child folder that holds cases, descend\n",
    "    children = [d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n",
    "    if len(children) == 1 and any((c.name.startswith(\"BCBM-RadioGenomics-\") for c in children[0].iterdir() if c.is_dir())):\n",
    "        root = children[0]\n",
    "\n",
    "    index = {}\n",
    "    for case_dir in sorted([d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]):\n",
    "        image_path = None\n",
    "        masks = {}\n",
    "        for f in case_dir.iterdir():\n",
    "            if not (f.is_file() and f.suffixes == ['.nii', '.gz']):\n",
    "                continue\n",
    "            name = f.name\n",
    "            if name.endswith(\"_image_ss_n4.nii.gz\"):\n",
    "                image_path = str(f)\n",
    "            elif \"_mask_\" in name:\n",
    "                key = name.split(\"_mask_\", 1)[1].replace(\".nii.gz\", \"\")\n",
    "                masks[key] = str(f)\n",
    "        if image_path or masks:\n",
    "            index[case_dir.name] = {\"image\": image_path, \"masks\": masks}\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289963d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize masks: non-zero voxels, best slice by area, etc.\n",
    "def summarize_case_masks(dataset_root: str, case_id: str):\n",
    "    idx = build_bcbm_index(dataset_root)\n",
    "    if case_id not in idx:\n",
    "        raise ValueError(f\"Case not found: {case_id}\")\n",
    "    masks = idx[case_id].get(\"masks\", {})\n",
    "    summaries = []\n",
    "    for key, path in sorted(masks.items()):\n",
    "        vol = load_volume_as_DHW(path)\n",
    "        nz = (vol > 0)\n",
    "        nz_voxels = int(nz.sum())\n",
    "        depth = vol.shape[0]\n",
    "        if nz_voxels > 0:\n",
    "            per_z = nz.reshape(depth, -1).sum(axis=1)\n",
    "            best_z = int(per_z.argmax())\n",
    "            nz_slices = int((per_z > 0).sum())\n",
    "        else:\n",
    "            best_z = None\n",
    "            nz_slices = 0\n",
    "        summaries.append({\n",
    "            \"mask_key\": key,\n",
    "            \"path\": path,\n",
    "            \"depth\": depth,\n",
    "            \"nonzero_voxels\": nz_voxels,\n",
    "            \"nonzero_fraction\": float(nz_voxels) / float(vol.size),\n",
    "            \"nonzero_slices\": nz_slices,\n",
    "            \"best_slice\": best_z,\n",
    "        })\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid plot: masks only, each at its best slice\n",
    "def plot_masks_best_slices(dataset_root: str, case_id: str, max_masks: int = 36, cols: int = 6, cmap=\"Reds\"):\n",
    "    summaries = summarize_case_masks(dataset_root, case_id)\n",
    "    nonempty = [s for s in summaries if s[\"nonzero_voxels\"] > 0]\n",
    "    if not nonempty:\n",
    "        print(f\"No non-empty masks for {case_id}.\")\n",
    "        return\n",
    "    nonempty = nonempty[:max_masks]\n",
    "    rows = ceil(len(nonempty) / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(2.8 * cols, 2.8 * rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "    for i, s in enumerate(nonempty):\n",
    "        vol = load_volume_as_DHW(s[\"path\"])\n",
    "        z = s[\"best_slice\"]\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        ax.imshow(vol[z], cmap=cmap, interpolation=\"nearest\")\n",
    "        ax.set_aspect(\"equal\"); ax.axis(\"off\")\n",
    "        ax.set_title(f\"{s['mask_key']}\\nz={z}\", fontsize=8)\n",
    "    # Hide any unused subplots\n",
    "    for j in range(len(nonempty), rows * cols):\n",
    "        ax = axes[j // cols, j % cols]\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"{case_id} - masks (best slices)\", y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20181ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single mask viewer: choose slice manually or use best slice\n",
    "def show_single_mask(dataset_root: str, case_id: str, mask_key: str, slice_no: int | None = None, cmap=\"Reds\"):\n",
    "    idx = build_bcbm_index(dataset_root)\n",
    "    entry = idx.get(case_id)\n",
    "    if not entry or mask_key not in entry.get(\"masks\", {}):\n",
    "        raise ValueError(f\"Mask '{mask_key}' not found for {case_id}\")\n",
    "    vol = load_volume_as_DHW(entry[\"masks\"][mask_key])\n",
    "    nz = (vol > 0).reshape(vol.shape[0], -1).sum(axis=1)\n",
    "    z = int(nz.argmax()) if slice_no is None else max(0, min(slice_no, vol.shape[0]-1))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(vol[z], cmap=cmap, interpolation=\"nearest\")\n",
    "    plt.gca().set_aspect(\"equal\"); plt.axis(\"off\")\n",
    "    plt.title(f\"{case_id} | {mask_key} | z={z}\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcbm_root = \"/Users/chufal/projects/Datasets/PKG-BCBM-RadioGenomics_Images_Masks_Dec2024/BCBM-RadioGenomics_Images_Masks_Dec2024\"\n",
    "case = \"BCBM-RadioGenomics-0-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Text summary of masks with non-zero info\n",
    "for s in summarize_case_masks(bcbm_root, case):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Grid of masks (best slice per mask), no MRI overlays\n",
    "plot_masks_best_slices(bcbm_root, case, max_masks=36, cols=6, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Inspect a specific mask (auto-picks slice with max area)\n",
    "show_single_mask(bcbm_root, case, mask_key=\"R-sylvian-tumor\")  # or any other key from the summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e403f",
   "metadata": {},
   "source": [
    "# UCSF-PDGM-v5 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume_as_DHW(path: str, rotate_k: int = 1):\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim == 4:\n",
    "        vol = vol[..., 0]\n",
    "    if vol.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D, got {vol.shape} for {path}\")\n",
    "    # assume on-disk (H,W,D) -> (D,H,W)\n",
    "    vol = np.transpose(vol, (2, 0, 1))\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1, 2))\n",
    "    return vol\n",
    "\n",
    "def choose_best_lesion_slice(seg_vol: np.ndarray) -> int | None:\n",
    "    # seg_vol is (D,H,W); returns z with max lesion area or None if empty\n",
    "    nz_per_z = (seg_vol > 0).reshape(seg_vol.shape[0], -1).sum(axis=1)\n",
    "    if nz_per_z.max() == 0:\n",
    "        return None\n",
    "    return int(nz_per_z.argmax())\n",
    "\n",
    "def coef_of_variation(vol: np.ndarray, mask: np.ndarray | None) -> float | None:\n",
    "    # CV within mask; returns None if mask invalid\n",
    "    if mask is None:\n",
    "        return None\n",
    "    vox = vol[mask > 0]\n",
    "    vox = vox[np.isfinite(vox)]\n",
    "    if vox.size < 100:\n",
    "        return None\n",
    "    m = float(vox.mean())\n",
    "    s = float(vox.std())\n",
    "    if m == 0:\n",
    "        return None\n",
    "    return s / m\n",
    "\n",
    "# ---------- 1) Indexer for UCSF-PDGM-v5 ----------\n",
    "# dataset_root can be either \".../PKG - UCSF-PDGM Version 5/UCSF-PDGM-v5\"\n",
    "# or the parent \".../PKG - UCSF-PDGM Version 5\" (the function will descend).\n",
    "def build_ucsf_pdgm_index(dataset_root: str) -> dict:\n",
    "    root = Path(dataset_root)\n",
    "    if not root.is_dir():\n",
    "        raise FileNotFoundError(f\"Dataset root not found: {dataset_root}\")\n",
    "    # Descend if parent folder was given\n",
    "    if (root / \"UCSF-PDGM-v5\").is_dir():\n",
    "        root = root / \"UCSF-PDGM-v5\"\n",
    "\n",
    "    patterns = {\n",
    "        r\"_T1\\.nii\\.gz$\": \"T1\",\n",
    "        r\"_T1_bias\\.nii\\.gz$\": \"T1_bias\",\n",
    "        r\"_T1c\\.nii\\.gz$\": \"T1c\",\n",
    "        r\"_T1c_bias\\.nii\\.gz$\": \"T1c_bias\",\n",
    "        r\"_T2\\.nii\\.gz$\": \"T2\",\n",
    "        r\"_T2_bias\\.nii\\.gz$\": \"T2_bias\",\n",
    "        r\"_FLAIR\\.nii\\.gz$\": \"FLAIR\",\n",
    "        r\"_FLAIR_bias\\.nii\\.gz$\": \"FLAIR_bias\",\n",
    "        r\"_tumor_segmentation\\.nii\\.gz$\": \"tumor_seg\",\n",
    "        r\"_brain_segmentation\\.nii\\.gz$\": \"brain_seg\",\n",
    "        r\"_brain_parenchyma_segmentation\\.nii\\.gz$\": \"brain_parenchyma_seg\",\n",
    "        # other modalities (optional)\n",
    "        r\"_ADC\\.nii\\.gz$\": \"ADC\",\n",
    "        r\"_DWI\\.nii\\.gz$\": \"DWI\",\n",
    "        r\"_SWI\\.nii\\.gz$\": \"SWI\",\n",
    "        r\"_ASL\\.nii\\.gz$\": \"ASL\",\n",
    "    }\n",
    "\n",
    "    index = {}\n",
    "    patient_dirs = [d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n",
    "    # typical patient dir name ends with \"_nifti\"\n",
    "    for pdir in sorted(patient_dirs):\n",
    "        entry = {}\n",
    "        for f in pdir.iterdir():\n",
    "            if not (f.is_file() and \"\".join(f.suffixes).endswith(\".nii.gz\")):\n",
    "                continue\n",
    "            fname = f.name\n",
    "            for pat, key in patterns.items():\n",
    "                if re.search(pat, fname):\n",
    "                    entry[key] = str(f)\n",
    "                    break\n",
    "        if entry:\n",
    "            index[pdir.name] = entry\n",
    "    return index\n",
    "\n",
    "# ---------- 2) Visual comparison helpers ----------\n",
    "def show_pair_with_overlay(vol_a: np.ndarray, vol_b: np.ndarray, seg: np.ndarray | None,\n",
    "                           title_a: str, title_b: str, z: int | None):\n",
    "    D = vol_a.shape[0]\n",
    "    z = D // 2 if z is None else max(0, min(z, D - 1))\n",
    "    seg_slice = None if seg is None else seg[z]\n",
    "    alpha = None if seg_slice is None else (seg_slice > 0).astype(np.float32) * 0.35\n",
    "\n",
    "    def normalize(img):\n",
    "        mn, mx = float(img.min()), float(img.max())\n",
    "        return (img - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(img)\n",
    "\n",
    "    a = normalize(vol_a[z])\n",
    "    b = normalize(vol_b[z])\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    # A without overlay\n",
    "    axes[0,0].imshow(a, cmap=\"gray\"); axes[0,0].set_aspect(\"equal\"); axes[0,0].axis(\"off\")\n",
    "    axes[0,0].set_title(title_a)\n",
    "    # A with overlay\n",
    "    axes[0,1].imshow(a, cmap=\"gray\")\n",
    "    if seg_slice is not None: axes[0,1].imshow(seg_slice, cmap=\"nipy_spectral\", alpha=alpha)\n",
    "    axes[0,1].set_aspect(\"equal\"); axes[0,1].axis(\"off\")\n",
    "    axes[0,1].set_title(f\"{title_a} + tumor\")\n",
    "\n",
    "    # B without overlay\n",
    "    axes[1,0].imshow(b, cmap=\"gray\"); axes[1,0].set_aspect(\"equal\"); axes[1,0].axis(\"off\")\n",
    "    axes[1,0].set_title(title_b)\n",
    "    # B with overlay\n",
    "    axes[1,1].imshow(b, cmap=\"gray\")\n",
    "    if seg_slice is not None: axes[1,1].imshow(seg_slice, cmap=\"nipy_spectral\", alpha=alpha)\n",
    "    axes[1,1].set_aspect(\"equal\"); axes[1,1].axis(\"off\")\n",
    "    axes[1,1].set_title(f\"{title_b} + tumor\")\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# ---------- 3) Main analyzer ----------\n",
    "def analyze_ucsf_pdgm_patient(dataset_root: str, patient_id: str, rotate_k: int = 1):\n",
    "    idx = build_ucsf_pdgm_index(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        raise ValueError(f\"Patient not found: {patient_id}\")\n",
    "    e = idx[patient_id]\n",
    "\n",
    "    # Load segmentation masks for metrics/slice selection\n",
    "    seg_tumor = load_volume_as_DHW(e[\"tumor_seg\"], rotate_k) if \"tumor_seg\" in e else None\n",
    "    brain_mask = None\n",
    "    if \"brain_parenchyma_seg\" in e:\n",
    "        brain_mask = (load_volume_as_DHW(e[\"brain_parenchyma_seg\"], rotate_k) > 0).astype(np.uint8)\n",
    "    elif \"brain_seg\" in e:\n",
    "        brain_mask = (load_volume_as_DHW(e[\"brain_seg\"], rotate_k) > 0).astype(np.uint8)\n",
    "\n",
    "    # Pick slice with max tumor if available\n",
    "    best_z = choose_best_lesion_slice(seg_tumor) if seg_tumor is not None else None\n",
    "\n",
    "    # Define modality pairs to compare\n",
    "    pairs = [\n",
    "        (\"T1\", \"T1_bias\"),\n",
    "        (\"T1c\", \"T1c_bias\"),\n",
    "        (\"T2\", \"T2_bias\"),\n",
    "        (\"FLAIR\", \"FLAIR_bias\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"=== {patient_id} ===\")\n",
    "    for a_key, b_key in pairs:\n",
    "        if a_key not in e and b_key not in e:\n",
    "            continue\n",
    "        vol_a = load_volume_as_DHW(e[a_key], rotate_k) if a_key in e else None\n",
    "        vol_b = load_volume_as_DHW(e[b_key], rotate_k) if b_key in e else None\n",
    "\n",
    "        # Shapes/dtypes\n",
    "        if vol_a is not None:\n",
    "            print(f\"{a_key}: shape={vol_a.shape}\")\n",
    "        if vol_b is not None:\n",
    "            print(f\"{b_key}: shape={vol_b.shape}\")\n",
    "\n",
    "        # CV metric inside brain mask\n",
    "        cv_a = coef_of_variation(vol_a, brain_mask) if (vol_a is not None and brain_mask is not None) else None\n",
    "        cv_b = coef_of_variation(vol_b, brain_mask) if (vol_b is not None and brain_mask is not None) else None\n",
    "\n",
    "        if cv_a is not None or cv_b is not None:\n",
    "            print(f\"CV {a_key}: {cv_a:.4f}\" if cv_a is not None else f\"CV {a_key}: NA\")\n",
    "            print(f\"CV {b_key}: {cv_b:.4f}\" if cv_b is not None else f\"CV {b_key}: NA\")\n",
    "            if cv_a is not None and cv_b is not None:\n",
    "                better = b_key if cv_b < cv_a else a_key\n",
    "                print(f\" Prefer: {better} (lower CV)\")\n",
    "        else:\n",
    "            print(\"CV: NA (no brain mask available)\")\n",
    "\n",
    "        # Visual comparison with tumor overlay (if available)\n",
    "        if vol_a is not None and vol_b is not None:\n",
    "            show_pair_with_overlay(vol_a, vol_b, seg_tumor, a_key, b_key, best_z)\n",
    "        elif vol_a is not None:\n",
    "            show_pair_with_overlay(vol_a, vol_a, seg_tumor, a_key, a_key, best_z)\n",
    "        elif vol_b is not None:\n",
    "            show_pair_with_overlay(vol_b, vol_b, seg_tumor, b_key, b_key, best_z)\n",
    "\n",
    "    # Return a small dict summary for programmatic use\n",
    "    return {\n",
    "        \"patient\": patient_id,\n",
    "        \"has_tumor_seg\": seg_tumor is not None,\n",
    "        \"has_brain_mask\": brain_mask is not None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucsf_root = \"/Users/chufal/projects/Datasets/PKG - UCSF-PDGM Version 5/UCSF-PDGM-v5\"\n",
    "analyze_ucsf_pdgm_patient(ucsf_root, \"UCSF-PDGM-0004_nifti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e9392",
   "metadata": {},
   "source": [
    "# UCSD PTGBM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ae5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- I/O helpers ----------\n",
    "def load_volume_as_DHW(path: str, rotate_k: int = 1):\n",
    "    \"\"\"Load NIfTI as (D,H,W). If 4D, take first channel. Rotate in-plane k times for consistent view.\"\"\"\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim == 4:\n",
    "        vol = vol[..., 0]\n",
    "    if vol.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D, got {vol.shape} for {path}\")\n",
    "    vol = np.transpose(vol, (2, 0, 1))  # (H,W,D)->(D,H,W)\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1, 2))\n",
    "    return vol\n",
    "\n",
    "def normalize01(img: np.ndarray):\n",
    "    mn, mx = float(img.min()), float(img.max())\n",
    "    return (img - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(img)\n",
    "\n",
    "# ---------- Indexer for UCSD-PTGBM ----------\n",
    "# dataset_root should point to \".../PKG-UCSD-PTGBM-v1/UCSD-PTGBM\"\n",
    "def build_ucsd_ptgbm_index(dataset_root: str) -> dict:\n",
    "    root = Path(dataset_root)\n",
    "    if not root.is_dir():\n",
    "        raise FileNotFoundError(f\"Dataset root not found: {dataset_root}\")\n",
    "\n",
    "    patterns = {\n",
    "        r\"_T1pre\\.nii\\.gz$\": \"T1pre\",\n",
    "        r\"_T1post\\.nii\\.gz$\": \"T1post\",\n",
    "        r\"_T2\\.nii\\.gz$\": \"T2\",\n",
    "        r\"_FLAIR\\.nii\\.gz$\": \"FLAIR\",\n",
    "        # segmentations\n",
    "        r\"_enhancing_cellular_tumor_seg\\.nii\\.gz$\": \"seg_enhancing\",\n",
    "        r\"_non_enhancing_cellular_tumor_seg\\.nii\\.gz$\": \"seg_nonenhancing\",\n",
    "        r\"_total_cellular_tumor_seg\\.nii\\.gz$\": \"seg_total\",\n",
    "        r\"_BraTS_tumor_seg\\.nii\\.gz$\": \"seg_brats\",\n",
    "    }\n",
    "\n",
    "    index = {}\n",
    "    for pdir in sorted([d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]):\n",
    "        entry = {}\n",
    "        for f in pdir.iterdir():\n",
    "            if not (f.is_file() and \"\".join(f.suffixes).endswith(\".nii.gz\")):\n",
    "                continue\n",
    "            fname = f.name\n",
    "            for pat, key in patterns.items():\n",
    "                if re.search(pat, fname):\n",
    "                    entry[key] = str(f)\n",
    "                    break\n",
    "        if entry:\n",
    "            index[pdir.name] = entry\n",
    "    return index\n",
    "\n",
    "def list_ucsd_available(dataset_root: str, patient_id: str):\n",
    "    idx = build_ucsd_ptgbm_index(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        print(f\"[ERROR] Patient not found: {patient_id}\")\n",
    "        print(\"Available (first 20):\")\n",
    "        for k in list(idx.keys())[:20]:\n",
    "            print(\" -\", k)\n",
    "        return\n",
    "    print(patient_id, \"\", sorted(idx[patient_id].keys()))\n",
    "    for k, v in sorted(idx[patient_id].items()):\n",
    "        print(f\" - {k}: {v}\")\n",
    "\n",
    "# ---------- Metrics and slice selection ----------\n",
    "def choose_best_lesion_slice(seg_union: np.ndarray | None) -> int | None:\n",
    "    if seg_union is None:\n",
    "        return None\n",
    "    nz_per_z = (seg_union > 0).reshape(seg_union.shape[0], -1).sum(axis=1)\n",
    "    if nz_per_z.max() == 0:\n",
    "        return None\n",
    "    return int(nz_per_z.argmax())\n",
    "\n",
    "def robust_cv(vol: np.ndarray) -> float | None:\n",
    "    \"\"\"Compute CV inside a robust intensity mask (exclude zeros and extremes).\"\"\"\n",
    "    vox = vol[np.isfinite(vol)]\n",
    "    if vox.size < 100:\n",
    "        return None\n",
    "    lo, hi = np.percentile(vox, [5, 99.5])\n",
    "    brain_like = (vol > lo) & (vol < hi)\n",
    "    sel = vol[brain_like]\n",
    "    if sel.size < 100:\n",
    "        return None\n",
    "    m, s = float(sel.mean()), float(sel.std())\n",
    "    return (s / m) if m != 0 else None\n",
    "\n",
    "def make_union_tumor_mask(entry: dict, rotate_k: int = 1) -> np.ndarray | None:\n",
    "    segs = []\n",
    "    for key in [\"seg_total\", \"seg_brats\", \"seg_enhancing\", \"seg_nonenhancing\"]:\n",
    "        if key in entry:\n",
    "            vol = load_volume_as_DHW(entry[key], rotate_k)\n",
    "            segs.append(vol > 0)\n",
    "    if not segs:\n",
    "        return None\n",
    "    union = np.zeros_like(segs[0], dtype=np.uint8)\n",
    "    for s in segs:\n",
    "        union |= s.astype(np.uint8)\n",
    "    return union\n",
    "\n",
    "# ---------- Visualization ----------\n",
    "def show_pair_with_overlay(vol: np.ndarray, title: str, seg_union: np.ndarray | None, z: int | None):\n",
    "    D = vol.shape[0]\n",
    "    z = D // 2 if z is None else max(0, min(z, D - 1))\n",
    "    img = normalize01(vol[z])\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    # left: MRI only\n",
    "    axes[0].imshow(img, cmap=\"gray\"); axes[0].set_aspect(\"equal\"); axes[0].axis(\"off\")\n",
    "    axes[0].set_title(f\"{title} | z={z}\")\n",
    "    # right: MRI + overlay (if present)\n",
    "    axes[1].imshow(img, cmap=\"gray\")\n",
    "    if seg_union is not None:\n",
    "        alpha = (seg_union[z] > 0).astype(np.float32) * 0.45\n",
    "        axes[1].imshow(seg_union[z], cmap=\"Reds\", alpha=alpha)\n",
    "    axes[1].set_aspect(\"equal\"); axes[1].axis(\"off\")\n",
    "    axes[1].set_title(f\"{title} + tumor\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# ---------- Main analyzer ----------\n",
    "def analyze_ucsd_ptgbm_patient(dataset_root: str, patient_id: str, rotate_k: int = 1):\n",
    "    idx = build_ucsd_ptgbm_index(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        raise ValueError(f\"Patient not found: {patient_id}\")\n",
    "    e = idx[patient_id]\n",
    "\n",
    "    # Build union tumor mask (D,H,W) if any\n",
    "    seg_union = make_union_tumor_mask(e, rotate_k)\n",
    "\n",
    "    # Choose best tumor slice (fallback to middle)\n",
    "    best_z = choose_best_lesion_slice(seg_union)\n",
    "\n",
    "    # Target modalities\n",
    "    modalities = [(\"T1pre\", \"T1pre\"), (\"T1post\", \"T1post\"), (\"T2\", \"T2\"), (\"FLAIR\", \"FLAIR\")]\n",
    "\n",
    "    results = {}\n",
    "    print(f\"=== {patient_id} ===\")\n",
    "    for key, title in modalities:\n",
    "        if key not in e:\n",
    "            print(f\"[INFO] Missing {key}\")\n",
    "            continue\n",
    "        vol = load_volume_as_DHW(e[key], rotate_k)\n",
    "        print(f\"{key}: shape={vol.shape}\")\n",
    "        cv = robust_cv(vol)\n",
    "        print(f\"  CV (robust, lower is better): {cv:.4f}\" if cv is not None else \"  CV: NA\")\n",
    "        show_pair_with_overlay(vol, title, seg_union, best_z)\n",
    "        results[key] = {\"shape\": vol.shape, \"cv\": cv}\n",
    "\n",
    "    # If both T1pre and T1post exist, report which is more homogeneous by CV\n",
    "    if \"T1pre\" in results and \"T1post\" in results and \\\n",
    "       results[\"T1pre\"][\"cv\"] is not None and results[\"T1post\"][\"cv\"] is not None:\n",
    "        better = \"T1post\" if results[\"T1post\"][\"cv\"] < results[\"T1pre\"][\"cv\"] else \"T1pre\"\n",
    "        print(f\" Prefer (homogeneity by CV): {better}\")\n",
    "\n",
    "    return {\"patient\": patient_id, \"modalities\": results, \"has_seg\": seg_union is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a277478",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucsd_root = \"/Users/chufal/projects/Datasets/PKG-UCSD-PTGBM-v1/UCSD-PTGBM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b88ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ucsd_available(ucsd_root, \"UCSD-PTGBM-0002_01\")  # optional, to inspect files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340595e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_ucsd_ptgbm_patient(ucsd_root, \"UCSD-PTGBM-0002_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5af4f",
   "metadata": {},
   "source": [
    "# PKG-UPENN-GBM-NIfTI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Utilities ---------\n",
    "def load_volume_as_DHW(path: str, rotate_k: int = 1):\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim == 4:\n",
    "        vol = vol[..., 0]\n",
    "    if vol.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D, got {vol.shape} for {path}\")\n",
    "    vol = np.transpose(vol, (2, 0, 1))  # (H,W,D)->(D,H,W)\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1,2))\n",
    "    return vol\n",
    "\n",
    "def normalize01(img: np.ndarray):\n",
    "    mn, mx = float(img.min()), float(img.max())\n",
    "    return (img - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(img)\n",
    "\n",
    "def robust_cv(vol: np.ndarray) -> float | None:\n",
    "    vox = vol[np.isfinite(vol)]\n",
    "    if vox.size < 100:\n",
    "        return None\n",
    "    lo, hi = np.percentile(vox, [5, 99.5])\n",
    "    brain_like = (vol > lo) & (vol < hi)\n",
    "    sel = vol[brain_like]\n",
    "    if sel.size < 100:\n",
    "        return None\n",
    "    m, s = float(sel.mean()), float(sel.std())\n",
    "    return (s / m) if m != 0 else None\n",
    "\n",
    "def choose_best_lesion_slice(seg_vol: np.ndarray | None) -> int | None:\n",
    "    if seg_vol is None:\n",
    "        return None\n",
    "    per_z = (seg_vol > 0).reshape(seg_vol.shape[0], -1).sum(axis=1)\n",
    "    if per_z.max() == 0:\n",
    "        return None\n",
    "    return int(per_z.argmax())\n",
    "\n",
    "# --------- Indexer for UPenn-GBM ---------\n",
    "# dataset_root can be:\n",
    "# - \".../PKG-UPENN-GBM-NIfTI/UPENN-GBM/NIfTI-files\"\n",
    "# - or its parent; the function will descend.\n",
    "def build_upenn_gbm_index(dataset_root: str) -> dict:\n",
    "    root = Path(dataset_root)\n",
    "    if not root.is_dir():\n",
    "        raise FileNotFoundError(f\"Not found: {dataset_root}\")\n",
    "    # Descend if needed\n",
    "    if (root / \"UPENN-GBM\" / \"NIfTI-files\").is_dir():\n",
    "        root = root / \"UPENN-GBM\" / \"NIfTI-files\"\n",
    "\n",
    "    img_dir = root / \"images_structural_unstripped\"\n",
    "    seg_dir = root / \"images_segm\"\n",
    "    if not img_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"Missing images_structural_unstripped at: {img_dir}\")\n",
    "    if not seg_dir.is_dir():\n",
    "        print(f\"[WARN] Missing images_segm at: {seg_dir}\")\n",
    "\n",
    "    # Build seg map: key = patient token \"UPENN-GBM-XXXXX_YY\"\n",
    "    seg_map = {}\n",
    "    if seg_dir.is_dir():\n",
    "        for f in seg_dir.iterdir():\n",
    "            if f.is_file() and \"\".join(f.suffixes).endswith(\".nii.gz\"):\n",
    "                m = re.match(r\"(UPENN-GBM-\\d{5}_\\d{2})_segm\\.nii\\.gz$\", f.name)\n",
    "                if m:\n",
    "                    seg_map[m.group(1)] = str(f)\n",
    "\n",
    "    # Collect per-patient images\n",
    "    patterns = {\n",
    "        r\"_T1_unstripped\\.nii\\.gz$\": \"T1\",\n",
    "        r\"_T1GD_unstripped\\.nii\\.gz$\": \"T1GD\",   # post-contrast\n",
    "        r\"_T2_unstripped\\.nii\\.gz$\": \"T2\",\n",
    "        r\"_FLAIR_unstripped\\.nii\\.gz$\": \"FLAIR\",\n",
    "    }\n",
    "\n",
    "    index = {}\n",
    "    for pdir in sorted([d for d in img_dir.iterdir() if d.is_dir() and not d.name.startswith(\".\")]):\n",
    "        entry = {}\n",
    "        for f in pdir.iterdir():\n",
    "            if not (f.is_file() and \"\".join(f.suffixes).endswith(\".nii.gz\")):\n",
    "                continue\n",
    "            for pat, key in patterns.items():\n",
    "                if re.search(pat, f.name):\n",
    "                    entry[key] = str(f)\n",
    "                    break\n",
    "        # Attach segmentation if available\n",
    "        pid = pdir.name  # e.g., \"UPENN-GBM-00001_11\"\n",
    "        if pid in seg_map:\n",
    "            entry[\"segm\"] = seg_map[pid]\n",
    "        if entry:\n",
    "            index[pid] = entry\n",
    "    return index\n",
    "\n",
    "def list_upenn_available(dataset_root: str, patient_id: str):\n",
    "    idx = build_upenn_gbm_index(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        print(f\"[ERROR] Patient not found: {patient_id}\")\n",
    "        print(\"Available (first 20):\")\n",
    "        for k in list(idx.keys())[:20]:\n",
    "            print(\" -\", k)\n",
    "        return\n",
    "    print(patient_id, \"\", sorted(idx[patient_id].keys()))\n",
    "    for k, v in sorted(idx[patient_id].items()):\n",
    "        print(f\" - {k}: {v}\")\n",
    "\n",
    "# --------- Visualization (side-by-side MRI and overlay) ---------\n",
    "def show_pair_with_overlay(vol: np.ndarray, title: str, seg_vol: np.ndarray | None, z: int | None):\n",
    "    D = vol.shape[0]\n",
    "    z = D // 2 if z is None else max(0, min(z, D - 1))\n",
    "    base = normalize01(vol[z])\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(base, cmap=\"gray\")\n",
    "    axes[0].set_aspect(\"equal\"); axes[0].axis(\"off\")\n",
    "    axes[0].set_title(f\"{title} | z={z}\")\n",
    "    axes[1].imshow(base, cmap=\"gray\")\n",
    "    if seg_vol is not None:\n",
    "        alpha = (seg_vol[z] > 0).astype(np.float32) * 0.45\n",
    "        axes[1].imshow(seg_vol[z], cmap=\"nipy_spectral\", alpha=alpha)\n",
    "    axes[1].set_aspect(\"equal\"); axes[1].axis(\"off\")\n",
    "    axes[1].set_title(f\"{title} + seg\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# --------- Main analyzer ---------\n",
    "def analyze_upenn_gbm_patient(dataset_root: str, patient_id: str, rotate_k: int = 1):\n",
    "    idx = build_upenn_gbm_index(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        raise ValueError(f\"Patient not found: {patient_id}\")\n",
    "    e = idx[patient_id]\n",
    "\n",
    "    seg_union = None\n",
    "    if \"segm\" in e:\n",
    "        seg_union = (load_volume_as_DHW(e[\"segm\"], rotate_k) > 0).astype(np.uint8)\n",
    "\n",
    "    best_z = choose_best_lesion_slice(seg_union)\n",
    "\n",
    "    modalities = [(\"T1\", \"T1\"), (\"T1GD\", \"T1GD (post)\"), (\"T2\", \"T2\"), (\"FLAIR\", \"FLAIR\")]\n",
    "\n",
    "    results = {}\n",
    "    print(f\"=== {patient_id} ===\")\n",
    "    for key, title in modalities:\n",
    "        if key not in e:\n",
    "            print(f\"[INFO] Missing {key}\")\n",
    "            continue\n",
    "        vol = load_volume_as_DHW(e[key], rotate_k)\n",
    "        cv = robust_cv(vol)\n",
    "        print(f\"{key}: shape={vol.shape} | CV (robust): {cv:.4f}\" if cv is not None else f\"{key}: shape={vol.shape} | CV: NA\")\n",
    "        show_pair_with_overlay(vol, title, seg_union, best_z)\n",
    "        results[key] = {\"shape\": vol.shape, \"cv\": cv}\n",
    "\n",
    "    return {\"patient\": patient_id, \"modalities\": results, \"has_seg\": seg_union is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc473de",
   "metadata": {},
   "outputs": [],
   "source": [
    "upenn_root = \"/Users/chufal/projects/Datasets/PKG-UPENN-GBM-NIfTI/UPENN-GBM/NIfTI-files\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_upenn_available(upenn_root, \"UPENN-GBM-00002_11\")  # optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_upenn_gbm_patient(upenn_root, \"UPENN-GBM-00002_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66349ac",
   "metadata": {},
   "source": [
    "# PKG-Yale-Brain-Mets-Longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb930fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Basic I/O ----------\n",
    "def load_volume_as_DHW(path: str, rotate_k: int = 1):\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim == 4:\n",
    "        vol = vol[..., 0]\n",
    "    if vol.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D volume, got {vol.shape} for {path}\")\n",
    "    vol = np.transpose(vol, (2, 0, 1))  # (H,W,D) -> (D,H,W)\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1, 2))\n",
    "    return vol\n",
    "\n",
    "def normalize01(img: np.ndarray):\n",
    "    mn, mx = float(img.min()), float(img.max())\n",
    "    return (img - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(img)\n",
    "\n",
    "# ---------- Representative slice without seg ----------\n",
    "def choose_representative_slice(vol: np.ndarray) -> int:\n",
    "    # Picks slice with most edge activity (no extra deps)\n",
    "    D = vol.shape[0]\n",
    "    scores = np.zeros(D, dtype=np.float32)\n",
    "    for z in range(D):\n",
    "        s = vol[z]\n",
    "        s = normalize01(s)\n",
    "        gx = np.gradient(s, axis=0)\n",
    "        gy = np.gradient(s, axis=1)\n",
    "        edge = np.hypot(gx, gy)\n",
    "        scores[z] = float(edge.mean())\n",
    "    return int(np.argmax(scores))\n",
    "\n",
    "# ---------- Indexer for Yale longitudinal dataset ----------\n",
    "# dataset_root should point to \".../PKG-Yale-Brain-Mets-Longitudinal/Yale-Brain-Mets-Longitudinal\"\n",
    "\n",
    "def debug_yale_root(dataset_root: str, sample: int = 10):\n",
    "    root = Path(dataset_root)\n",
    "    print(\"Exists:\", root.exists(), \"| Is dir:\", root.is_dir())\n",
    "    print(\"Root:\", root)\n",
    "    patient_dirs = [d.name for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")] if root.is_dir() else []\n",
    "    print(f\"Found {len(patient_dirs)} patient dirs. Sample:\")\n",
    "    for name in sorted(patient_dirs)[:sample]:\n",
    "        print(\" -\", name)\n",
    "\n",
    "# 1) Robust indexer (descend if needed; optional time; case-insensitive)\n",
    "def build_yale_index_tolerant(dataset_root: str) -> dict:\n",
    "    \"\"\"\n",
    "    patient_id -> { date -> { 'PRE': path?, 'POST': path?, 'T2': path?, 'FLAIR': path? } }\n",
    "    - Strips '.nii.gz' correctly\n",
    "    - Accepts optional HH-MM-SS time token\n",
    "    - Case-insensitive modality\n",
    "    - Keeps latest time per modality if multiple files on same date\n",
    "    \"\"\"\n",
    "    root = Path(dataset_root)\n",
    "    if not root.is_dir():\n",
    "        raise FileNotFoundError(f\"Not found: {dataset_root}\")\n",
    "    if (root / \"Yale-Brain-Mets-Longitudinal\").is_dir():\n",
    "        root = root / \"Yale-Brain-Mets-Longitudinal\"\n",
    "\n",
    "    date_dir_re = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}$\")\n",
    "    valid_mods = {\"PRE\",\"POST\",\"T2\",\"FLAIR\"}\n",
    "\n",
    "    index: dict[str, dict[str, dict[str, str]]] = {}\n",
    "\n",
    "    for pdir in sorted([d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\".\")]):\n",
    "        patient_id = pdir.name\n",
    "        timepoints: dict[str, dict[str, str]] = {}\n",
    "        date_dirs = [d for d in pdir.iterdir() if d.is_dir() and date_dir_re.match(d.name)]\n",
    "        for ddir in date_dirs:\n",
    "            date_key = ddir.name\n",
    "            latest_by_mod: dict[str, str] = {}\n",
    "            mod_to_path: dict[str, str] = {}\n",
    "\n",
    "            for f in ddir.iterdir():\n",
    "                if not (f.is_file() and f.name.lower().endswith(\".nii.gz\")):\n",
    "                    continue\n",
    "                base = f.name[:-7]  # strip \".nii.gz\"\n",
    "                parts = base.split(\"_\")\n",
    "                if not parts:\n",
    "                    continue\n",
    "                mod_candidate = parts[-1].upper()\n",
    "                if mod_candidate not in valid_mods:\n",
    "                    continue\n",
    "                time_token = \"\"\n",
    "                if len(parts) >= 3:\n",
    "                    maybe_time = parts[-2]\n",
    "                    if re.fullmatch(r\"\\d{2}-\\d{2}-\\d{2}\", maybe_time):\n",
    "                        time_token = maybe_time\n",
    "\n",
    "                if mod_candidate not in latest_by_mod or time_token > latest_by_mod[mod_candidate]:\n",
    "                    latest_by_mod[mod_candidate] = time_token\n",
    "                    mod_to_path[mod_candidate] = str(f)\n",
    "\n",
    "            timepoints[date_key] = mod_to_path  # record the date even if empty\n",
    "\n",
    "        if timepoints:\n",
    "            index[patient_id] = dict(sorted(timepoints.items(), key=lambda kv: kv[0]))\n",
    "\n",
    "    return index\n",
    "\n",
    "def list_yale_available(dataset_root: str, patient_id: str, head: int = 10):\n",
    "    idx = build_yale_index_tolerant(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        print(f\"[ERROR] Patient not found: {patient_id}\")\n",
    "        print(f\"Available patients (first {head}):\")\n",
    "        for k in list(sorted(idx.keys()))[:head]:\n",
    "            print(\" -\", k)\n",
    "        return\n",
    "    print(patient_id)\n",
    "    for date, mods in idx[patient_id].items():\n",
    "        keys = sorted(list(mods.keys()))\n",
    "        print(f\" - {date}: {keys if keys else '[] (no recognized PRE/POST/T2/FLAIR)'}\")\n",
    "\n",
    "def debug_yale_list_date(dataset_root: str, patient_id: str, date: str, max_show: int = 50):\n",
    "    root = Path(dataset_root)\n",
    "    if (root / \"Yale-Brain-Mets-Longitudinal\").is_dir():\n",
    "        root = root / \"Yale-Brain-Mets-Longitudinal\"\n",
    "    ddir = root / patient_id / date\n",
    "    print(\"Exists:\", ddir.exists(), \"| Is dir:\", ddir.is_dir())\n",
    "    if ddir.is_dir():\n",
    "        files = sorted([f.name for f in ddir.iterdir() if f.is_file()])\n",
    "        print(f\"Files in {patient_id}/{date} (up to {max_show}):\")\n",
    "        for name in files[:max_show]:\n",
    "            print(\" -\", name)\n",
    "\n",
    "# ---------- Visualizations ----------\n",
    "# Use the tolerant indexer by default\n",
    "def show_yale_timeline(\n",
    "    dataset_root: str,\n",
    "    patient_id: str,\n",
    "    modality: str = \"POST\",     # 'PRE', 'POST', 'T2', 'FLAIR' (case-insensitive)\n",
    "    slice_mode: str = \"rep\",    # 'rep' (representative) or 'mid'\n",
    "    rotate_k: int = 1,\n",
    "    cols: int = 6,\n",
    "    index_fn=build_yale_index_tolerant\n",
    "):\n",
    "    idx = index_fn(dataset_root)\n",
    "    if patient_id not in idx:\n",
    "        raise ValueError(f\"Patient not found: {patient_id}\")\n",
    "    modality = modality.upper()\n",
    "    entries = [(date, mods.get(modality)) for date, mods in idx[patient_id].items()]\n",
    "    entries = [(d, p) for d, p in entries if p is not None]\n",
    "    if not entries:\n",
    "        print(f\"[INFO] No {modality} found for {patient_id}\")\n",
    "        return\n",
    "\n",
    "    from math import ceil\n",
    "    rows = ceil(len(entries) / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3.0*cols, 3.0*rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "    for i, (date, path) in enumerate(entries):\n",
    "        vol = load_volume_as_DHW(path, rotate_k)\n",
    "        z = choose_representative_slice(vol) if slice_mode == \"rep\" else vol.shape[0] // 2\n",
    "        img = normalize01(vol[z])\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.set_aspect(\"equal\"); ax.axis(\"off\")\n",
    "        ax.set_title(f\"{date}\", fontsize=9)\n",
    "    # hide unused\n",
    "    for j in range(len(entries), rows*cols):\n",
    "        axes[j // cols, j % cols].axis(\"off\")\n",
    "    plt.suptitle(f\"{patient_id} | {modality} timeline ({slice_mode})\", y=0.98)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def compare_pre_post_at_date(\n",
    "    dataset_root: str,\n",
    "    patient_id: str,\n",
    "    date: str,          # 'YYYY-MM-DD'\n",
    "    slice_mode: str = \"rep\",\n",
    "    rotate_k: int = 1,\n",
    "    index_fn=build_yale_index_tolerant\n",
    "):\n",
    "    idx = index_fn(dataset_root)\n",
    "    if patient_id not in idx or date not in idx[patient_id]:\n",
    "        raise ValueError(f\"No data for {patient_id} at {date}\")\n",
    "    mods = idx[patient_id][date]\n",
    "    pre_path = mods.get(\"PRE\")\n",
    "    post_path = mods.get(\"POST\")\n",
    "    if not pre_path and not post_path:\n",
    "        print(f\"[INFO] No PRE/POST for {patient_id} at {date}\")\n",
    "        return\n",
    "    vol_pre = load_volume_as_DHW(pre_path, rotate_k) if pre_path else None\n",
    "    vol_post = load_volume_as_DHW(post_path, rotate_k) if post_path else None\n",
    "    ref = vol_post if vol_post is not None else vol_pre\n",
    "    z = choose_representative_slice(ref) if (ref is not None and slice_mode == \"rep\") else (ref.shape[0]//2 if ref is not None else 0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    if vol_pre is not None:\n",
    "        axes[0].imshow(normalize01(vol_pre[z]), cmap=\"gray\"); axes[0].set_title(\"PRE\"); axes[0].set_aspect(\"equal\"); axes[0].axis(\"off\")\n",
    "    else:\n",
    "        axes[0].text(0.5, 0.5, \"PRE missing\", ha=\"center\", va=\"center\"); axes[0].axis(\"off\")\n",
    "    if vol_post is not None:\n",
    "        axes[1].imshow(normalize01(vol_post[z]), cmap=\"gray\"); axes[1].set_title(\"POST\"); axes[1].set_aspect(\"equal\"); axes[1].axis(\"off\")\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, \"POST missing\", ha=\"center\", va=\"center\"); axes[1].axis(\"off\")\n",
    "    plt.suptitle(f\"{patient_id} | {date} | z={z} ({slice_mode})\", y=0.98)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def show_modalities_at_date(\n",
    "    dataset_root: str,\n",
    "    patient_id: str,\n",
    "    date: str,\n",
    "    modalities: list[str] = (\"PRE\",\"POST\",\"T2\",\"FLAIR\"),\n",
    "    slice_mode: str = \"rep\",\n",
    "    rotate_k: int = 1,\n",
    "    index_fn=build_yale_index_tolerant\n",
    "):\n",
    "    idx = index_fn(dataset_root)\n",
    "    if patient_id not in idx or date not in idx[patient_id]:\n",
    "        raise ValueError(f\"No data for {patient_id} at {date}\")\n",
    "    mods = idx[patient_id][date]\n",
    "    vols = []\n",
    "    for m in modalities:\n",
    "        p = mods.get(m.upper())\n",
    "        vols.append((m.upper(), load_volume_as_DHW(p, rotate_k) if p else None))\n",
    "    ref = next((v for (_, v) in vols if v is not None), None)\n",
    "    if ref is None:\n",
    "        print(f\"[INFO] No requested modalities available for {patient_id} at {date}\")\n",
    "        return\n",
    "    z = choose_representative_slice(ref) if slice_mode == \"rep\" else ref.shape[0] // 2\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(modalities), figsize=(3.2*len(modalities), 3.2))\n",
    "    if len(modalities) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (m, v) in zip(axes, vols):\n",
    "        if v is None:\n",
    "            ax.text(0.5, 0.5, f\"{m} missing\", ha=\"center\", va=\"center\"); ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.imshow(normalize01(v[z]), cmap=\"gray\")\n",
    "            ax.set_aspect(\"equal\"); ax.axis(\"off\"); ax.set_title(m)\n",
    "    plt.suptitle(f\"{patient_id} | {date} | z={z} ({slice_mode})\", y=0.98)\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yale_root = \"/Users/chufal/projects/Datasets/PKG-Yale-Brain-Mets-Longitudinal/Yale-Brain-Mets-Longitudinal\"\n",
    "# Inspect availability\n",
    "list_yale_available(yale_root, \"YG_0B4NV6E3KEZQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afafbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeline of POST (T1 post-contrast) across dates\n",
    "show_yale_timeline(yale_root, \"YG_0B4NV6E3KEZQ\", modality=\"POST\", slice_mode=\"rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973863ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PRE vs POST for a specific date\n",
    "compare_pre_post_at_date(yale_root, \"YG_0B4NV6E3KEZQ\", date=\"2015-09-29\", slice_mode=\"rep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show modalities at a date (whatever exists will be shown)\n",
    "show_modalities_at_date(yale_root, \"YG_0B4NV6E3KEZQ\", date=\"2015-09-29\", modalities=[\"PRE\",\"POST\",\"T2\",\"FLAIR\"], slice_mode=\"rep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78919686",
   "metadata": {},
   "source": [
    "# BCBM Radiogenomics - explore Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize01(img):\n",
    "    mn, mx = float(img.min()), float(img.max())\n",
    "    return (img - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(img)\n",
    "\n",
    "def _load_DHW(path: str, rotate_k: int = 1):\n",
    "    vol = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    if vol.ndim == 4:\n",
    "        vol = vol[..., 0]\n",
    "    # assume on-disk (H,W,D) -> (D,H,W)\n",
    "    vol = np.transpose(vol, (2, 0, 1))\n",
    "    if rotate_k:\n",
    "        vol = np.rot90(vol, k=rotate_k, axes=(1, 2))\n",
    "    return vol\n",
    "\n",
    "def _best_slice_by_area(mask_DHW: np.ndarray) -> tuple[int, int]:\n",
    "    m = (mask_DHW > 0)\n",
    "    per_z = m.reshape(m.shape[0], -1).sum(axis=1)\n",
    "    z = int(per_z.argmax())\n",
    "    return z, int(per_z[z])\n",
    "\n",
    "def inspect_bcbm_masks_only(\n",
    "    case_dir: str,\n",
    "    *,\n",
    "    alpha: float = 0.7,\n",
    "    gamma: float = 0.9,\n",
    "    rotate_k: int = 1,\n",
    "    cols: int = 4,\n",
    "    include_substrings: list[str] | None = None,\n",
    "    exclude_substrings: list[str] | None = None,\n",
    "    max_masks: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    For a BCBM case folder: show one panel PER MASK.\n",
    "    Each panel = MRI slice (at that mask's best z) + that mask overlay.\n",
    "    No standalone MRI-only panel.\n",
    "\n",
    "    - include_substrings: keep masks containing any of these (case-insensitive)\n",
    "    - exclude_substrings: drop masks containing any of these\n",
    "    \"\"\"\n",
    "    case_path = Path(case_dir)\n",
    "    if not case_path.is_dir():\n",
    "        raise FileNotFoundError(f\"Case folder not found: {case_dir}\")\n",
    "\n",
    "    # MRI image\n",
    "    image = None\n",
    "    for cand in case_path.iterdir():\n",
    "        if cand.is_file() and cand.name.endswith(\"_image_ss_n4.nii.gz\"):\n",
    "            image = cand\n",
    "            break\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"No *_image_ss_n4.nii.gz found in {case_dir}\")\n",
    "    img_vol = _load_DHW(str(image), rotate_k=rotate_k)\n",
    "\n",
    "    # Masks\n",
    "    masks = [f for f in case_path.iterdir() if f.is_file() and \"_mask_\" in f.name and f.name.endswith(\".nii.gz\")]\n",
    "\n",
    "    def _contains_any(name: str, subs: list[str]) -> bool:\n",
    "        n = name.lower()\n",
    "        return any(s.lower() in n for s in subs)\n",
    "\n",
    "    if include_substrings:\n",
    "        masks = [m for m in masks if _contains_any(m.name, include_substrings)]\n",
    "    if exclude_substrings:\n",
    "        masks = [m for m in masks if not _contains_any(m.name, exclude_substrings)]\n",
    "    if max_masks is not None:\n",
    "        masks = masks[:max_masks]\n",
    "\n",
    "    # Build per-mask overlays\n",
    "    entries = []\n",
    "    for mpath in masks:\n",
    "        try:\n",
    "            mvol = _load_DHW(str(mpath), rotate_k=rotate_k)\n",
    "            if mvol.shape != img_vol.shape:\n",
    "                print(f\"[SKIP] shape mismatch {mpath.name}: mask {mvol.shape} vs img {img_vol.shape}\")\n",
    "                continue\n",
    "            z, area = _best_slice_by_area(mvol)\n",
    "            if area == 0:\n",
    "                print(f\"[SKIP] empty mask {mpath.name}\")\n",
    "                continue\n",
    "            entries.append((mpath, z, area))\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIP] error loading {mpath.name}: {e}\")\n",
    "\n",
    "    if not entries:\n",
    "        print(\"No non-empty masks to display.\")\n",
    "        return\n",
    "\n",
    "    # Plot grid: one panel per mask\n",
    "    n = len(entries)\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3.2 * cols, 3.2 * rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    palette = [\"#ff1744\",\"#00e5ff\",\"#76ff03\",\"#ffea00\",\"#651fff\",\"#ff9100\",\"#00bfa5\",\"#d500f9\",\n",
    "               \"#ff6d00\",\"#64dd17\",\"#2962ff\",\"#dd2c00\"]\n",
    "\n",
    "    for i, (mpath, z, area) in enumerate(entries):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        base = _normalize01(img_vol[z]) ** gamma\n",
    "        ax.imshow(base, cmap=\"gray\")\n",
    "        mask_slice = (_load_DHW(str(mpath), rotate_k=rotate_k)[z] > 0).astype(np.float32)\n",
    "        color = palette[i % len(palette)]\n",
    "        overlay = np.ma.masked_where(mask_slice == 0, mask_slice)\n",
    "        ax.imshow(overlay, cmap=plt.cm.get_cmap('cool', 2), alpha=alpha, interpolation=\"nearest\")\n",
    "        ax.contour(mask_slice, levels=[0.5], colors=[color], linewidths=2.0, antialiased=True)\n",
    "        title = re.sub(r\"\\.nii\\.gz$\", \"\", mpath.name)\n",
    "        ax.set_title(f\"{title}\\nz={z}, area={area}\", fontsize=8)\n",
    "        ax.set_aspect(\"equal\"); ax.axis(\"off\")\n",
    "\n",
    "    # Hide leftovers\n",
    "    for j in range(n, rows * cols):\n",
    "        axes[j // cols, j % cols].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"{case_path.name} | masks shown: {n}\", y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48007ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcbm_root = \"/Users/chufal/projects/Datasets/PKG-BCBM-RadioGenomics_Images_Masks_Dec2024/BCBM-RadioGenomics_Images_Masks_Dec2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = \"BCBM-RadioGenomics-183-3\"\n",
    "inspect_bcbm_masks_only(\n",
    "    f\"{bcbm_root}/{case}\",\n",
    "    alpha=0.75, gamma=0.9, cols=4,\n",
    "    # Focus on tumor-like; exclude OAR/cavity if you want:\n",
    "    # include_substrings=[\"tumor\",\"met\",\"gtv\",\"ptv\",\"tgt\"],\n",
    "    # exclude_substrings=[\"optic\",\"chiasm\",\"lens\",\"brainstem\",\"bst\",\"bs\",\"cavity\",\"surgical\"],\n",
    "    max_masks=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Users/chufal/projects/Datasets/PKG-BraTS-Africa/BraTS-Africa/95_Glioma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient to review\n",
    "n = 1\n",
    "\n",
    "all_files = os.listdir(data_folder)\n",
    "\n",
    "path_to_review = Path(data_folder, all_files[n])\n",
    "\n",
    "all_nifty_files = os.listdir(path_to_review)\n",
    "\n",
    "seg_file = [f for f in all_nifty_files if \"seg\" in f][0]\n",
    "mri_tic_file = [f for f in all_nifty_files if \"t1c\" in f][0]\n",
    "\n",
    "print(f\"seg_file: {seg_file}\")\n",
    "print(f\"mri_tic_file: {mri_tic_file}\"   )\n",
    "\n",
    "print(f\"all_nifty_files: {all_nifty_files}\")\n",
    "\n",
    "mask_file = Path(path_to_review, seg_file)\n",
    "tic_file = Path(path_to_review, mri_tic_file)\n",
    "\n",
    "print(f\"mask_file: {mask_file}\")\n",
    "\n",
    "msk_vol = nib.load(mask_file).get_fdata(dtype=np.float32)\n",
    "tic_vol = nib.load(tic_file).get_fdata(dtype=np.float32)\n",
    "\n",
    "print(f\"msk_vol.shape: {msk_vol.shape}\")\n",
    "print(f\"tic_vol.shape: {tic_vol.shape}\")\n",
    "\n",
    "plt.imshow(msk_vol[90])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901f3bf",
   "metadata": {},
   "source": [
    "# Functions to review Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5946af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import (\n",
    "    Dropdown, SelectMultiple, IntSlider, FloatSlider, Checkbox, RadioButtons,\n",
    "    HBox, VBox, Output, HTML, Layout\n",
    ")\n",
    "from matplotlib.colors import ListedColormap, to_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c71503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Helpers: discovery and loading\n",
    "# ---------------------------\n",
    "\n",
    "def _is_case_folder(path: Path) -> bool:\n",
    "    nii_files = list(path.glob(\"*.nii\")) + list(path.glob(\"*.nii.gz\"))\n",
    "    return len(nii_files) > 0\n",
    "\n",
    "def _find_case_modalities(case_dir: Path) -> dict:\n",
    "    # Find segmentation and modalities by naming hints\n",
    "    files = list(case_dir.glob(\"*.nii\")) + list(case_dir.glob(\"*.nii.gz\"))\n",
    "    by_key = {\n",
    "        \"seg\": None,\n",
    "        \"t1c\": None,\n",
    "        \"flair\": None,\n",
    "        \"t2\": None,\n",
    "        \"t1\": None,\n",
    "    }\n",
    "    # First pass: perfect contains-key match\n",
    "    for f in files:\n",
    "        name = f.name.lower()\n",
    "        if \"seg\" in name and by_key[\"seg\"] is None:\n",
    "            by_key[\"seg\"] = f\n",
    "        if \"t1c\" in name and by_key[\"t1c\"] is None:\n",
    "            by_key[\"t1c\"] = f\n",
    "        if \"flair\" in name and by_key[\"flair\"] is None:\n",
    "            by_key[\"flair\"] = f\n",
    "        if re.search(r\"(^|[^a-z])t2([^a-z]|$)\", name) and by_key[\"t2\"] is None:\n",
    "            by_key[\"t2\"] = f\n",
    "        # ensure t1c took precedence, so for plain t1 exclude t1c\n",
    "        if \"t1\" in name and \"t1c\" not in name and by_key[\"t1\"] is None:\n",
    "            by_key[\"t1\"] = f\n",
    "    return by_key\n",
    "\n",
    "def _discover_cases(root_path: str) -> dict:\n",
    "    root = Path(root_path)\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"Path not found: {root_path}\")\n",
    "\n",
    "    cases = {}\n",
    "    if _is_case_folder(root):\n",
    "        # Single case\n",
    "        modalities = _find_case_modalities(root)\n",
    "        if modalities[\"seg\"] is not None:\n",
    "            cases[root.name] = modalities\n",
    "    else:\n",
    "        # Dataset root with subfolders\n",
    "        for sub in sorted(p for p in root.iterdir() if p.is_dir()):\n",
    "            modalities = _find_case_modalities(sub)\n",
    "            if modalities[\"seg\"] is not None:\n",
    "                cases[sub.name] = modalities\n",
    "\n",
    "    if not cases:\n",
    "        raise RuntimeError(\"No valid cases with a 'seg' file were found under the provided path.\")\n",
    "    return cases\n",
    "\n",
    "# Simple cache to avoid reloading from disk\n",
    "_VOLUME_CACHE = {}\n",
    "\n",
    "def _load_nifti_array(path: Path) -> np.ndarray:\n",
    "    key = str(path.resolve())\n",
    "    if key in _VOLUME_CACHE:\n",
    "        return _VOLUME_CACHE[key]\n",
    "    arr = nib.load(path).get_fdata(dtype=np.float32)\n",
    "    _VOLUME_CACHE[key] = arr\n",
    "    return arr\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Label utilities and colors\n",
    "# ---------------------------\n",
    "\n",
    "def summarize_segmentation_labels(seg_path: str) -> dict:\n",
    "    \"\"\"Return a dict: label_value -> voxel_count\"\"\"\n",
    "    seg = _load_nifti_array(Path(seg_path))\n",
    "    unique, counts = np.unique(seg, return_counts=True)\n",
    "    summary = {int(u): int(c) for u, c in zip(unique, counts)}\n",
    "    return summary\n",
    "\n",
    "def _default_label_colors(unique_labels):\n",
    "    # Default mapping for common BraTS labels; fall back to tab20 for others\n",
    "    preferred = {\n",
    "        1: \"#1f77b4\",  # blue\n",
    "        2: \"#2ca02c\",  # green\n",
    "        3: \"#ff7f0e\",  # orange\n",
    "        4: \"#d62728\",  # red\n",
    "    }\n",
    "    colors = {}\n",
    "    # generate distinct colors for anything not in preferred\n",
    "    tab20 = plt.get_cmap(\"tab20\")\n",
    "    extra_labels = [l for l in unique_labels if l not in preferred and l != 0]\n",
    "    for idx, l in enumerate(extra_labels):\n",
    "        colors[l] = tab20(idx % tab20.N)\n",
    "    for k, v in preferred.items():\n",
    "        if k in unique_labels:\n",
    "            colors[k] = v\n",
    "    return colors\n",
    "\n",
    "# ---------------------------\n",
    "# Visualization\n",
    "# ---------------------------\n",
    "\n",
    "def _extract_slice(volume: np.ndarray, axis: int, index: int) -> np.ndarray:\n",
    "    if axis == 0:\n",
    "        return volume[index, :, :]\n",
    "    elif axis == 1:\n",
    "        return volume[:, index, :]\n",
    "    else:\n",
    "        return volume[:, :, index]\n",
    "\n",
    "def _normalize_image(image2d: np.ndarray, do_normalize: bool) -> np.ndarray:\n",
    "    if not do_normalize:\n",
    "        return image2d\n",
    "    # robust percentile normalization for display\n",
    "    lo, hi = np.percentile(image2d[np.isfinite(image2d)], [1, 99])\n",
    "    if hi <= lo:\n",
    "        return image2d\n",
    "    img = np.clip(image2d, lo, hi)\n",
    "    img = (img - lo) / (hi - lo + 1e-6)\n",
    "    return img\n",
    "\n",
    "def launch_mask_viewer(root_path: str):\n",
    "    \"\"\"\n",
    "    Launch an interactive viewer for cases under root_path.\n",
    "    \"\"\"\n",
    "    cases = _discover_cases(root_path)\n",
    "    case_names = sorted(cases.keys())\n",
    "\n",
    "    # pick default modality order\n",
    "    def _default_modality(mods: dict) -> str:\n",
    "        for m in [\"t1c\", \"flair\", \"t2\", \"t1\"]:\n",
    "            if mods.get(m) is not None:\n",
    "                return m\n",
    "        # fallback: seg (to at least inspect)\n",
    "        return \"t1c\"\n",
    "\n",
    "    # Widgets\n",
    "    case_dd = Dropdown(options=case_names, description=\"Case:\", layout=Layout(width=\"280px\"))\n",
    "    modality_dd = Dropdown(options=[], description=\"Modality:\", layout=Layout(width=\"180px\"))\n",
    "    plane_rb = RadioButtons(options=[(\"Axial\", 2), (\"Coronal\", 1), (\"Sagittal\", 0)],\n",
    "                            description=\"Plane:\", layout=Layout(width=\"200px\"))\n",
    "    slice_slider = IntSlider(description=\"Slice:\", min=0, max=1, value=0, continuous_update=False, layout=Layout(width=\"400px\"))\n",
    "    labels_ms = SelectMultiple(options=[], description=\"Labels:\", layout=Layout(width=\"180px\", height=\"160px\"))\n",
    "    alpha_slider = FloatSlider(description=\"Alpha:\", min=0.1, max=1.0, step=0.05, value=0.5, readout_format=\".2f\", layout=Layout(width=\"200px\"))\n",
    "    contour_cb = Checkbox(value=False, description=\"Contour only\")\n",
    "    norm_cb = Checkbox(value=True, description=\"Normalize image\")\n",
    "\n",
    "    label_summary_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    out = Output(layout=Layout(border=\"1px solid #ddd\"))\n",
    "\n",
    "    # State\n",
    "    current_seg_unique = []\n",
    "    current_case_modalities = {}\n",
    "\n",
    "    def _update_modality_options(change=None):\n",
    "        nonlocal current_case_modalities, current_seg_unique\n",
    "        case = case_dd.value\n",
    "        current_case_modalities = cases[case]\n",
    "\n",
    "        available_modalities = [m for m in [\"t1c\", \"flair\", \"t2\", \"t1\"] if current_case_modalities.get(m) is not None]\n",
    "        if not available_modalities:\n",
    "            available_modalities = [\"seg\"]\n",
    "        modality_dd.options = available_modalities\n",
    "        modality_dd.value = _default_modality(current_case_modalities)\n",
    "\n",
    "        # Update labels from seg\n",
    "        seg_path = current_case_modalities[\"seg\"]\n",
    "        seg = _load_nifti_array(seg_path)\n",
    "        unique_labels = sorted([int(x) for x in np.unique(seg)])\n",
    "        current_seg_unique = unique_labels\n",
    "        # labels list defaults to all labels except 0\n",
    "        nonzero_labels = [l for l in unique_labels if l != 0]\n",
    "        labels_ms.options = [(str(l), l) for l in nonzero_labels]\n",
    "        labels_ms.value = tuple(nonzero_labels)\n",
    "\n",
    "        # Update slice slider range based on selected plane and selected modality volume\n",
    "        _update_slice_slider_range()\n",
    "\n",
    "        # Update summary\n",
    "        summary = summarize_segmentation_labels(str(seg_path))\n",
    "        # Pretty print small summary inline\n",
    "        items = [f\"<b>{k}</b>: {v}\" for k, v in sorted(summary.items())]\n",
    "        label_summary_html.value = f\"Label voxel counts: {' | '.join(items)}\"\n",
    "\n",
    "        _render()\n",
    "\n",
    "    def _update_slice_slider_range(change=None):\n",
    "        vol_path = current_case_modalities.get(modality_dd.value) or current_case_modalities[\"seg\"]\n",
    "        vol = _load_nifti_array(vol_path)\n",
    "        axis = plane_rb.value\n",
    "        max_idx = int(vol.shape[axis]) - 1\n",
    "        slice_slider.max = max_idx\n",
    "        # Choose a middle slice by default, bounded safely\n",
    "        slice_slider.value = max(0, min(max_idx, max_idx // 2))\n",
    "\n",
    "    def _render(change=None):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "\n",
    "            case = case_dd.value\n",
    "            mods = current_case_modalities\n",
    "            img_path = mods.get(modality_dd.value) or mods[\"seg\"]\n",
    "            seg_path = mods[\"seg\"]\n",
    "\n",
    "            img_vol = _load_nifti_array(img_path)\n",
    "            seg_vol = _load_nifti_array(seg_path)\n",
    "\n",
    "            axis = plane_rb.value\n",
    "            idx = slice_slider.value\n",
    "\n",
    "            img_slice = _extract_slice(img_vol, axis, idx)\n",
    "            seg_slice = _extract_slice(seg_vol, axis, idx)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "            ax.imshow(_normalize_image(img_slice, norm_cb.value), cmap=\"gray\")\n",
    "            ax.set_title(f\"{case} | {modality_dd.value.upper()} | {['Sagittal','Coronal','Axial'][axis]}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Prepare colors\n",
    "            colors_map = _default_label_colors(current_seg_unique)\n",
    "\n",
    "            selected_labels = list(labels_ms.value) if labels_ms.value else []\n",
    "            for l in selected_labels:\n",
    "                if l == 0:\n",
    "                    continue\n",
    "                mask = (seg_slice == l)\n",
    "                if not np.any(mask):\n",
    "                    continue\n",
    "                color_rgba = to_rgba(colors_map.get(l, \"#9467bd\"), alpha=alpha_slider.value)\n",
    "                if contour_cb.value:\n",
    "                    # Draw contour for each label\n",
    "                    ax.contour(mask.astype(float), levels=[0.5], colors=[color_rgba], linewidths=1.5)\n",
    "                else:\n",
    "                    # Draw filled overlay for each label using 2-color colormap (transparent, color)\n",
    "                    cmap = ListedColormap([(0, 0, 0, 0), color_rgba])\n",
    "                    ax.imshow(mask.astype(int), cmap=cmap, interpolation=\"none\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    # Wire callbacks\n",
    "    case_dd.observe(_update_modality_options, names=\"value\")\n",
    "    modality_dd.observe(_update_slice_slider_range, names=\"value\")\n",
    "    plane_rb.observe(_update_slice_slider_range, names=\"value\")\n",
    "    slice_slider.observe(_render, names=\"value\")\n",
    "    labels_ms.observe(_render, names=\"value\")\n",
    "    alpha_slider.observe(_render, names=\"value\")\n",
    "    contour_cb.observe(_render, names=\"value\")\n",
    "    norm_cb.observe(_render, names=\"value\")\n",
    "\n",
    "    # Initial layout\n",
    "    controls_row1 = HBox([case_dd, modality_dd, plane_rb, alpha_slider, contour_cb, norm_cb])\n",
    "    controls_row2 = HBox([slice_slider, labels_ms])\n",
    "    ui = VBox([controls_row1, controls_row2, label_summary_html, out])\n",
    "\n",
    "    # Initialize values and show\n",
    "    _update_modality_options()\n",
    "    display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_file = \"/Users/chufal/projects/Datasets/PKG-BraTS-Africa/BraTS-Africa/95_Glioma/BraTS-SSA-00002-000/*seg*.nii.gz\"\n",
    "# If you know the exact filename, pass it directly:\n",
    "# summarize_segmentation_labels(\"/Users/.../95_Glioma/xxx_seg.nii.gz\")\n",
    "from glob import glob\n",
    "seg_candidates = glob(seg_file)\n",
    "if seg_candidates:\n",
    "    summary = summarize_segmentation_labels(seg_candidates[0])\n",
    "    print(summary)\n",
    "else:\n",
    "    print(\"No seg file matched; open the viewer to discover it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_mask_viewer(\"/Users/chufal/projects/Datasets/PKG-BraTS-Africa/BraTS-Africa/95_Glioma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877902e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
