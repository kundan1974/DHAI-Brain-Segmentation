{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3c59ba",
   "metadata": {},
   "source": [
    "# Unified dataset builder for dual-task (segmentation + classification)\n",
    "- Outputs nnU-Net-style folders: imagesTr/ (with _0000 channel suffix), labelsTr/\n",
    "- dataset.json includes classes per case (non-standard nnU-Net extension)\n",
    "- train.csv / val.csv / test.csv with columns: case_id, class_label, image_path, label_path\n",
    "#\n",
    "## NOTES:\n",
    "- Reorients to RAS+ via nibabel.as_closest_canonical\n",
    "- Binary conversions are applied per dataset-specific rules below\n",
    "- Splits are patient-disjoint and stratified by class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68c222",
   "metadata": {},
   "source": [
    "### CONFIGURE these before running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/chufal/projects/Datasets\"\n",
    "OUT_ROOT = \"/Users/chufal/projects/DHAI-Brain-Segmentation/derived/unified_dualtask\"\n",
    "SPLIT_RATIOS = (0.7, 0.15, 0.15)  # (train, val, test) for the unified dataset\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932f03b",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167381ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, csv, re, random\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import (\n",
    "    Dropdown, IntSlider, FloatSlider, Checkbox, RadioButtons, HBox, VBox, Output, HTML, Layout,\n",
    "    Button, Text, Textarea\n",
    ")\n",
    "from IPython.display import display as _display\n",
    "from matplotlib.colors import ListedColormap, to_rgba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bae5b",
   "metadata": {},
   "source": [
    "# Data Curation Function and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80396f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IO & helpers ----------\n",
    "def as_ras(img: nib.Nifti1Image) -> nib.Nifti1Image:\n",
    "    return nib.as_closest_canonical(img)\n",
    "\n",
    "def save_nifti(path: Path, data: np.ndarray, affine: np.ndarray) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    nib.save(nib.Nifti1Image(data, affine), str(path))\n",
    "\n",
    "def load_arr_ras(path: Path, is_seg: bool = False) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    img = nib.load(str(path))\n",
    "    img_ras = as_ras(img)\n",
    "    arr = img_ras.get_fdata(dtype=np.float32)\n",
    "    if is_seg:\n",
    "        arr = np.rint(arr).astype(np.int16)\n",
    "    return arr, img_ras.affine\n",
    "\n",
    "def ensure_binary(arr: np.ndarray) -> np.ndarray:\n",
    "    return (arr > 0).astype(np.uint8)\n",
    "\n",
    "# ---------- Binary conversion rules (per dataset) ----------\n",
    "def bin_ucsf_pdgm(lbl: np.ndarray) -> np.ndarray:\n",
    "    # If 1 or 4 present -> those -> 1, else >0 -> 1\n",
    "    uniq = set(np.unique(lbl).tolist())\n",
    "    if 1 in uniq or 4 in uniq:\n",
    "        out = ((lbl == 1) | (lbl == 4)).astype(np.uint8)\n",
    "    else:\n",
    "        out = (lbl > 0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def bin_brats_africa(lbl: np.ndarray) -> np.ndarray:\n",
    "    uniq = set(np.unique(lbl).tolist())\n",
    "    if 1 in uniq or 3 in uniq:\n",
    "        out = ((lbl == 1) | (lbl == 3)).astype(np.uint8)\n",
    "    else:\n",
    "        out = (lbl > 0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def bin_mu_glioma_post(lbl: np.ndarray) -> np.ndarray:\n",
    "    uniq = set(np.unique(lbl).tolist())\n",
    "    if 1 in uniq or 3 in uniq:\n",
    "        out = ((lbl == 1) | (lbl == 3)).astype(np.uint8)\n",
    "    else:\n",
    "        out = (lbl > 0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def bin_ucsd_ptgbm(lbl: np.ndarray) -> np.ndarray:\n",
    "    uniq = set(np.unique(lbl).tolist())\n",
    "    if 1 in uniq or 3 in uniq:\n",
    "        out = ((lbl == 1) | (lbl == 3)).astype(np.uint8)\n",
    "    else:\n",
    "        out = (lbl > 0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def bin_upenn(lbl: np.ndarray) -> np.ndarray:\n",
    "    uniq = set(np.unique(lbl).tolist())\n",
    "    if 1 in uniq or 4 in uniq:\n",
    "        out = ((lbl == 1) | (lbl == 4)).astype(np.uint8)\n",
    "    else:\n",
    "        out = (lbl > 0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def bin_pretreat_mets(lbl: np.ndarray) -> np.ndarray:\n",
    "    uniq = set(np.unique(lbl).tolist())\n",
    "    if 3 in uniq:\n",
    "        out = (lbl == 3).astype(np.uint8)\n",
    "    else:\n",
    "        out = (lbl > 0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "# ---------- Dataset scanners ----------\n",
    "\n",
    "def scan_ucsf_pdgm(base: Path) -> List[Dict]:\n",
    "    # Base_path/UCSF-PDGM-v5/ contains per-patient folders.\n",
    "    root = base / \"PKG - UCSF-PDGM Version 5\"  # adjust name if directory differs\n",
    "    if not root.exists():\n",
    "        # Try alternative common folder name\n",
    "        root = base / \"UCSF-PDGM-v5\"\n",
    "    results = []\n",
    "    if not root.exists():\n",
    "        return results\n",
    "    for case_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        files = list(case_dir.glob(\"*.nii.gz\"))\n",
    "        img = next((f for f in files if re.search(r\"_T1c_bias\\.nii\\.gz$\", f.name, re.IGNORECASE)), None)\n",
    "        seg = next((f for f in files if re.search(r\"_tumor_segmentation\\.nii\\.gz$\", f.name, re.IGNORECASE)), None)\n",
    "        if img is None or seg is None:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"case_id\": case_dir.name,\n",
    "            \"image\": img,\n",
    "            \"label\": seg,\n",
    "            \"class_label\": 0,  # Glioma\n",
    "            \"bin_fn\": bin_ucsf_pdgm,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def scan_brats_africa(base: Path) -> List[Dict]:\n",
    "    root = base / \"PKG-BraTS-Africa\" / \"95_Glioma\"\n",
    "    results = []\n",
    "    if not root.exists():\n",
    "        return results\n",
    "    for case_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        img = next((f for f in case_dir.glob(\"*-t1c.nii.gz\")), None)\n",
    "        seg = next((f for f in case_dir.glob(\"*-seg.nii.gz\")), None)\n",
    "        if img is None or seg is None:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"case_id\": case_dir.name,\n",
    "            \"image\": img,\n",
    "            \"label\": seg,\n",
    "            \"class_label\": 0,\n",
    "            \"bin_fn\": bin_brats_africa,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def scan_mu_glioma_post(base: Path) -> List[Dict]:\n",
    "    root = base / \"PKG-MU-Glioma-Post\" / \"MU-Glioma-Post\"\n",
    "    results = []\n",
    "    if not root.exists():\n",
    "        return results\n",
    "    for patient in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        for tp in sorted([p for p in patient.iterdir() if p.is_dir() and p.name.startswith(\"Timepoint_\")]):\n",
    "            img = next((f for f in tp.glob(\"*brain_t1c.nii.gz\")), None)\n",
    "            seg = next((f for f in tp.glob(\"*tumorMask.nii.gz\")), None)\n",
    "            if img is None or seg is None:\n",
    "                continue\n",
    "            case_id = f\"{patient.name}_{tp.name}\"\n",
    "            results.append({\n",
    "                \"case_id\": case_id,\n",
    "                \"image\": img,\n",
    "                \"label\": seg,\n",
    "                \"class_label\": 0,\n",
    "                \"bin_fn\": bin_mu_glioma_post,\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def scan_ucsd_ptgbm(base: Path) -> List[Dict]:\n",
    "    root = base / \"PKG-UCSD-PTGBM-v1\" / \"UCSD-PTGBM\"\n",
    "    results = []\n",
    "    if not root.exists():\n",
    "        return results\n",
    "    for case_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        img = next((f for f in case_dir.glob(\"*_T1post.nii.gz\")), None)\n",
    "        # Prefer BraTS-style multi-class seg, if available\n",
    "        seg = next((f for f in case_dir.glob(\"*BraTS_tumor_seg.nii.gz\")), None)\n",
    "        if img is None or seg is None:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"case_id\": case_dir.name,\n",
    "            \"image\": img,\n",
    "            \"label\": seg,\n",
    "            \"class_label\": 0,\n",
    "            \"bin_fn\": bin_ucsd_ptgbm,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def scan_upenn(base: Path) -> List[Dict]:\n",
    "    root = base / \"PKG-UPENN-GBM-NIfTI\" / \"UPENN-GBM\" / \"NIfTI-files\"\n",
    "    images_root = root / \"images_structural_unstripped\"\n",
    "    masks_root = root / \"images_segm\"\n",
    "    results = []\n",
    "    if not images_root.exists() or not masks_root.exists():\n",
    "        return results\n",
    "    id_img_re = re.compile(r\"(UPENN-GBM-\\d{5}_\\d{2})_T1GD_unstripped\\.nii\\.gz$\", re.IGNORECASE)\n",
    "    id_mask_re = re.compile(r\"(UPENN-GBM-\\d{5}_\\d{2})_segm\\.nii\\.gz$\", re.IGNORECASE)\n",
    "    # Index masks\n",
    "    id_to_mask = {}\n",
    "    for m in masks_root.glob(\"*.nii.gz\"):\n",
    "        mm = id_mask_re.match(m.name)\n",
    "        if mm:\n",
    "            id_to_mask[mm.group(1)] = m\n",
    "    # Walk images\n",
    "    for case_dir in sorted([d for d in images_root.iterdir() if d.is_dir()]):\n",
    "        img = next((f for f in case_dir.glob(\"*.nii.gz\") if id_img_re.match(f.name)), None)\n",
    "        if img is None:\n",
    "            continue\n",
    "        cid = id_img_re.match(img.name).group(1)\n",
    "        seg = id_to_mask.get(cid)\n",
    "        if seg is None:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"case_id\": cid,\n",
    "            \"image\": img,\n",
    "            \"label\": seg,\n",
    "            \"class_label\": 0,\n",
    "            \"bin_fn\": bin_upenn,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def scan_bcbm_radiogenomics(base: Path) -> List[Dict]:\n",
    "    root = base / \"PKG-BCBM-RadioGenomics_Images_Masks_Dec2024\" / \"BCBM_KSC_curated_data\"\n",
    "    results = []\n",
    "    if not root.exists():\n",
    "        return results\n",
    "    for case_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        img = next((f for f in case_dir.glob(\"*_image_ss_n4.nii.gz\")), None)\n",
    "        masks = [f for f in case_dir.glob(\"*_mask_*.nii.gz\")]\n",
    "        if img is None or not masks:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"case_id\": case_dir.name,\n",
    "            \"image\": img,\n",
    "            \"mask_list\": masks,  # union required\n",
    "            \"class_label\": 1,  # Metastatic\n",
    "            \"bin_fn\": None,    # handled via union\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def scan_pretreat_mets(base: Path) -> List[Dict]:\n",
    "    root = base / \"PKG-Pretreat-MetsToBrain-Masks\" / \"Pretreat-MetsToBrain-Masks\"\n",
    "    results = []\n",
    "    if not root.exists():\n",
    "        return results\n",
    "    for case_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        img = next((f for f in case_dir.glob(\"*-t1c.nii.gz\")), None)\n",
    "        seg = next((f for f in case_dir.glob(\"*-seg.nii.gz\")), None)\n",
    "        if img is None or seg is None:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"case_id\": case_dir.name,\n",
    "            \"image\": img,\n",
    "            \"label\": seg,\n",
    "            \"class_label\": 1,\n",
    "            \"bin_fn\": bin_pretreat_mets,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# ---------- Build unified dataset ----------\n",
    "\n",
    "def union_masks(mask_paths: List[Path]) -> np.ndarray:\n",
    "    accum = None\n",
    "    for mp in mask_paths:\n",
    "        arr, _ = load_arr_ras(mp, is_seg=True)\n",
    "        binm = (arr > 0).astype(np.uint8)\n",
    "        accum = binm if accum is None else np.logical_or(accum, binm).astype(np.uint8)\n",
    "    return accum\n",
    "\n",
    "def to_unified_case_id(source: str, case_id: str) -> str:\n",
    "    return f\"{source}_{case_id}\"\n",
    "\n",
    "def write_case(out_root: Path, unified_id: str, img_arr: np.ndarray, img_aff: np.ndarray, lbl_arr: np.ndarray) -> Tuple[Path, Path]:\n",
    "    # nnU-Net naming: image ends with _0000.nii.gz; label uses base name\n",
    "    images_dir = out_root / \"imagesTr\"\n",
    "    labels_dir = out_root / \"labelsTr\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    img_path = images_dir / f\"{unified_id}_0000.nii.gz\"\n",
    "    lbl_path = labels_dir / f\"{unified_id}.nii.gz\"\n",
    "    save_nifti(img_path, img_arr.astype(np.float32), img_aff)\n",
    "    save_nifti(lbl_path, lbl_arr.astype(np.uint8), img_aff)\n",
    "    return img_path, lbl_path\n",
    "\n",
    "def main_build(base_path: str, out_root: str, splits: Tuple[float,float,float]=(0.7,0.15,0.15), seed: int=42):\n",
    "    base = Path(base_path)\n",
    "    out = Path(out_root)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Discover all sources\n",
    "    entries: List[Dict] = []\n",
    "    entries += [{\"source\":\"UCSF_PDGM\", **e} for e in scan_ucsf_pdgm(base)]\n",
    "    entries += [{\"source\":\"BRATS_AFRICA\", **e} for e in scan_brats_africa(base)]\n",
    "    entries += [{\"source\":\"MU_GLIOMA_POST\", **e} for e in scan_mu_glioma_post(base)]\n",
    "    entries += [{\"source\":\"UCSD_PTGBM\", **e} for e in scan_ucsd_ptgbm(base)]\n",
    "    entries += [{\"source\":\"UPENN_GBM\", **e} for e in scan_upenn(base)]\n",
    "    entries += [{\"source\":\"BCBM_RADIOGENOMICS\", **e} for e in scan_bcbm_radiogenomics(base)]\n",
    "    entries += [{\"source\":\"PRETREAT_METS\", **e} for e in scan_pretreat_mets(base)]\n",
    "\n",
    "    if not entries:\n",
    "        raise RuntimeError(\"No cases found across the specified datasets\")\n",
    "\n",
    "    # Build unified cases\n",
    "    index_rows = []  # for dataset.json + CSVs\n",
    "    for e in entries:\n",
    "        unified_id = to_unified_case_id(e[\"source\"], e[\"case_id\"])\n",
    "        # Load image\n",
    "        img_arr, img_aff = load_arr_ras(e[\"image\"], is_seg=False)\n",
    "\n",
    "        # Build label\n",
    "        if e[\"source\"] == \"BCBM_RADIOGENOMICS\":\n",
    "            lbl_arr = union_masks(e[\"mask_list\"])\n",
    "        else:\n",
    "            lbl_raw, _ = load_arr_ras(e[\"label\"], is_seg=True)\n",
    "            lbl_arr = e[\"bin_fn\"](lbl_raw) if e.get(\"bin_fn\") else ensure_binary(lbl_raw)\n",
    "\n",
    "        # Write\n",
    "        img_path, lbl_path = write_case(out, unified_id, img_arr, img_aff, lbl_arr)\n",
    "        index_rows.append({\n",
    "            \"case_id\": unified_id,\n",
    "            \"class_label\": int(e[\"class_label\"]),\n",
    "            \"image\": str(img_path),\n",
    "            \"label\": str(lbl_path),\n",
    "            \"source\": e[\"source\"],\n",
    "            \"orig_case_id\": e[\"case_id\"],\n",
    "        })\n",
    "\n",
    "    # Write dataset.json (nnU-Net style + extra 'class_label' in training entries)\n",
    "    ds_json = {\n",
    "        \"name\": \"UnifiedDualTask\",\n",
    "        \"description\": \"Unified T1c + binary tumor dataset (glioma vs metastatic) built from multiple sources\",\n",
    "        \"tensorImageSize\": \"3D\",\n",
    "        \"modality\": {\"0\": \"t1gd\"},\n",
    "        \"labels\": {\"0\": \"background\", \"1\": \"tumor\"},\n",
    "        \"numTraining\": len(index_rows),\n",
    "        \"training\": [\n",
    "            {\"image\": os.path.relpath(r[\"image\"], out_root), \"label\": os.path.relpath(r[\"label\"], out_root), \"class_label\": r[\"class_label\"]}\n",
    "            for r in index_rows\n",
    "        ],\n",
    "        \"numTest\": 0,\n",
    "        \"test\": []\n",
    "    }\n",
    "    with open(out / \"dataset.json\", \"w\") as f:\n",
    "        json.dump(ds_json, f, indent=2)\n",
    "\n",
    "    # Make splits (patient/case disjoint, stratified by class)\n",
    "    # Group by case_id -> class_label\n",
    "    class_to_cases: Dict[int, List[str]] = {}\n",
    "    for r in index_rows:\n",
    "        class_to_cases.setdefault(int(r[\"class_label\"]), []).append(r[\"case_id\"])\n",
    "    rnd = random.Random(seed)\n",
    "    train_ids, val_ids, test_ids = [], [], []\n",
    "    trf, vf, tf = splits\n",
    "    for lab, cids in class_to_cases.items():\n",
    "        rnd.shuffle(cids)\n",
    "        n = len(cids)\n",
    "        n_train = int(round(trf * n))\n",
    "        n_val = int(round(vf * n))\n",
    "        n_test = max(0, n - n_train - n_val)\n",
    "        train_ids += cids[:n_train]\n",
    "        val_ids += cids[n_train:n_train + n_val]\n",
    "        test_ids += cids[n_train + n_val:]\n",
    "\n",
    "    def _write_split(name: str, ids: List[str]):\n",
    "        p = out / f\"{name}.csv\"\n",
    "        with p.open(\"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"case_id\", \"class_label\", \"image_path\", \"label_path\"])\n",
    "            for cid in ids:\n",
    "                r = next(rr for rr in index_rows if rr[\"case_id\"] == cid)\n",
    "                w.writerow([cid, r[\"class_label\"], r[\"image\"], r[\"label\"]])\n",
    "        return p\n",
    "\n",
    "    p_train = _write_split(\"train\", train_ids)\n",
    "    p_val = _write_split(\"val\", val_ids)\n",
    "    p_test = _write_split(\"test\", test_ids)\n",
    "\n",
    "    print(f\"[DONE] Unified dataset written to: {out_root}\")\n",
    "    print(f\" - imagesTr: {len(list((out/'imagesTr').glob('*.nii*')))}\")\n",
    "    print(f\" - labelsTr: {len(list((out/'labelsTr').glob('*.nii*')))}\")\n",
    "    print(f\" - train: {p_train}\")\n",
    "    print(f\" - val:   {p_val}\")\n",
    "    print(f\" - test:  {p_test}\")\n",
    "\n",
    "# Run the builder (do not run in this message; copy/paste into your environment and execute)\n",
    "# main_build(BASE_PATH, OUT_ROOT, splits=SPLIT_RATIOS, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee574fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_build(BASE_PATH, OUT_ROOT, splits=SPLIT_RATIOS, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152936f4",
   "metadata": {},
   "source": [
    "# Review curated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86bea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#  Dataset review / curation helper (nnU‑Net style)\n",
    "#  ---------------------------------------------------------------\n",
    "#  * Works with a `dataset.json` under <root_path>\n",
    "#  * Optional train/val/test CSV split files are respected\n",
    "#  * Unsatisfactory cases can be flagged with a note and saved to CSV\n",
    "#\n",
    "#  Requirements: nibabel, numpy, matplotlib, ipywidgets\n",
    "# ----------------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "import json, csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, to_rgba\n",
    "from ipywidgets import (\n",
    "    Dropdown, IntSlider, RadioButtons, FloatSlider,\n",
    "    Checkbox, Textarea, Button, HBox, VBox, HTML, Output, Layout, Text\n",
    ")\n",
    "from IPython.display import display\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Utility helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def _as_ras(img: nib.Nifti1Image) -> nib.Nifti1Image:\n",
    "    \"\"\"Return a NIfTI image in RAS orientation.\"\"\"\n",
    "    return nib.as_closest_canonical(img)\n",
    "\n",
    "def _load_arr_ras(path: Path, is_seg: bool = False) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load a nifti file, force it to RAS, and return its 3‑D array + affine.\"\"\"\n",
    "    img = nib.load(str(path))\n",
    "    img = _as_ras(img)\n",
    "    arr = img.get_fdata(dtype=np.float32)\n",
    "    if is_seg:\n",
    "        arr = np.rint(arr).astype(np.int16)        # make segmentation integers\n",
    "    return arr, img.affine\n",
    "\n",
    "def _normalize(img2d: np.ndarray, lo: int = 1, hi: int = 99) -> np.ndarray:\n",
    "    \"\"\"Clip the image to the 1‑99 percentile window and scale to 0‑1.\"\"\"\n",
    "    valid = np.isfinite(img2d)\n",
    "    if not np.any(valid):\n",
    "        return img2d\n",
    "    a, b = np.percentile(img2d[valid], [lo, hi])\n",
    "    if b <= a:\n",
    "        return img2d\n",
    "    img2d = np.clip(img2d, a, b)\n",
    "    return (img2d - a) / (b - a + 1e-6)\n",
    "\n",
    "def _apply_window_percentile(img2d: np.ndarray, p_low: float, p_high: float) -> np.ndarray:\n",
    "    valid = np.isfinite(img2d)\n",
    "    if not np.any(valid): return img2d\n",
    "    lo, hi = np.percentile(img2d[valid], [p_low, p_high])\n",
    "    if hi <= lo: return img2d\n",
    "    img2d = np.clip(img2d, lo, hi)\n",
    "    return (img2d - lo) / (hi - lo + 1e-6)\n",
    "\n",
    "def _apply_window_center_width(img2d: np.ndarray, center: float, width: float) -> np.ndarray:\n",
    "    lo, hi = center - width/2.0, center + width/2.0\n",
    "    if hi <= lo: return img2d\n",
    "    img2d = np.clip(img2d, lo, hi)\n",
    "    return (img2d - lo) / (hi - lo + 1e-6)\n",
    "\n",
    "def _extract_slice(vol: np.ndarray, axis: int, idx: int) -> np.ndarray:\n",
    "    \"\"\"Return a 2‑D slice of a 3‑D volume.\"\"\"\n",
    "    return vol.take(indices=idx, axis=axis)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Dataset parsing helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def _parse_dataset(root: Path) -> list[dict]:\n",
    "    \"\"\"Return a list of cases from `dataset.json` (or by convention).\"\"\"\n",
    "    root = Path(root)\n",
    "    dsj = root / \"dataset.json\"\n",
    "\n",
    "    if not dsj.exists():\n",
    "        # fall back to imagesTr/labelsTr convention\n",
    "        images = sorted((root / \"imagesTr\").glob(\"*.nii*\"))\n",
    "        labels = {p.name.replace(\"_0000\", \"\"): p for p in (root / \"labelsTr\").glob(\"*.nii*\")}\n",
    "        rows = []\n",
    "        for im in images:\n",
    "            lbl_name = im.name.replace(\"_0000\", \"\")\n",
    "            lp = labels.get(lbl_name)\n",
    "            if lp:\n",
    "                rows.append({\n",
    "                    \"case_id\": im.stem.split(\"_\")[0],\n",
    "                    \"image\": str(im),\n",
    "                    \"label\": str(lp),\n",
    "                    \"class_label\": None,\n",
    "                    \"source\": None\n",
    "                })\n",
    "        return rows\n",
    "\n",
    "    # normal nnU‑Net dataset.json\n",
    "    with dsj.open() as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for t in meta.get(\"training\", []):\n",
    "        im = (root / t[\"image\"]).resolve()\n",
    "        lb = (root / t[\"label\"]).resolve()\n",
    "        rows.append({\n",
    "            \"case_id\": Path(lb).stem,\n",
    "            \"image\": str(im),\n",
    "            \"label\": str(lb),\n",
    "            \"class_label\": t.get(\"class_label\"),\n",
    "            \"source\": t.get(\"source\")\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def _load_split_csvs(root: Path) -> dict[str, str]:\n",
    "    \"\"\"Return a dict {case_id : 'train'/'val'/'test'} if split CSVs exist.\"\"\"\n",
    "    cid2split = {}\n",
    "    for nm in (\"train\", \"val\", \"test\"):\n",
    "        p = root / f\"{nm}.csv\"\n",
    "        if p.exists():\n",
    "            with p.open() as f:\n",
    "                for r in csv.DictReader(f):\n",
    "                    cid = r.get(\"case_id\")\n",
    "                    if cid:\n",
    "                        cid2split[cid] = nm\n",
    "    return cid2split\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Main interactive UI\n",
    "# ----------------------------------------------------------------------\n",
    "def launch_curation_tool(root_path: str | Path,\n",
    "                         output_csv: str | Path | None = None,\n",
    "                         preload_csv: str | Path | None = None) -> None:\n",
    "    \"\"\"Show an interactive curation UI.\"\"\"\n",
    "    root = Path(root_path)\n",
    "    cases = _parse_dataset(root)\n",
    "    cid2split = _load_split_csvs(root)\n",
    "\n",
    "    # -------------  add split info to each case  ---------------------\n",
    "    for r in cases:\n",
    "        r[\"split\"] = cid2split.get(r[\"case_id\"], \"NA\")\n",
    "\n",
    "    # -------------  preload any previously flagged cases -----------\n",
    "    flagged = {}\n",
    "    if preload_csv:\n",
    "        p = Path(preload_csv)\n",
    "        if p.exists():\n",
    "            with p.open() as f:\n",
    "                for r in csv.DictReader(f):\n",
    "                    flagged[r[\"case_id\"]] = {\n",
    "                        \"note\": r.get(\"note\", \"\"),\n",
    "                        \"image_path\": r.get(\"image_path\", \"\"),\n",
    "                        \"label_path\": r.get(\"label_path\", \"\"),\n",
    "                        \"split\": r.get(\"split\", \"\")\n",
    "                    }\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  UI widgets\n",
    "    # ------------------------------------------------------------------\n",
    "    split_opts = [\"All\"] + sorted(\n",
    "        {r[\"split\"] for r in cases if r[\"split\"] != \"NA\"}\n",
    "    )\n",
    "    split_dd = Dropdown(\n",
    "        options=split_opts,\n",
    "        value=\"All\",\n",
    "        description=\"Split:\",\n",
    "        layout=Layout(width=\"180px\")\n",
    "    )\n",
    "\n",
    "    def _filter_cases():\n",
    "        s = split_dd.value\n",
    "        return cases if s == \"All\" else [r for r in cases if r[\"split\"] == s]\n",
    "\n",
    "    case_dd = Dropdown(\n",
    "        options=[r[\"case_id\"] for r in _filter_cases()],\n",
    "        description=\"Case:\",\n",
    "        layout=Layout(width=\"360px\")\n",
    "    )\n",
    "\n",
    "    plane_rb = RadioButtons(\n",
    "        options=[(\"Axial\", 2), (\"Coronal\", 1), (\"Sagittal\", 0)],\n",
    "        value=2,\n",
    "        description=\"Plane:\",\n",
    "        layout=Layout(width=\"220px\")\n",
    "    )\n",
    "\n",
    "    slice_slider = IntSlider(\n",
    "        description=\"Slice:\",\n",
    "        min=0,\n",
    "        max=1,\n",
    "        value=0,\n",
    "        continuous_update=False,\n",
    "        layout=Layout(width=\"420px\")\n",
    "    )\n",
    "\n",
    "    alpha_slider = FloatSlider(\n",
    "        description=\"Alpha:\",\n",
    "        min=0.1,\n",
    "        max=1.0,\n",
    "        step=0.05,\n",
    "        value=0.5,\n",
    "        readout_format=\".2f\",\n",
    "        layout=Layout(width=\"220px\")\n",
    "    )\n",
    "\n",
    "    contour_cb = Checkbox(value=False, description=\"Contour only\")\n",
    "    unsat_cb = Checkbox(value=False, description=\"Unsatisfactory\")\n",
    "\n",
    "    # Zoom/magnifier\n",
    "    fig_size = FloatSlider(description=\"FigSize:\", min=5.0, max=12.0, step=0.5, value=6.5, layout=Layout(width=\"240px\"))\n",
    "    zoom_factor = FloatSlider(description=\"Zoom×\", min=1.0, max=6.0, step=0.1, value=1.0, readout_format=\".1f\", layout=Layout(width=\"240px\"))\n",
    "    zoom_cx = FloatSlider(description=\"Cx\", min=0.0, max=1.0, step=0.01, value=0.5, readout_format=\".2f\", layout=Layout(width=\"220px\"))\n",
    "    zoom_cy = FloatSlider(description=\"Cy\", min=0.0, max=1.0, step=0.01, value=0.5, readout_format=\".2f\", layout=Layout(width=\"220px\"))\n",
    "\n",
    "    # Status (Reviewed vs Unsatisfactory). Replaces/augments your unsat_cb.\n",
    "    status_rb = RadioButtons(\n",
    "        options=[(\"Reviewed\", \"reviewed\"), (\"Unsatisfactory\", \"unsatisfactory\")],\n",
    "        value=\"reviewed\",\n",
    "        description=\"Status:\",\n",
    "        layout=Layout(width=\"220px\")\n",
    "    )\n",
    "\n",
    "    # Counters\n",
    "    count_html = HTML(value=\"\", layout=Layout(width=\"100%\"))\n",
    "\n",
    "    \n",
    "\n",
    "    window_mode = Dropdown(\n",
    "    options=[\"Percentile\", \"Center/Width\"], value=\"Percentile\",\n",
    "    description=\"Window:\", layout=Layout(width=\"200px\")\n",
    "    )\n",
    "    p_low = IntSlider(description=\"P_low:\", min=0, max=20, value=1, layout=Layout(width=\"250px\"))\n",
    "    p_high = IntSlider(description=\"P_high:\", min=80, max=100, value=99, layout=Layout(width=\"250px\"))\n",
    "    center_slider = FloatSlider(description=\"Center:\", min=-500.0, max=500.0, step=1.0, value=0.0, readout_format=\".1f\", layout=Layout(width=\"300px\"))\n",
    "    width_slider = FloatSlider(description=\"Width:\", min=1.0, max=2000.0, step=1.0, value=200.0, readout_format=\".1f\", layout=Layout(width=\"300px\"))\n",
    "\n",
    "    note_txt = Textarea(\n",
    "        value=\"\",\n",
    "        placeholder=\"Optional note/reason ...\",\n",
    "        description=\"Note:\",\n",
    "        layout=Layout(width=\"420px\", height=\"60px\")\n",
    "    )\n",
    "\n",
    "    save_btn = Button(description=\"Save CSV\", button_style=\"warning\")\n",
    "    next_btn = Button(description=\"Next ▶\")\n",
    "    prev_btn = Button(description=\"◀ Prev\")\n",
    "\n",
    "    info_html = HTML(layout=Layout(width=\"100%\"))\n",
    "    out = Output(layout=Layout(border=\"1px solid #ddd\"))\n",
    "    csv_path_txt = Text(\n",
    "        value=str(output_csv or root / \"unsatisfactory.csv\"),\n",
    "        description=\"CSV:\",\n",
    "        layout=Layout(width=\"520px\")\n",
    "    )\n",
    "\n",
    "    stats_html = HTML(layout=Layout(width=\"100%\"))\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  Internal state\n",
    "    # ------------------------------------------------------------------\n",
    "    current_img = None          # 3‑D np.ndarray\n",
    "    current_lbl = None          # 3‑D np.ndarray\n",
    "    _is_rendering = False\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  Helper functions\n",
    "    # ------------------------------------------------------------------\n",
    "    def _persist_note_for_case(case_id: str | None):\n",
    "        if not case_id:\n",
    "            return\n",
    "        row = next((r for r in _filter_cases() if r[\"case_id\"] == case_id), None)\n",
    "        if not row:\n",
    "            return\n",
    "        # always persist current status; note can be empty\n",
    "        flagged[case_id] = {\n",
    "            \"status\": status_rb.value,        # \"reviewed\" or \"unsatisfactory\"\n",
    "            \"note\": note_txt.value,\n",
    "            \"image_path\": row[\"image\"],\n",
    "            \"label_path\": row[\"label\"],\n",
    "            \"split\": row.get(\"split\", \"NA\")\n",
    "        }\n",
    "        _update_counters()\n",
    "\n",
    "    def _set_slice_slider_safely(max_val: int, value: int):\n",
    "        \"\"\"Update the slider without firing its observers.\"\"\"\n",
    "        with slice_slider.hold_trait_notifications():\n",
    "            slice_slider.max = max_val\n",
    "            slice_slider.value = value\n",
    "\n",
    "    def _load_case():\n",
    "        \"\"\"Load the 3‑D volumes for the currently selected case.\"\"\"\n",
    "        nonlocal current_img, current_lbl\n",
    "        cid = case_dd.value\n",
    "        row = next(r for r in _filter_cases() if r[\"case_id\"] == cid)\n",
    "\n",
    "        current_img, img_aff = _load_arr_ras(Path(row[\"image\"]))\n",
    "        current_lbl, lbl_aff = _load_arr_ras(Path(row[\"label\"]), is_seg=True)\n",
    "\n",
    "        valid = np.isfinite(current_img)\n",
    "        if np.any(valid):\n",
    "            lo, hi = np.percentile(current_img[valid], [1, 99])\n",
    "            # Percentile sliders\n",
    "            p_low.value = 1\n",
    "            p_high.value = 99\n",
    "            # Center/Width sliders\n",
    "            center_slider.min = float(current_img[valid].min())\n",
    "            center_slider.max = float(current_img[valid].max())\n",
    "            center_slider.value = float((lo + hi) / 2.0)\n",
    "            width_slider.min = 1.0\n",
    "            width_slider.max = float(max(10.0, current_img[valid].max() - current_img[valid].min()))\n",
    "            width_slider.value = float(max(10.0, hi - lo))\n",
    "\n",
    "        # reset slider to the middle of the volume\n",
    "        ax = plane_rb.value\n",
    "        max_idx = max(0, min(current_img.shape[ax], current_lbl.shape[ax]) - 1)\n",
    "        _set_slice_slider_safely(max_idx, max(0, max_idx // 2))\n",
    "\n",
    "        # update flag / note widgets\n",
    "        unsat_cb.unobserve(_on_unsat_change, names=\"value\")\n",
    "        note_txt.unobserve(_on_note_change, names=\"value\")\n",
    "        if cid in flagged:\n",
    "            note_txt.value = flagged[cid][\"note\"]\n",
    "            unsat_cb.value = True\n",
    "        else:\n",
    "            note_txt.value = \"\"\n",
    "            unsat_cb.value = False\n",
    "        unsat_cb.observe(_on_unsat_change, names=\"value\")\n",
    "        note_txt.observe(_on_note_change, names=\"value\")\n",
    "\n",
    "        # restore status/note safely\n",
    "        status_rb.unobserve(_on_status_change, names=\"value\")\n",
    "        note_txt.unobserve(_on_note_change, names=\"value\")\n",
    "        try:\n",
    "            if cid in flagged:\n",
    "                status_rb.value = flagged[cid].get(\"status\", \"reviewed\")\n",
    "                note_txt.value = flagged[cid].get(\"note\", \"\")\n",
    "            else:\n",
    "                status_rb.value = \"reviewed\"\n",
    "                note_txt.value = \"\"\n",
    "        finally:\n",
    "            status_rb.observe(_on_status_change, names=\"value\")\n",
    "            note_txt.observe(_on_note_change, names=\"value\")\n",
    "\n",
    "        # also update zoom center defaults for this case\n",
    "        zoom_cx.value = 0.5\n",
    "        zoom_cy.value = 0.5\n",
    "\n",
    "        # refresh counters (in case filter changed)\n",
    "        _update_counters()\n",
    "\n",
    "        # info line\n",
    "        info_html.value = (\n",
    "            f\"Class: <b>{row.get('class_label','NA')}</b> | \"\n",
    "            f\"Source: <b>{row.get('source','NA')}</b> | \"\n",
    "            f\"Split: <b>{row.get('split','NA')}</b>\"\n",
    "        )\n",
    "\n",
    "        # spacing from affines (mm)\n",
    "        def _spacing_from_aff(aff):\n",
    "            return (abs(float(aff[0, 0])), abs(float(aff[1, 1])), abs(float(aff[2, 2])))\n",
    "\n",
    "        sp_img = _spacing_from_aff(img_aff)\n",
    "        sp_lbl = _spacing_from_aff(lbl_aff)\n",
    "\n",
    "        # intensity stats (raw 3D image)\n",
    "        valid_img = np.isfinite(current_img)\n",
    "        vmin = float(np.nanmin(current_img[valid_img])) if np.any(valid_img) else float(\"nan\")\n",
    "        vmax = float(np.nanmax(current_img[valid_img])) if np.any(valid_img) else float(\"nan\")\n",
    "        vmean = float(np.nanmean(current_img[valid_img])) if np.any(valid_img) else float(\"nan\")\n",
    "        vstd = float(np.nanstd(current_img[valid_img])) if np.any(valid_img) else float(\"nan\")\n",
    "        p1, p99 = (np.percentile(current_img[valid_img], [1, 99]) if np.any(valid_img) else (float(\"nan\"), float(\"nan\")))\n",
    "\n",
    "        # label stats\n",
    "        lbl_nz = int((current_lbl > 0).sum())\n",
    "        lbl_total = int(np.prod(current_lbl.shape))\n",
    "        lbl_cov = (lbl_nz / lbl_total) if lbl_total > 0 else 0.0\n",
    "        lbl_uniq = \", \".join(str(int(x)) for x in np.unique(current_lbl))\n",
    "\n",
    "        stats_html.value = (\n",
    "            f\"Image shape: <b>{current_img.shape}</b> | Label shape: <b>{current_lbl.shape}</b> | \"\n",
    "            f\"Spacing img (mm): <b>{sp_img[0]:.3f}, {sp_img[1]:.3f}, {sp_img[2]:.3f}</b> | \"\n",
    "            f\"Spacing lbl (mm): <b>{sp_lbl[0]:.3f}, {sp_lbl[1]:.3f}, {sp_lbl[2]:.3f}</b><br/>\"\n",
    "            f\"Intensity (raw): min <b>{vmin:.3f}</b>, max <b>{vmax:.3f}</b>, mean <b>{vmean:.3f}</b>, std <b>{vstd:.3f}</b>, \"\n",
    "            f\"p1 <b>{p1:.3f}</b>, p99 <b>{p99:.3f}</b><br/>\"\n",
    "            f\"Labels: unique <b>{lbl_uniq}</b> | voxels >0: <b>{lbl_nz}</b> \"\n",
    "            f\"({lbl_cov*100:.2f}% of volume)\"\n",
    "        )\n",
    "\n",
    "    def _render(*_):\n",
    "        \"\"\"Draw a single frame inside the `Output` widget.\"\"\"\n",
    "        nonlocal _is_rendering\n",
    "        if _is_rendering:\n",
    "            return\n",
    "        _is_rendering = True\n",
    "        try:\n",
    "            if current_img is None or current_lbl is None:\n",
    "                _load_case()\n",
    "\n",
    "            with out:\n",
    "                out.clear_output(wait=True)\n",
    "\n",
    "                ax_val = plane_rb.value\n",
    "                # Guard for very thin volumes and keep label/image shapes in sync\n",
    "                max_idx = max(0, min(current_img.shape[ax_val], current_lbl.shape[ax_val]) - 1)\n",
    "                idx = min(slice_slider.value, max_idx)\n",
    "\n",
    "                img2d = _extract_slice(current_img, ax_val, idx)\n",
    "                lbl2d = _extract_slice(current_lbl, ax_val, idx)\n",
    "\n",
    "                # windowing (reuse your existing windowing selection, else default percentile)\n",
    "                if window_mode.value == \"Percentile\":\n",
    "                    shown = _apply_window_percentile(img2d, float(p_low.value), float(p_high.value))\n",
    "                else:\n",
    "                    shown = _apply_window_center_width(img2d, float(center_slider.value), float(width_slider.value))\n",
    "\n",
    "                # zoom crop (center in [0,1] units)\n",
    "                shown = _crop_for_zoom(shown, float(zoom_factor.value), float(zoom_cx.value), float(zoom_cy.value))\n",
    "\n",
    "                with plt.ioff():\n",
    "                    fig, ax = plt.subplots(1, 1, figsize=(float(fig_size.value), float(fig_size.value)), dpi=100)\n",
    "                    ax.imshow(shown, cmap=\"gray\")\n",
    "                    # mask computed from original lbl2d resized by cropping with same window\n",
    "                    mask = _crop_for_zoom((lbl2d > 0).astype(np.uint8), float(zoom_factor.value), float(zoom_cx.value), float(zoom_cy.value)) > 0\n",
    "                    if np.any(mask):\n",
    "                        col = to_rgba(\"#d62728\", alpha=alpha_slider.value)\n",
    "                        if contour_cb.value:\n",
    "                            ax.contour(mask.astype(float), levels=[0.5], colors=[col], linewidths=1.5)\n",
    "                        else:\n",
    "                            ax.imshow(mask.astype(int), cmap=ListedColormap([(0, 0, 0, 0), col]), interpolation=\"none\")\n",
    "                    ax.axis(\"off\")\n",
    "                    title = f\"{case_dd.value} | {['Sagittal','Coronal','Axial'][ax_val]} | z={idx}\"\n",
    "                    ax.set_title(title)\n",
    "                    out.append_display_data(fig)\n",
    "                    plt.close(fig)\n",
    "\n",
    "        finally:\n",
    "            _is_rendering = False\n",
    "\n",
    "    def _crop_for_zoom(img2d: np.ndarray, zoom: float, cx: float, cy: float) -> np.ndarray:\n",
    "        if zoom <= 1.0:\n",
    "            return img2d\n",
    "        h, w = img2d.shape\n",
    "        win_h = max(1, int(h / zoom))\n",
    "        win_w = max(1, int(w / zoom))\n",
    "        cy_px = int(np.clip(cy, 0.0, 1.0) * (h - 1))\n",
    "        cx_px = int(np.clip(cx, 0.0, 1.0) * (w - 1))\n",
    "        y0 = np.clip(cy_px - win_h // 2, 0, h - win_h)\n",
    "        x0 = np.clip(cx_px - win_w // 2, 0, w - win_w)\n",
    "        return img2d[y0:y0 + win_h, x0:x0 + win_w]\n",
    "\n",
    "    def _update_counters():\n",
    "        fc = _filter_cases()\n",
    "        total = len(fc)\n",
    "        # statuses we’ve saved so far\n",
    "        reviewed_set = {cid for cid, info in flagged.items() if info.get(\"status\") in {\"reviewed\", \"unsatisfactory\"}}\n",
    "        unsat_set = {cid for cid, info in flagged.items() if info.get(\"status\") == \"unsatisfactory\"}\n",
    "        reviewed = len([r for r in fc if r[\"case_id\"] in reviewed_set])\n",
    "        unsat = len([r for r in fc if r[\"case_id\"] in unsat_set])\n",
    "        remaining = max(0, total - reviewed)\n",
    "        count_html.value = f\"Reviewed: <b>{reviewed}</b> | Unsatisfactory: <b>{unsat}</b> | Remaining: <b>{remaining}</b> | Total: <b>{total}</b>\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  Event handlers\n",
    "    # ------------------------------------------------------------------\n",
    "    def _on_split_change(change):\n",
    "        if change[\"name\"] != \"value\":\n",
    "            return\n",
    "        _persist_note_for_case(case_dd.value)\n",
    "        case_dd.options = [r[\"case_id\"] for r in _filter_cases()]\n",
    "        if case_dd.options:\n",
    "            case_dd.value = case_dd.options[0]\n",
    "            _load_case()\n",
    "            _render()\n",
    "\n",
    "    def _on_case_change(change):\n",
    "        if change[\"name\"] != \"value\":\n",
    "            return\n",
    "        _persist_note_for_case(change.get(\"old\"))\n",
    "        _load_case()\n",
    "        _render()\n",
    "\n",
    "    def _on_unsat_change(change):\n",
    "        if change[\"name\"] != \"value\":\n",
    "            return\n",
    "        cid = case_dd.value\n",
    "        row = next(r for r in _filter_cases() if r[\"case_id\"] == cid)\n",
    "\n",
    "        if change[\"new\"]:                       # checked\n",
    "            if cid not in flagged:\n",
    "                flagged[cid] = {\n",
    "                    \"note\": note_txt.value,\n",
    "                    \"image_path\": row[\"image\"],\n",
    "                    \"label_path\": row[\"label\"],\n",
    "                    \"split\": row.get(\"split\", \"NA\")\n",
    "                }\n",
    "            else:\n",
    "                # keep the existing note if the user edited it\n",
    "                if note_txt.value:\n",
    "                    flagged[cid][\"note\"] = note_txt.value\n",
    "                flagged[cid][\"image_path\"] = row[\"image\"]\n",
    "                flagged[cid][\"label_path\"] = row[\"label\"]\n",
    "                flagged[cid][\"split\"] = row.get(\"split\", \"NA\")\n",
    "        else:                                   # unchecked\n",
    "            flagged.pop(cid, None)\n",
    "\n",
    "    def _on_note_change(change):\n",
    "        cid = case_dd.value\n",
    "        if unsat_cb.value:\n",
    "            if cid not in flagged:\n",
    "                flagged[cid] = {\"note\": \"\", \"image_path\": \"\", \"label_path\": \"\", \"split\": \"NA\"}\n",
    "            flagged[cid][\"note\"] = note_txt.value\n",
    "\n",
    "    def _save_csv(_):\n",
    "        p = Path(csv_path_txt.value)\n",
    "        p.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with p.open(\"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"case_id\", \"image_path\", \"label_path\", \"split\", \"status\", \"note\"])\n",
    "            for cid, info in flagged.items():\n",
    "                w.writerow([\n",
    "                    cid,\n",
    "                    info.get(\"image_path\", \"\"),\n",
    "                    info.get(\"label_path\", \"\"),\n",
    "                    info.get(\"split\", \"\"),\n",
    "                    info.get(\"status\", \"reviewed\"),\n",
    "                    info.get(\"note\", \"\")\n",
    "                ])\n",
    "        print(f\"[SAVED] {p} ({len(flagged)} flagged)\")\n",
    "\n",
    "    def _goto_next(_):\n",
    "        _persist_note_for_case(case_dd.value)\n",
    "        idx = list(case_dd.options).index(case_dd.value)\n",
    "        case_dd.value = case_dd.options[(idx + 1) % len(case_dd.options)]\n",
    "\n",
    "    def _goto_prev(_):\n",
    "        _persist_note_for_case(case_dd.value)\n",
    "        idx = list(case_dd.options).index(case_dd.value)\n",
    "        case_dd.value = case_dd.options[(idx - 1) % len(case_dd.options)]\n",
    "\n",
    "    def _on_plane_change(change):\n",
    "        if change[\"name\"] != \"value\" or current_img is None or current_lbl is None:\n",
    "            return\n",
    "        ax = plane_rb.value\n",
    "        max_idx = max(0, min(current_img.shape[ax], current_lbl.shape[ax]) - 1)\n",
    "        _set_slice_slider_safely(max_idx, max(0, max_idx // 2))\n",
    "        _render()\n",
    "\n",
    "    def _on_slice_change(change):\n",
    "        if change[\"name\"] != \"value\" or _is_rendering:\n",
    "            return\n",
    "        _render()\n",
    "\n",
    "    def _on_status_change(change):\n",
    "        if change[\"name\"] != \"value\":\n",
    "            return\n",
    "        _persist_note_for_case(case_dd.value)\n",
    "\n",
    "    def _on_window_change(change):\n",
    "        if change[\"name\"] != \"value\" or _is_rendering:\n",
    "            return\n",
    "        _render()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  Wire everything together\n",
    "    # ------------------------------------------------------------------\n",
    "    split_dd.observe(_on_split_change, names=\"value\")\n",
    "    case_dd.observe(_on_case_change, names=\"value\")\n",
    "    plane_rb.observe(_on_plane_change, names=\"value\")\n",
    "    slice_slider.observe(_on_slice_change, names=\"value\")\n",
    "    alpha_slider.observe(_render, names=\"value\")\n",
    "    contour_cb.observe(_render, names=\"value\")\n",
    "    unsat_cb.observe(_on_unsat_change, names=\"value\")\n",
    "    note_txt.observe(_on_note_change, names=\"value\")\n",
    "    save_btn.on_click(_save_csv)\n",
    "    next_btn.on_click(_goto_next)\n",
    "    prev_btn.on_click(_goto_prev)\n",
    "    window_mode.observe(_render, names=\"value\")\n",
    "    p_low.observe(_render, names=\"value\")\n",
    "    p_high.observe(_render, names=\"value\")\n",
    "    center_slider.observe(_render, names=\"value\")\n",
    "    width_slider.observe(_render, names=\"value\")\n",
    "    status_rb.observe(_on_status_change, names=\"value\")\n",
    "    fig_size.observe(_on_window_change, names=\"value\")\n",
    "    zoom_factor.observe(_on_window_change, names=\"value\")\n",
    "    zoom_cx.observe(_on_window_change, names=\"value\")\n",
    "    zoom_cy.observe(_on_window_change, names=\"value\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  Build the UI layout\n",
    "    # ------------------------------------------------------------------\n",
    "    row0 = HBox([split_dd, case_dd, prev_btn, next_btn])\n",
    "    row1 = HBox([plane_rb, slice_slider])\n",
    "    row2 = HBox([alpha_slider, contour_cb, status_rb])\n",
    "    rowW1 = HBox([window_mode, p_low, p_high])\n",
    "    rowW2 = HBox([center_slider, width_slider])\n",
    "    rowZ  = HBox([fig_size, zoom_factor, zoom_cx, zoom_cy])\n",
    "    row3 = HBox([HTML(\"CSV Path:\"), csv_path_txt, save_btn])\n",
    "\n",
    "    ui = VBox([row0, count_html, row1, row2, rowW1, rowW2, rowZ, note_txt, info_html, stats_html, out, row3])\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #  Initial draw\n",
    "    # ------------------------------------------------------------------\n",
    "    if case_dd.options:\n",
    "        # resume: go to the first unreviewed in current filter\n",
    "        fc = _filter_cases()\n",
    "        reviewed_or_unsat = {cid for cid, info in flagged.items() if info.get(\"status\") in {\"reviewed\", \"unsatisfactory\"}}\n",
    "        next_cid = next((r[\"case_id\"] for r in fc if r[\"case_id\"] not in reviewed_or_unsat), fc[0][\"case_id\"])\n",
    "        case_dd.value = next_cid\n",
    "        _load_case()\n",
    "        _render()\n",
    "\n",
    "    display(ui)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Example usage\n",
    "# ----------------------------------------------------------------------\n",
    "# root = \"/path/to/your/nnunet/dataset\"\n",
    "# launch_curation_tool(root, output_csv=None, preload_csv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc15e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5a262394b84912bee04c75cb13ca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Split:', layout=Layout(width='180px'), options=('All',), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = \"/Users/chufal/projects/DHAI-Brain-Segmentation/derived/unified_dualtask\"\n",
    "launch_curation_tool(root, output_csv=None, preload_csv=\"/Users/chufal/projects/DHAI-Brain-Segmentation/derived/unified_dualtask/unsatisfactory.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acccd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50f0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
